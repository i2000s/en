<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="https://www.w3.org/2005/Atom">

 <title>The NoteBlog of Xiaodong Qi</title>
 <link href="https://www.qixiaodong.tk/en/atom.xml" rel="self"/>
 <link href="https://www.qixiaodong.tk/en"/>
 <updated>2016-11-22T10:52:44+00:00</updated>
 <id>https://www.qixiaodong.tk/en</id>
 <author>
   <name>Xiaodong Qi</name>
   <email>i2000s@hotmail.com</email>
 </author>

 
 <entry>
   <title>Put everything on a quantum circuit--part I</title>
   <link href="https://www.qixiaodong.tk/en/2016/07/23/put-everything-on-a-quantum-circuit-part-i.html"/>
   <updated>2016-07-23T00:00:00+00:00</updated>
   <id>/2016/07/23/put-everything-on-a-quantum-circuit-part-i</id>
   <content type="html">&lt;h2 id=&quot;preface&quot;&gt;Preface&lt;/h2&gt;
&lt;p&gt;This series of notes is initially written for &lt;a href=&quot;https://github.com/amitjamadagni&quot;&gt;Amit Jamadagni&lt;/a&gt; and &lt;a href=&quot;https://github.com/Roger-luo&quot;&gt;Xiuzhe Luo&lt;/a&gt; who have been working on the &lt;a href=&quot;https://juliaquantum.github.io&quot;&gt;JuliaQuantum organization&lt;/a&gt;’s &lt;a href=&quot;https://github.com/JuliaQuantum/QuBase.jl&quot;&gt;Base.jl&lt;/a&gt;, &lt;a href=&quot;https://github.com/JuliaQuantum/QuDynamics.jl&quot;&gt;QuDynamics.jl&lt;/a&gt; and &lt;a href=&quot;https://github.com/JuliaQuantum/QuCmp.jl&quot;&gt;QuCmp.jl&lt;/a&gt; projects individually. Amit has put intensive efforts on framing out the basic &lt;a href=&quot;https://julialang.org&quot;&gt;Julia&lt;/a&gt; libraries on basic quantum type system, the time evolution of quantum systems and the idea of propagators. Xiuzhe as a junior undergraduate physics student just started the QuCmp.jl project to build some fundamental Julia libraries for quantum computing (adiabatic quantum computing, quantum circuit model and others). I try to outline in the notes some theoretical foundations on quantum dynamics (especially for open quantum systems) and its link to simulating quantum computing models (especially on the circuit model) with the hope to conclude the following points:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;To reach out the regime of more complicated scenarios to simulate general quantum systems beyond what Amit have done, it would be great to have the stochastic differential equations and their solvers established.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;To be widely useful and efficient, it may be better to reframe the type system on top of operator and superoperator language&lt;a href=&quot;#fn1&quot; class=&quot;footnoteRef&quot; id=&quot;fnref1&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;. It could be easier to start with the complete positive mapping case where the methods and theory have been well established.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;All of the current projects are depending on each other on different levels, and hence developers should know how JuliaQuantum projects are connected in a big picture and work together. That will make the organization and its projects long-lasting and attractive.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;There are a lot to look forward to in building the JuliaQuantum libraries. Once the operator/superoperator type system established, the stochastic equation solves will be easier to implement; once that is done, quantum metrology, tomography and control which usually involve stochastic processes instead of deterministic time-evolution processes will be possible to simulate using the basic packages, and packages for these applications can be developed; the quantum computing package–especially the universal quantum circuit simulation module–is one aspect of those applications as well as the foundation for designing and controlling future quantum computers, the high-performance and generality of which could attract people to join us to develop more useful tools and devices even after the quantum computing times burst.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I wish this series of notes could be helpful in sketching a big and inspiring picture in the readers’ mind, instead of trapping their mind into some niches. It may be helpful for other audience. Please leave your comments if you find it helpful or have other thoughts.&lt;/p&gt;
&lt;h2 id=&quot;a-normal-time-evolution-instance-you-may-have-studied&quot;&gt;A normal time-evolution instance you may have studied&lt;/h2&gt;
&lt;p&gt;Let us begin with a simple example: an atomic ensemble interacts with a quantum bath which could be a magnetic field or ideal single photon sources. The time evolution of the density operator may be described by the following differential map &lt;span class=&quot;math&quot;&gt;\[\begin{equation}\label{eq:drhot}
\hat{\rho}(t+dt) = \hat{M}_0(dt)\hat{\rho}(t)\hat{M}^\dagger_0(dt) +
\sum_{\mu&amp;gt;0} \hat{M}_\mu (dt)\hat{\rho}(t)\hat{M}^\dagger(dt)
\end{equation}\]&lt;/span&gt; where the self-evolution operator in the time slot &lt;span class=&quot;math&quot;&gt;\(dt\)&lt;/span&gt; is given by &lt;span class=&quot;math&quot;&gt;\(\hat{M}_0(dt)=\hat{\mathbb{1}}-\frac{i}{\hbar}\hat{H}_{eff}dt\)&lt;/span&gt; with the effective Hamiltonian &lt;span class=&quot;math&quot;&gt;\(\hat{H}_{eff}=\hat{H}-\frac{i\hbar}{2}\sum_\mu \hat{L}_\mu^\dagger \hat{L}_\mu\)&lt;/span&gt;. The system Hamiltonian &lt;span class=&quot;math&quot;&gt;\(\hat{H}\)&lt;/span&gt; can be arbitrary yet Hermitian. It defines how the system processes without interacting with environment and its energy spectrum (levels). If we consider a spin-&lt;span class=&quot;math&quot;&gt;\(1/2\)&lt;/span&gt; system in the z-basis, a simple free-processing Hamiltonian could be &lt;span class=&quot;math&quot;&gt;\[\begin{align}
\hat{H} &amp;amp;= \left( \matrix{E_+ &amp;amp; 0 \\ 0 &amp;amp; E_-}\right),
\end{align}\]&lt;/span&gt; where &lt;span class=&quot;math&quot;&gt;\(E_+\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(E_-\)&lt;/span&gt; are the two energy levels. Obviously, it can be rewritten using the Pauli operators.&lt;/p&gt;
&lt;p&gt;The so-called jump operators &lt;span class=&quot;math&quot;&gt;\(\hat{L}_\mu\)&lt;/span&gt; define how the system will evolve in each measurement basis &lt;span class=&quot;math&quot;&gt;\(\mu\)&lt;/span&gt;. A quantum state will be evolved into &lt;span class=&quot;math&quot;&gt;\[\begin{align}
\ket{\Psi(t+dt)} &amp;amp;= \hat{L}_\mu(dt) \ket{\Psi(t)}
\end{align}\]&lt;/span&gt; if only considering the single jump operator &lt;span class=&quot;math&quot;&gt;\(\hat{L}_\mu\)&lt;/span&gt; applied in a small period of time, &lt;span class=&quot;math&quot;&gt;\(dt\)&lt;/span&gt;. We call &lt;span class=&quot;math&quot;&gt;\(\hat{L}_\mu\)&lt;/span&gt; a jump operator because it projects the quantum state towards some eigenstate of the operator randomly. For example, we could let $ \hat{L}&lt;em&gt;i = \sigma&lt;/em&gt;z $ for a spin-&lt;span class=&quot;math&quot;&gt;\(1/2\)&lt;/span&gt; system, which means &lt;span class=&quot;math&quot;&gt;\(\hat{L}_i\)&lt;/span&gt; will tend to project the system onto one of its eigenstate for spin number &lt;span class=&quot;math&quot;&gt;\(\pm \frac{1}{2}\)&lt;/span&gt; in the z-basis. To give a concrete sense of physics, this type of jump operators could corresponding to a magnetic field interaction–the one as we know in the &lt;a href=&quot;https://en.wikipedia.org/wiki/Stern%E2%80%93Gerlach_experiment&quot;&gt;Stern-Gerlach experiment&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We can formally define a set of Krause operators &lt;span class=&quot;math&quot;&gt;\[\begin{align}
\hat{M}_\mu &amp;amp;= \hat{L}_\mu \sqrt{dt},\quad \mu=1,\cdots,m.
\end{align}\]&lt;/span&gt; Notice that each &lt;span class=&quot;math&quot;&gt;\(\hat{M}_\mu\)&lt;/span&gt; is on the order of &lt;span class=&quot;math&quot;&gt;\(\sqrt{dt}\)&lt;/span&gt; which makes the Krause operator a second-order effect on the evolution of the system. We define the Krause operators in this way is based on the fact that the measurement operators &lt;span class=&quot;math&quot;&gt;\(\hat{E}_\mu\)&lt;/span&gt; and the probability of finding the output on the &lt;span class=&quot;math&quot;&gt;\(\mu\)&lt;/span&gt; channel &lt;span class=&quot;math&quot;&gt;\(p_\mu\)&lt;/span&gt; should be &lt;span class=&quot;math&quot;&gt;\[\begin{align}
\hat{E}_\mu &amp;amp;= \hat{M}^\dagger_\mu\hat{M}_\mu \\
p_\mu &amp;amp;= \tr\left( \hat{\rho}\hat{E}_\mu\right) \label{eq:jumppmu}
\end{align}\]&lt;/span&gt; which are incremental over &lt;span class=&quot;math&quot;&gt;\(dt\)&lt;/span&gt; time slots. The post-measurement state can therefore be written as &lt;span class=&quot;math&quot;&gt;\[\begin{align}\label{eq:rhodt}
\hat{\rho}_\mu = \frac{\hat{M}_\mu\hat{\rho}\hat{M}^\dagger_\mu}{p_\mu}.
\end{align}\]&lt;/span&gt; For a pure state &lt;span class=&quot;math&quot;&gt;\(\hat{\rho}=\ketbra{\Psi}{\Psi}\)&lt;/span&gt;&lt;a href=&quot;#fn2&quot; class=&quot;footnoteRef&quot; id=&quot;fnref2&quot;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;, &lt;span class=&quot;math&quot;&gt;\[\begin{align} \label{eq:Psidt}
\ket{\Psi(t+dt)}_\mu = \frac{\hat{M}_\mu\ket{\Psi(t)}}{\sqrt{p_\mu}} = \frac{\hat{L}_\mu\ket{\Psi(t)}}{ \abs{\hat{L}_\mu\ket{\Psi(t)}} }.
\end{align}\]&lt;/span&gt; Eq.&lt;span class=&quot;math&quot;&gt;\(\eqref{eq:Psidt}\)&lt;/span&gt; may look more familiar than Eq.&lt;span class=&quot;math&quot;&gt;\(\eqref{eq:rhodt}\)&lt;/span&gt; as the former one is commonly used to describe Born’s rules on quantum measurements.&lt;/p&gt;
&lt;p&gt;If we look at Eqs.&lt;span class=&quot;math&quot;&gt;\(\eqref{eq:Psidt}\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\eqref{eq:rhodt}\)&lt;/span&gt; more closely, we will find that both has been used in defining the algorithms of &lt;strong&gt;&lt;em&gt;quantum diffusion Monte Carlo&lt;/em&gt;&lt;/strong&gt; (QDMC) or &lt;strong&gt;&lt;em&gt;quantum wavefunction Monte Carlo&lt;/em&gt;&lt;/strong&gt; (QWFMC) method&lt;a href=&quot;#Dum1992Monte&quot;&gt; [1,2,3,4]&lt;/a&gt;. The &lt;span class=&quot;math&quot;&gt;\(\hat{L}_\mu\)&lt;/span&gt; operator indeed defines the random quantum jumps in the algorithm with a jump probability defined in Eq.&lt;span class=&quot;math&quot;&gt;\(\eqref{eq:jumppmu}\)&lt;/span&gt;! Each jump will lead to a new quantum trajectory and &lt;em&gt;diffuse&lt;/em&gt; the quantum states over time.&lt;/p&gt;
&lt;p&gt;Further more, if we rewrite Eq.&lt;span class=&quot;math&quot;&gt;\(\eqref{eq:drhot}\)&lt;/span&gt; in the form of an ordinary differential equation, we have obtain &lt;span class=&quot;math&quot;&gt;\[\begin{align} \label{eq:lindblad}
\dd{\rho}{t} &amp;amp;= -\frac{i}{\hbar} \left[ \hat{H},\hat{\rho}\right]-\frac{1}{2}\sum_{\mu=1}^m \left( \hat{L}_\mu^\dagger\hat{L}_\mu\hat{\rho}+\hat{\rho}\hat{L}^\dagger_\mu\hat{L}_\mu-2\hat{L}_\mu\hat{\rho}\hat{L}^\dagger_\mu \right).
\end{align}\]&lt;/span&gt; This is the famous &lt;em&gt;Lindblad&lt;/em&gt; form of the &lt;strong&gt;&lt;em&gt;quantum master equation&lt;/em&gt;&lt;/strong&gt; for an open system! In many textbooks, the Lindblad equation can also be formally simplified by defining a superoperator &lt;span class=&quot;math&quot;&gt;\(\mathcal{D}[\cdot]\)&lt;/span&gt; via &lt;span class=&quot;math&quot;&gt;\[\begin{equation}
\mathcal{D}[\hat{\rho}] = -\frac{i}{\hbar} \left[ \hat{H},\hat{\rho}\right]-\frac{1}{2}\sum_{\mu=1}^m \left( \hat{L}_\mu^\dagger\hat{L}_\mu\hat{\rho}+\hat{\rho}\hat{L}^\dagger_\mu\hat{L}_\mu-2\hat{L}_\mu\hat{\rho}\hat{L}^\dagger_\mu \right)
\end{equation}\]&lt;/span&gt; so that &lt;span class=&quot;math&quot;&gt;\(\dd{\hat{\rho}}{t}=\mathcal{D}[\hat{\rho}]\)&lt;/span&gt; describes a dissipative process in a neat form. In the mean time, the jump operators &lt;span class=&quot;math&quot;&gt;\(\hat{L}_\mu\)&lt;/span&gt; could also be called in many places the Lindblad operators if they yields the POVMs as defined earlier.&lt;/p&gt;
&lt;p&gt;Just a note on side: the measurement operator defined earlier is usually called POVMs (postive-valued measurements) if the eigenvalues are not negative corresponding to physical projection measurement outputs. In research, finding an optimal set of measurements to retrieve the maximum information of the quantum state of a system with minimal times of measurements has been a hot topic and leads to the field of quantum tomography, compressed sensing and related algorithms.&lt;/p&gt;
&lt;h2 id=&quot;a-second-look-on-the-quantum-trajectories-using-stochastic-calculus-language&quot;&gt;A second look on the quantum trajectories using stochastic calculus language&lt;/h2&gt;
&lt;p&gt;Above, we have described the system-environment interaction as a process of random quantum measurements. In the cases we have studied, we treat the environmental disturb as statistically identical sources over time–to some extent, the jump probability distribution has to be identical for each jump step to be able to directly apply the pure time-differential equations we have derived earlier. Let us take a closer look on its statistic nature in the language of stochastic calculus&lt;a href=&quot;#Gardiner1985Handbook&quot;&gt; [5]&lt;/a&gt;&lt;a href=&quot;#fn3&quot; class=&quot;footnoteRef&quot; id=&quot;fnref3&quot;&gt;&lt;sup&gt;3&lt;/sup&gt;&lt;/a&gt;.&lt;/p&gt;
For simplicity, we will stick to a given state &lt;span class=&quot;math&quot;&gt;\(\ket{\Psi(t)}\)&lt;/span&gt;. We define a random variable–a stochastic interval &lt;span class=&quot;math&quot;&gt;\(dN_\mu(t)\)&lt;/span&gt;–Poisson distributed with values
&lt;div&gt;
&lt;span class=&quot;math&quot;&gt;\[\begin{equation}\label{eq:dNmudistr}
dN_\mu(t) = \left\{
  \begin{array}
  \\1 , &amp;amp; \text{with probability } p_\mu \\
  0, &amp;amp; \text{with probability } 1-p_\mu.
  \end{array}\right.
\end{equation}\]&lt;/span&gt;
&lt;/div&gt;
&lt;p&gt;It satisfies the properties based on the rule of stochastic calculus that &lt;span class=&quot;math&quot;&gt;\[\begin{align}
\sum_{\mu=0}^m dN_\mu(t) &amp;amp;=1,\label{eq:sumdNmu}\\
dN_\mu(t)dN_\nu (t) &amp;amp;= \delta_{\mu\nu} dN_\mu(t),\\
\text{expectation value } \langle dN_\mu (t)\rangle &amp;amp;= p_\mu = \bra{\Psi(t)} \hat{L}^\dagger_\mu \hat{L}_\mu \ket{\Psi(t)}dt.
\end{align}\]&lt;/span&gt; Then based on the physical meaning, we can rewrite an unnormalized form of the evolved state by &lt;span class=&quot;math&quot;&gt;\[\begin{align}
\ket{\tilde{\Psi}(t+dt)} &amp;amp;= dN_0(t)\hat{M}_0\ket{\Psi(t)} + \sum_{\mu=1}^m dN_\mu (t)\hat{L}_\mu \ket{\Psi(t)}.
\end{align}\]&lt;/span&gt; We use the property of the stochastic internal &lt;span class=&quot;math&quot;&gt;\(dN_\mu(t)\)&lt;/span&gt; to replace &lt;span class=&quot;math&quot;&gt;\(dN_0(t)=1-\sum_{\mu=1}^m dN_\mu\)&lt;/span&gt;, and obtain &lt;span class=&quot;math&quot;&gt;\[\begin{align}
\ket{\tilde{\Psi}(t+dt)} &amp;amp;= \hat{M}_0\ket{\Psi(t)} + \sum_{\mu=1}^m dN_\mu (t) (\hat{L}_\mu -\hat{M}_0) \ket{\Psi(t)}\\
&amp;amp;= (\mathbb{1} - \frac{i}{\hbar}\hat{H}_{eff}dt)\ket{\Psi(t)} + \sum_{\mu=1}^m dN_\mu (\hat{L}_\mu - \mathbb{1} + \frac{i}{\hbar}\hat{H}_{eff}dt)\ket{\Psi(t)}.
\end{align}\]&lt;/span&gt; We ignore the terms that have an order higher than &lt;span class=&quot;math&quot;&gt;\(dt\)&lt;/span&gt; according to the rules of stochastic calculus, that is to let &lt;span class=&quot;math&quot;&gt;\(dN_\mu (t)dt \sim \sqrt{dt}dt=0\)&lt;/span&gt;, and obtain the unnormalized state update equation &lt;span class=&quot;math&quot;&gt;\[\begin{align}
d\ket{\tilde{\Psi}} &amp;amp;\equiv \ket{\tilde{\Psi}(t+dt)} - \ket{\Psi(t)}\\
&amp;amp;= -\frac{i}{\hbar} \hat{H}_{eff}dt\ket{\Psi} + \sum_{\mu=1}^m dN_\mu(t)(\hat{L}_\mu-1)\ket{\Psi}.
\end{align}\]&lt;/span&gt; This is the unnormalized &lt;strong&gt;&lt;em&gt;stochastic Schrodinger equation&lt;/em&gt;&lt;/strong&gt; (SSE) for a jump update. Alternatively, in the normalized form, the SSE becomes &lt;span class=&quot;math&quot;&gt;\[\begin{align}\label{eq:SSE}
d\ket{\Psi} &amp;amp;= \left( -\frac{i}{\hbar}\hat{H}_{eff} + \frac{1}{2}\sum_{\mu=1}^m \langle \hat{L}^\dagger_\mu \hat{L}_\mu \rangle \right) dt\ket{\Psi} + \sum_{\mu=1}^m dN_\mu(t) \left( \frac{\hat{L}_\mu}{\sqrt{\langle \hat{L}^\dagger_\mu \hat{L}_\mu\rangle }}-1\right)\ket{\Psi}.
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;By using the definition that the density operator is the ensemble average, &lt;span class=&quot;math&quot;&gt;\(\hat{\rho}(t+dt)=\bar{\ketbra{\Psi(t+dt)}{\Psi(t+dt)}}\)&lt;/span&gt; and only keep terms up to the order of &lt;span class=&quot;math&quot;&gt;\(dt\)&lt;/span&gt;, it is trivial to show that the Lindblad equation (Eq.&lt;span class=&quot;math&quot;&gt;\(\eqref{eq:lindblad}\)&lt;/span&gt;) is equivalent to the SSE.&lt;/p&gt;
&lt;p&gt;There are two important properties of the SSEs, Lindblad equations and &lt;span class=&quot;math&quot;&gt;\(dN(t)\)&lt;/span&gt;:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The SSEs and Lindblad master equations in general are unlike the normal Schrodinger equation, and could be nonlinear due to the fact that &lt;span class=&quot;math&quot;&gt;\(dN_\mu(t)\)&lt;/span&gt; could depend on the state of &lt;span class=&quot;math&quot;&gt;\(\Psi(t)\)&lt;/span&gt; at each time step&lt;a href=&quot;#fn4&quot; class=&quot;footnoteRef&quot; id=&quot;fnref4&quot;&gt;&lt;sup&gt;4&lt;/sup&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;In our case, &lt;span class=&quot;math&quot;&gt;\(dN(t)\)&lt;/span&gt; obeys the Poisson distribution. It means that, in every jump of the quantum trajectory, the jump statistics will be the same as the previous step, and the process of determining which trajectory to jump can be mapped to the “toss of a coin” problem–whether the result is a “head” or “tail” for every toss is predefined as independent identical instances with a uniform random distribution. This is a typical Markov chain process that the “toss of coin” doesn’t have a memory with the previous step, or physically you might want to regard this process as being jumping in steps slower than the dissipative or equilibrium process (&lt;span class=&quot;math&quot;&gt;\(\delta t \gg 1/\gamma\)&lt;/span&gt;). Lindblad equations with a simple time-homogeneous evolution only works for Markovian processes with simple random sampling properties.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In similar cases, one can use different Lindblad operators to describe the quantum dynamics with the same form of Lindblad equations as shown in Eq.&lt;span class=&quot;math&quot;&gt;\(\eqref{eq:lindblad}\)&lt;/span&gt;. Commonly, the &lt;em&gt;relaxation&lt;/em&gt; process of a quantum system in presence of a reservoir can be described by the Lindblad superoperator &lt;span class=&quot;math&quot;&gt;\[\begin{align}
\mathcal{L}[\hat{\rho}] &amp;amp;= -\frac{1}{2}\sum_{\mu=1} \left( \hat{L}_\mu^\dagger\hat{L}_\mu\hat{\rho}+\hat{\rho}\hat{L}^\dagger_\mu\hat{L}_\mu-2\hat{L}_\mu\hat{\rho}\hat{L}^\dagger_\mu \right)\\
&amp;amp;= \frac{1}{2}\sum_{\mu=1}\left[\hat{L}_\mu,\left[\hat{\rho}, \hat{L}_\mu \right] \right].
\end{align}\]&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;all-can-be-extended-to-more-complicated-cases-with-a-small-tweak&quot;&gt;All can be extended to more complicated cases with a small tweak&lt;/h2&gt;
&lt;p&gt;We can briefly take a look on how this formalism can be extended to other cases and find the correct Lindblad operators–yes, find a proper Lindblad operator is the only modification without changing the form of equations for some cases. For example, in a homodyne detection case&lt;a href=&quot;#Wiseman1993Interpretation&quot;&gt; [6]&lt;/a&gt;, a beam splitter is used to branch out two signal paths for the final measurement; a local oscillator, which could be a coherent laser beam locked at the same frequency as the input signal on the other branch of the beam splitter as shown in the figure below. For a balanced beam splitter, the two output branches yield the combined and subtracted signals in detection, which are the &lt;span class=&quot;math&quot;&gt;\(\hat{X}\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(\hat{P}\)&lt;/span&gt; quadratures in the phase plane.&lt;/p&gt;
&lt;center&gt;
 
&lt;figure&gt;
&lt;img src=&quot;https://www.qixiaodong.tk/assets/img/homodyneheterodyne_beamsplitter.svg&quot; alt=&quot;Fig 1. Beam splitter for homodyne and heterodyne detections.&quot; /&gt;&lt;figcaption&gt;Fig 1. Beam splitter for homodyne and heterodyne detections.&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;br&gt; &lt;br&gt;
&lt;/center&gt;

&lt;p&gt;By treating the local oscillator as a coherent light with a large amplitude &lt;span class=&quot;math&quot;&gt;\(\alpha\)&lt;/span&gt; (related to the averge phone flux with a phase factor), the input-output relationship of the beam splitter can be given by &lt;span class=&quot;math&quot;&gt;\[\begin{align}
\hat{a}_\pm &amp;amp;= \frac{\alpha\hat{\mathbb{1}} \pm \hat{a}}{\sqrt{2}}.
\end{align}\]&lt;/span&gt; Assuming the other part of the quantum system is the same as before and the signal has &lt;span class=&quot;math&quot;&gt;\(\mu=1,\cdots,m\)&lt;/span&gt; modes, the Lindblad operators can be written as &lt;span class=&quot;math&quot;&gt;\(\hat{J}_{\mu,\pm} = \frac{A_\mu \hat{\mathbb{1}}\pm \hat{L}_\mu}{\sqrt{2}}\)&lt;/span&gt;, where &lt;span class=&quot;math&quot;&gt;\(A_\mu\)&lt;/span&gt; is a complex constant. After some algebra, the Krause operators of the homodyne case can also be defined as a linear transformation of the previous Krause operators: &lt;span class=&quot;math&quot;&gt;\[\begin{align}
\left(\begin{array}{c} \hat{K}_0\\ \hat{K}_{\mu,+} \\ \hat{K}_{\mu,-}\end{array}\right)
&amp;amp;= \left[ \begin{array}{ccc}
1-\frac{1}{2}|A_\mu|^2dt &amp;amp; 0 &amp;amp; A_\mu \sqrt{\frac{dt}{2}}\\
A_\mu\sqrt{\frac{dt}{2}} &amp;amp; \frac{1}{\sqrt{2}} &amp;amp; \frac{1-\frac{1}{2}|A_\mu|^2dt}{\sqrt{2}}\\
A_\mu\sqrt{2} &amp;amp; -\frac{1}{\sqrt{2}} &amp;amp; \frac{1-\frac{1}{2}|A_\mu|^2dt}{\sqrt{2}}
\end{array}\right]
\left(\begin{array}{c} \hat{M}_0 \\ \hat{M}_\mu \\ 0 \end{array}\right).
\end{align}\]&lt;/span&gt; The form of Lindblad eqution and the stochastic Schrodinger equation will be the same as before&lt;a href=&quot;#Wiseman1993Interpretation&quot;&gt; [6]&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You may ask could the sampling process have any statistical distribution types other than the uniform random distribution? Indeed, the stochastic interval &lt;span class=&quot;math&quot;&gt;\(dN_\mu(t)\)&lt;/span&gt; can have different statistical distribution modes. In either homodyne or heterodyne measurements with a local oscillator at a frequency the same as or different from the signal merged at a beam splitter&lt;a href=&quot;#Wiseman1993Interpretation&quot;&gt; [6]&lt;/a&gt;, the local oscillator injects noise to the measurement result and affects the quantum dynamics in the process of continuous measurements. Roughly speaking, we may be able to formally rewrite the stochastic interval in the following form, &lt;span class=&quot;math&quot;&gt;\[\begin{equation}
dN_\mu (t) = &amp;lt;dN_\mu(t)&amp;gt; + \sigma_\mu \delta W_\mu(t),
\end{equation}\]&lt;/span&gt; where the first part &lt;span class=&quot;math&quot;&gt;\(&amp;lt;dN_\mu(t)&amp;gt;\)&lt;/span&gt; is the mean value of stochastic interval, &lt;span class=&quot;math&quot;&gt;\(\sigma_\mu\)&lt;/span&gt; is the variance, and &lt;span class=&quot;math&quot;&gt;\(\delta W_\mu(t)\)&lt;/span&gt; is the Weiner stochastic variable. In our case, &lt;span class=&quot;math&quot;&gt;\(&amp;lt;dN_\mu(t)&amp;gt;\)&lt;/span&gt; is proportional to the intensity of the input modes, and the variance of the signals can be determined by the square root of the photon number in the interaction time interval for a coherent light. Given a relatively strong local oscillator, the noise generated obeys the central limit law and will be a Gaussian noise. Therefore, &lt;span class=&quot;math&quot;&gt;\(\delta W_\mu(t)\)&lt;/span&gt; will be a Brownian diffusion random variable in a Gaussian distribution which gives a white noise. Later, we will use &lt;span class=&quot;math&quot;&gt;\(dW(t)\)&lt;/span&gt; to characterize the stochastic process for the normalized stochastic variable with various distribution modes. We will see the stochastic viable will eventually extend the commonly seen time-homogeneous quantum evolution to a broader spectrum of scenarios in the next part of the notes.&lt;/p&gt;
&lt;p&gt;If you want to modify a quantum dynamics simulation code–either using Monte Carlo method or other algorithms–which only involves homogeneously distributed random variable to a general stochastic processes, what you need to do is to bring in a stochastic variable &lt;span class=&quot;math&quot;&gt;\(dW(t)\)&lt;/span&gt; with other statistical distributions and find a proper integration method to solve the differential equations. Using the homodyne detection case, for instance, you can define &lt;span class=&quot;math&quot;&gt;\(dt\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(dW(t)\)&lt;/span&gt; in a time list &lt;span class=&quot;math&quot;&gt;\(t\)&lt;/span&gt; as below.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;In [1]:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class=&quot;sourceCode julia&quot;&gt;&lt;code class=&quot;sourceCode julia&quot;&gt;tmin = &lt;span class=&quot;fl&quot;&gt;0&lt;/span&gt;.;
tmax = &lt;span class=&quot;fl&quot;&gt;10.0&lt;/span&gt;;
step = &lt;span class=&quot;fl&quot;&gt;100&lt;/span&gt;;
t = linspace(tmin,tmax,step);
dt = t[&lt;span class=&quot;fl&quot;&gt;2&lt;/span&gt;]-t[&lt;span class=&quot;fl&quot;&gt;1&lt;/span&gt;];
dW = randn(step).*dt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The variable &lt;code&gt;dW&lt;/code&gt; is now a list of Gaussian/normally distributed numbers with mean &lt;span class=&quot;math&quot;&gt;\(0\)&lt;/span&gt; and standard deviation &lt;span class=&quot;math&quot;&gt;\(1\)&lt;/span&gt; with the same length as &lt;code&gt;t&lt;/code&gt;, and &lt;code&gt;dt&lt;/code&gt; is a constant for all time steps. Easy peasy, right?&lt;/p&gt;
&lt;h2 id=&quot;wrap-up-for-this-part&quot;&gt;Wrap up for this part&lt;/h2&gt;
&lt;p&gt;In this part of notes, we have revisited the quantum dynamics problems that has been widely taught in undergraduate level quantum mechanics classes but in a stochastic process perspective in the end. In general, the stochastic process reflects one important nature of quantum systems and will lead to a rich church of differential equations that our JuliaQuantum libraries would want to include, and I will illustrate more on their forms in the next part. The leftover practical task for solving stochastic equations is to implementing various solvers or integrating algorithms. There are two well-known stochastic integrals–&lt;a href=&quot;https://en.wikipedia.org/wiki/It%C3%B4_calculus&quot;&gt;Itô integral&lt;/a&gt; and &lt;a href=&quot;https://en.wikipedia.org/wiki/Stratonovich_integral&quot;&gt;Stratonovich integral&lt;/a&gt;. More details of the general form of stochastic differential equations and integration methods can be found in &lt;a href=&quot;#Gardiner2004Quantum&quot;&gt; [7]&lt;/a&gt; and other modern books. I will not write too much on those details, but rather give you a big picture on the connected fields.&lt;/p&gt;
&lt;p&gt;On the other hand, quantum simulation packages like the &lt;em&gt;Quantum Optics Toolbox in Matlab&lt;/em&gt;&lt;a href=&quot;#Tan1999Computational&quot;&gt; [8]&lt;/a&gt; and its Python version &lt;em&gt;QuTiP&lt;/em&gt;&lt;a href=&quot;#Johansson2013Qutip&quot;&gt; [9]&lt;/a&gt; becomes widely used while the input quantities can be classified into a few object classes is mainly due to the mathematical fact that the quantum dynamics equations and quantum systems those toolboxes can simulate all have nice mathematical structures. For example, a lot of quantum dynamics problems can be described by the Lindblad form of master equations, which in the end is completely positive maps (CP-maps) and can be fully characterized by the hierarchy of complete positive operators and superoperators as mathematical objects&lt;a href=&quot;#fn5&quot; class=&quot;footnoteRef&quot; id=&quot;fnref5&quot;&gt;&lt;sup&gt;5&lt;/sup&gt;&lt;/a&gt;. To my perspective, the existing JuliaQuantum libraries can be improved by extending its representation types to the operator and superoperator system and build more general solvers to cover the stochastic equations, and we can make better program libraries with in-depth mathematical insights and high-performance programming language. I will also touch the base of some mathematical fundation in the next part.&lt;/p&gt;
&lt;p&gt;With the basic stochastic language introduced, we are ready to explore more complicated differential equations and start appreciating the nature of quantum measurements and how all of these can be connected to the quantum circuit model. Content is mainly based on my hand-written lecture notes taught by my supervisor &lt;a href=&quot;https://cquic.unm.edu/deutsch-group/&quot;&gt;Ivan Deutsch&lt;/a&gt; and my daily journals on reading, meeting and playing. I hope the following notes can help understand those content intuitively.&lt;/p&gt;
&lt;h2 id=&quot;references&quot;&gt;References&lt;/h2&gt;
&lt;ol class=&quot;bibliography&quot; reversed=&quot;reversed&quot;&gt;&lt;li&gt;&lt;!----&gt;
&lt;p&gt;&lt;span id=&quot;Dum1992Monte&quot;&gt;R. Dum, A. S. Parkins, P. Zoller, and C. W. Gardiner, &lt;i&gt;Monte Carlo simulation of master equations in quantum optics for vacuum, thermal, and squeezed reservoirs&lt;/i&gt;, Physical Review A &lt;b&gt;46&lt;/b&gt;, 4382 (1992).&lt;/span&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;div id=&quot;Dum1992Monte-materials&quot;&gt;
&lt;ul class=&quot;nav nav-pills&quot; style=&quot;margin-top:-34px&quot;&gt;

&lt;li&gt;
&lt;a data-toggle=&quot;collapse&quot; href=&quot;#Dum1992Monte-bibtex&quot;&gt;BibTeX&lt;/a&gt;
&lt;/li&gt;




&lt;!----&gt;

&lt;/ul&gt;

&lt;pre id=&quot;Dum1992Monte-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Dum1992Monte,
  title = {Monte Carlo simulation of master equations in quantum optics for vacuum, thermal, and squeezed reservoirs},
  author = {Dum, R and Parkins, AS and Zoller, P and Gardiner, CW},
  journal = {Physical Review A},
  volume = {46},
  number = {7},
  pages = {4382},
  year = {1992},
  publisher = {APS}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;!----&gt;
&lt;p&gt;&lt;span id=&quot;Molmer1993Monte&quot;&gt;K. Mølmer, Y. Castin, and J. Dalibard, &lt;i&gt;Monte Carlo wave-function method in quantum optics&lt;/i&gt;, JOSA B &lt;b&gt;10&lt;/b&gt;, 524 (1993).&lt;/span&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;div id=&quot;Molmer1993Monte-materials&quot;&gt;
&lt;ul class=&quot;nav nav-pills&quot; style=&quot;margin-top:-34px&quot;&gt;

&lt;li&gt;
&lt;a data-toggle=&quot;collapse&quot; href=&quot;#Molmer1993Monte-bibtex&quot;&gt;BibTeX&lt;/a&gt;
&lt;/li&gt;




&lt;!----&gt;

&lt;/ul&gt;

&lt;pre id=&quot;Molmer1993Monte-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Molmer1993Monte,
  title = {Monte Carlo wave-function method in quantum optics},
  author = {M{\o}lmer, Klaus and Castin, Yvan and Dalibard, Jean},
  journal = {JOSA B},
  volume = {10},
  number = {3},
  pages = {524--538},
  year = {1993},
  publisher = {Optical Society of America}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;!----&gt;
&lt;p&gt;&lt;span id=&quot;Molmer1996Monte&quot;&gt;K. Mølmer and Y. Castin, &lt;i&gt;Monte Carlo wavefunctions in quantum optics&lt;/i&gt;, Quantum and Semiclassical Optics: Journal of the European Optical Society Part B &lt;b&gt;8&lt;/b&gt;, 49 (1996).&lt;/span&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;div id=&quot;Molmer1996Monte-materials&quot;&gt;
&lt;ul class=&quot;nav nav-pills&quot; style=&quot;margin-top:-34px&quot;&gt;

&lt;li&gt;
&lt;a data-toggle=&quot;collapse&quot; href=&quot;#Molmer1996Monte-bibtex&quot;&gt;BibTeX&lt;/a&gt;
&lt;/li&gt;




&lt;!----&gt;

&lt;/ul&gt;

&lt;pre id=&quot;Molmer1996Monte-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Molmer1996Monte,
  title = {Monte Carlo wavefunctions in quantum optics},
  author = {M{\o}lmer, Klaus and Castin, Yvan},
  journal = {Quantum and Semiclassical Optics: Journal of the European Optical Society Part B},
  volume = {8},
  number = {1},
  pages = {49},
  year = {1996},
  publisher = {IOP Publishing}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;!----&gt;
&lt;p&gt;&lt;span id=&quot;Plenio1998Quantum&quot;&gt;M. B. Plenio and P. L. Knight, &lt;i&gt;The quantum-jump approach to dissipative dynamics in quantum optics&lt;/i&gt;, Reviews of Modern Physics &lt;b&gt;70&lt;/b&gt;, 101 (1998).&lt;/span&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;div id=&quot;Plenio1998Quantum-materials&quot;&gt;
&lt;ul class=&quot;nav nav-pills&quot; style=&quot;margin-top:-34px&quot;&gt;

&lt;li&gt;
&lt;a data-toggle=&quot;collapse&quot; href=&quot;#Plenio1998Quantum-bibtex&quot;&gt;BibTeX&lt;/a&gt;
&lt;/li&gt;




&lt;!----&gt;

&lt;/ul&gt;

&lt;pre id=&quot;Plenio1998Quantum-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Plenio1998Quantum,
  title = {The quantum-jump approach to dissipative dynamics in quantum optics},
  author = {Plenio, MB and Knight, PL},
  journal = {Reviews of Modern Physics},
  volume = {70},
  number = {1},
  pages = {101},
  year = {1998},
  publisher = {APS}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;!----&gt;
&lt;p&gt;&lt;span id=&quot;Gardiner1985Handbook&quot;&gt;C. W. Gardiner, &lt;i&gt;Handbook of Stochastic Methods&lt;/i&gt;, 2nd ed. (Springer Berlin, 1985).&lt;/span&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;div id=&quot;Gardiner1985Handbook-materials&quot;&gt;
&lt;ul class=&quot;nav nav-pills&quot; style=&quot;margin-top:-34px&quot;&gt;

&lt;li&gt;
&lt;a data-toggle=&quot;collapse&quot; href=&quot;#Gardiner1985Handbook-bibtex&quot;&gt;BibTeX&lt;/a&gt;
&lt;/li&gt;




&lt;!----&gt;

&lt;/ul&gt;

&lt;pre id=&quot;Gardiner1985Handbook-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@book{Gardiner1985Handbook,
  title = {Handbook of stochastic methods},
  author = {Gardiner, Crispin W},
  edition = {2nd},
  year = {1985},
  publisher = {Springer Berlin}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;!----&gt;
&lt;p&gt;&lt;span id=&quot;Wiseman1993Interpretation&quot;&gt;H. M. Wiseman and G. J. Milburn, &lt;i&gt;Interpretation of quantum jump and diffusion processes illustrated on the Bloch sphere&lt;/i&gt;, Phys. Rev. A &lt;b&gt;47&lt;/b&gt;, 1652 (1993).&lt;/span&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;div id=&quot;Wiseman1993Interpretation-materials&quot;&gt;
&lt;ul class=&quot;nav nav-pills&quot; style=&quot;margin-top:-34px&quot;&gt;

&lt;li&gt;
&lt;a data-toggle=&quot;collapse&quot; href=&quot;#Wiseman1993Interpretation-bibtex&quot;&gt;BibTeX&lt;/a&gt;
&lt;/li&gt;

&lt;li&gt;
&lt;a href=&quot;https://dx.doi.org/10.1103/PhysRevA.47.1652&quot; target=&quot;_blank&quot;&gt;Link&lt;/a&gt;
&lt;/li&gt;



&lt;!----&gt;

&lt;/ul&gt;

&lt;pre id=&quot;Wiseman1993Interpretation-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Wiseman1993Interpretation,
  title = {Interpretation of quantum jump and diffusion processes illustrated on the Bloch sphere},
  author = {Wiseman, H. M. and Milburn, G. J.},
  journal = {Phys. Rev. A},
  volume = {47},
  issue = {3},
  pages = {1652--1666},
  numpages = {0},
  year = {1993},
  month = mar,
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevA.47.1652},
  url = {http://link.aps.org/doi/10.1103/PhysRevA.47.1652}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;!----&gt;
&lt;p&gt;&lt;span id=&quot;Gardiner2004Quantum&quot;&gt;C. Gardiner and P. Zoller, &lt;i&gt;Quantum Noise: a Handbook of Markovian and Non-Markovian Quantum Stochastic Methods with Applications to Quantum Optics&lt;/i&gt; (Springer Science &amp;amp; Business Media, 2004).&lt;/span&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;div id=&quot;Gardiner2004Quantum-materials&quot;&gt;
&lt;ul class=&quot;nav nav-pills&quot; style=&quot;margin-top:-34px&quot;&gt;

&lt;li&gt;
&lt;a data-toggle=&quot;collapse&quot; href=&quot;#Gardiner2004Quantum-bibtex&quot;&gt;BibTeX&lt;/a&gt;
&lt;/li&gt;




&lt;!----&gt;

&lt;/ul&gt;

&lt;pre id=&quot;Gardiner2004Quantum-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@book{Gardiner2004Quantum,
  title = {Quantum noise: a handbook of Markovian and non-Markovian quantum stochastic methods with applications to quantum optics},
  author = {Gardiner, Crispin and Zoller, Peter},
  volume = {56},
  year = {2004},
  publisher = {Springer Science \&amp; Business Media}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;!----&gt;
&lt;p&gt;&lt;span id=&quot;Tan1999Computational&quot;&gt;S. M. Tan, &lt;i&gt;A computational toolbox for quantum and atomic optics&lt;/i&gt;, Journal of Optics B: Quantum and Semiclassical Optics &lt;b&gt;1&lt;/b&gt;, 424 (1999).&lt;/span&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;div id=&quot;Tan1999Computational-materials&quot;&gt;
&lt;ul class=&quot;nav nav-pills&quot; style=&quot;margin-top:-34px&quot;&gt;

&lt;li&gt;
&lt;a data-toggle=&quot;collapse&quot; href=&quot;#Tan1999Computational-bibtex&quot;&gt;BibTeX&lt;/a&gt;
&lt;/li&gt;




&lt;!----&gt;

&lt;/ul&gt;

&lt;pre id=&quot;Tan1999Computational-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Tan1999Computational,
  title = {A computational toolbox for quantum and atomic optics},
  author = {Tan, Sze M},
  journal = {Journal of Optics B: Quantum and Semiclassical Optics},
  volume = {1},
  number = {4},
  pages = {424},
  year = {1999},
  publisher = {IOP Publishing}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;
&lt;li&gt;&lt;!----&gt;
&lt;p&gt;&lt;span id=&quot;Johansson2013Qutip&quot;&gt;J. R. Johansson, P. D. Nation, and F. Nori, &lt;i&gt;QuTiP 2: A Python framework for the dynamics of open quantum systems&lt;/i&gt;, Computer Physics Communications &lt;b&gt;184&lt;/b&gt;, 1234 (2013).&lt;/span&gt;&lt;/p&gt;
&lt;br /&gt;
&lt;div id=&quot;Johansson2013Qutip-materials&quot;&gt;
&lt;ul class=&quot;nav nav-pills&quot; style=&quot;margin-top:-34px&quot;&gt;

&lt;li&gt;
&lt;a data-toggle=&quot;collapse&quot; href=&quot;#Johansson2013Qutip-bibtex&quot;&gt;BibTeX&lt;/a&gt;
&lt;/li&gt;




&lt;!----&gt;

&lt;/ul&gt;

&lt;pre id=&quot;Johansson2013Qutip-bibtex&quot; class=&quot;pre pre-scrollable collapse&quot;&gt;@article{Johansson2013Qutip,
  title = {QuTiP 2: A Python framework for the dynamics of open quantum systems},
  author = {Johansson, JR and Nation, PD and Nori, Franco},
  journal = {Computer Physics Communications},
  volume = {184},
  number = {4},
  pages = {1234--1240},
  year = {2013},
  publisher = {Elsevier}
}
&lt;/pre&gt;
&lt;/div&gt;
&lt;/li&gt;&lt;/ol&gt;

&lt;div class=&quot;references&quot;&gt;
&lt;h2&gt;Footnotes&lt;/h2&gt;
&lt;/div&gt;
&lt;section class=&quot;footnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot;&gt;&lt;p&gt;If you only know quantum operators, superoperators are just another layer of operations on operators. Superoperator notations have been widely used to describe the evolution of open quantum systems where the concept of propagator can be fully characterized.&lt;a href=&quot;#fnref1&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn2&quot;&gt;&lt;p&gt;For mixed states, the state of the system cannot be written as a signle pure state, &lt;span class=&quot;math&quot;&gt;\(\ket{\Psi}\)&lt;/span&gt; any more, in general. Instead, a density operator &lt;span class=&quot;math&quot;&gt;\(\hat{\rho}=\sum_i p_i\ketbra{\Psi_i}{\Psi_i}\)&lt;/span&gt; as an ensemble decomposition of pure states, &lt;span class=&quot;math&quot;&gt;\(\ket{\Psi_i}\)&lt;/span&gt;, is used to characterize the system, where &lt;span class=&quot;math&quot;&gt;\(p_i\)&lt;/span&gt; is the probability of being in the &lt;span class=&quot;math&quot;&gt;\(\ket{\Psi_i}\)&lt;/span&gt; state.&lt;a href=&quot;#fnref2&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn3&quot;&gt;&lt;p&gt;Also see the &lt;a href=&quot;https://en.wikipedia.org/wiki/Quantum_stochastic_calculus&quot;&gt;Quantum stochastic calculus&lt;/a&gt; page for a quick review created by &lt;a href=&quot;https://www.unm.edu/~jagross/&quot;&gt;Jonathan Gross&lt;/a&gt; for a &lt;a href=&quot;https://iciq.github.io/entangle/WikipediaProject.html&quot;&gt;Quantum Optics wikipedia project&lt;/a&gt;.&lt;a href=&quot;#fnref3&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn4&quot;&gt;&lt;p&gt;We will use this fact in my future notes on deriving quantum dynamic equations symbolically for general scenarios.&lt;a href=&quot;#fnref4&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn5&quot;&gt;&lt;p&gt;A brief summary on the relation between Lindblad equations and CP-map can be found in &lt;a href=&quot;http://blog.jessriedel.com/2014/07/26/lindblad-equation-is-differential-form-of-cp-map/&quot;&gt;Jess Riedel’s blog&lt;/a&gt;.&lt;a href=&quot;#fnref5&quot;&gt;↩&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;
</content>
 </entry>
 
 <entry>
   <title>NVidia Linux driver update fixed the openGL problem of Matlab 2016a</title>
   <link href="https://www.qixiaodong.tk/en/2016/06/23/nvidia-driver-update-for-matlab-2016a.html"/>
   <updated>2016-06-23T00:00:00+00:00</updated>
   <id>/2016/06/23/nvidia-driver-update-for-matlab-2016a</id>
   <content type="html">&lt;p&gt;When the Matlab 2016a was released initially, the &lt;a href=&quot;//askubuntu.com/questions/765455/how-to-run-matlab-2016a-with-nvidia-drivers-of-gtx-960-in-ubuntu-16-04&quot;&gt;openGL render was not compatible with some NVidia drivers in Linux&lt;/a&gt;. Recently, I have noticed that the last update of NVidia-367 driver has fixed this problem.&lt;/p&gt;
&lt;p&gt;To install the nvidia-367 driver in Ubuntu 16.04, you need to uninstall the previous nvidia driver first:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt purge nvidia*&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;followed by a reboot of your computer.&lt;/p&gt;
&lt;p&gt;Then install the new driver by adding the ppa and retrieving the package from the repo.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo add-apt-repository ppa:graphics-drivers/ppa
sudo apt update
sudo apt install NVidia-367&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After a successful reboot, you should see the new driver has been added to your module list.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;lsmod | grep nvidia&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Matlab should work smoothly now with a better graphics render. On my laptop, I got the following information in the Matlab command line window:&lt;/p&gt;
&lt;pre class=&quot;sourceCode Matlab&quot;&gt;&lt;code class=&quot;sourceCode matlab&quot;&gt;&amp;gt;&amp;gt; opengl info
                          Version: &lt;span class=&quot;st&quot;&gt;&amp;#39;4.5.0 NVIDIA 367.27&amp;#39;&lt;/span&gt;
                           Vendor: &lt;span class=&quot;st&quot;&gt;&amp;#39;NVIDIA Corporation&amp;#39;&lt;/span&gt;
                         Renderer: &lt;span class=&quot;st&quot;&gt;&amp;#39;Quadro M1000M/PCIe/SSE2&amp;#39;&lt;/span&gt;
                   MaxTextureSize: &lt;span class=&quot;fl&quot;&gt;16384&lt;/span&gt;
                           Visual: &lt;span class=&quot;st&quot;&gt;&amp;#39;Visual 0x70, (RGBA 32 bits (8 8 8 8), Z depth 16 bits…&amp;#39;&lt;/span&gt;
                         Software: &lt;span class=&quot;st&quot;&gt;&amp;#39;false&amp;#39;&lt;/span&gt;
             HardwareSupportLevel: &lt;span class=&quot;st&quot;&gt;&amp;#39;full&amp;#39;&lt;/span&gt;
        SupportsGraphicsSmoothing: &lt;span class=&quot;fl&quot;&gt;1&lt;/span&gt;
    SupportsDepthPeelTransparency: &lt;span class=&quot;fl&quot;&gt;1&lt;/span&gt;
       SupportsAlignVertexCenters: &lt;span class=&quot;fl&quot;&gt;1&lt;/span&gt;
                       Extensions: {&lt;span class=&quot;fl&quot;&gt;330&lt;/span&gt;x1 cell}
               MaxFrameBufferSize: &lt;span class=&quot;fl&quot;&gt;16384&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This was tested working on my Lenovo Thinkpad P50 mobile workstation with Quadro M1000M GPU and Linux kernels 4.5.2 and 4.4.22. Kernel 4.6.0 was not compatible with some latest nvidia drivers before this update, and I haven’t got a chance to try again.&lt;/p&gt;
&lt;p&gt;You may want to remove the graphics driver ppa after this update to prevent new updates of the driver which may screw up your software environment in the future.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>2016 summer study on selected topics in Quantum Optics</title>
   <link href="https://www.qixiaodong.tk/en/2016/05/26/2016-summer-study-on-quantum-optics-II.html"/>
   <updated>2016-05-26T00:00:00+00:00</updated>
   <id>/2016/05/26/2016-summer-study-on-quantum-optics-II</id>
   <content type="html">&lt;p&gt;As usual, I will organize/participate a summer study this year. Since there are a lot of things going on this summer and &lt;a href=&quot;http://cquic.unm.edu/deutsch-group/&quot;&gt;Prof. Ivan Deutsch&lt;/a&gt; here in UNM is actually hosting review sessions on Quantum Optics I this summer, I was thinking to have the following focus for my self-organized summer study:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Title: Advanced Topics in Quantum Optics (II)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;(Yeah, we have tagged part I &lt;a href=&quot;//iciq.github.io/entangle/QuantumOpticsGroup.html&quot;&gt;two years before&lt;/a&gt; already.)&lt;/p&gt;
&lt;center&gt;
&lt;div class=&quot;row&quot;&gt;
&lt;figure&gt;
&lt;img src=&quot;//media.wiley.com/product_data/coverImage300/73/35274070/3527407073.jpg&quot;  scale=&quot;95%&quot;    align=&quot;center&quot; alt=&quot;optical pumping and laser cooling&quot;   /&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;/center&gt;
  
&lt;p&gt;&lt;br&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Main topics:
&lt;ul&gt;
&lt;li&gt;Optical pumping&lt;/li&gt;
&lt;li&gt;Laser cooling&lt;/li&gt;
&lt;li&gt;matrix/tensor product state representation of many-body systems (let’s see if time permits)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Time slot: From June 1st to July 29th. Detailed schedule to be updated.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;Main references:
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://info.phys.unm.edu/~ideutsch/Classes/Phys566F15/index.htm&quot;&gt;Quantum Optics I by Prof. Ivan Deutsch&lt;/a&gt; (lecture videos, notes and homeworks are all available in the link).&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://info.phys.unm.edu/~ideutsch/Classes/Phys531F11/index.htm&quot;&gt;Atomic Physics course by Prof. Ivan Deutsch&lt;/a&gt; (lecture videos, notes and homeworks are all available in the link).&lt;/li&gt;
&lt;li&gt;A book, if you wish, as shown in the photo above by our friend &lt;a href=&quot;http://cquic.unm.edu/member/yuan.yu.jau/&quot;&gt;Yuan-Yu Jau&lt;/a&gt; and others on Optical Pumping featured with simulation demo codes and detailed analysis.&lt;/li&gt;
&lt;li&gt;A handful of classical papers to be updated here later.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Discussion forum: &lt;a href=&quot;https://disqus.com/home/channel/quantumoptics&quot;&gt;see this channel&lt;/a&gt; I created recently.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The plan is to visit or revisit those lectures and do some homeworks and derivations, and reproduce some known results published in some reference papers. I may do some programming in Julia using our preliminary &lt;a href=&quot;//juliaquantum.github.io&quot;&gt;JuliaQuantum libraries&lt;/a&gt;, which is good to me since I will meet with Nik from Stanford in June to share our experiences on symbolic computing and simulating quantum control related stuffs in Julia, and then meet with our core JuliaQuantum developer Amir and a tensor network guru Jutho from Ghent to discuss some efficient ways to handle quantum objects in Julia. I hope some good ideas can be further transferred to the code base of the JuliaQuantum libraries under construction.&lt;/p&gt;
&lt;p&gt;If you are interested in taking this challenge and fun study opportunity, feel free to contact me or comment below. Thanks!&lt;/p&gt;
&lt;h1 id=&quot;schedule-and-progress&quot;&gt;Schedule and progress&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;[X] June 1st-5th:
&lt;ul&gt;
&lt;li&gt;[X] From Ivan’s QO lectures: Coherence, density matrix, Bloch-sphere, Rabi oscillations. Lecture notes #4-6, P.S. #2-4; Optical Bloch equations, Master equation, Damped two-level atom. Lecture notes #7-8, P.S. #5-6.&lt;/li&gt;
&lt;li&gt;[X] From Yuan-Yu’s book: chapters 1-5 (Alkali atoms, wavefunction, Schrodinger space, density matrix, Liouville space, optical pumping of atoms).&lt;/li&gt;
&lt;li&gt;[X] Get familiar with JuliaQuantum libraries: &lt;a href=&quot;https://github.com/JuliaQuantum/QuBase.jl&quot;&gt;QuBase.jl&lt;/a&gt;, &lt;a href=&quot;https://github.com/JuliaQuantum/QuDirac.jl&quot;&gt;QuDirac.jl&lt;/a&gt; and &lt;a href=&quot;https://github.com/JuliaQuantum/QuDynamics.jl&quot;&gt;QuDynamics.jl&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[X] June 6th-12th:
&lt;ul&gt;
&lt;li&gt;[X] From Ivan’s QO lectures: Quantization of the field, atoms+quantized field. Lecture notes #11-13, P.S. #7;&lt;/li&gt;
&lt;li&gt;[X] From Ivan’s AP lectures: notes 10-13.&lt;/li&gt;
&lt;li&gt;[X] From Yuan-Yu’s book: chapters 6-9.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;[X] Skip June 13th-19th for more research work to be done. Then from June 20th-26th:
&lt;ul&gt;
&lt;li&gt;[X] Wrap up on Yuan-Yu’s book.&lt;/li&gt;
&lt;li&gt;[X] A blog post on some essential points. See &lt;a href=&quot;https://www.qixiaodong.tk/2016/07/23/put-everything-on-a-quantum-circuit-part-i.html&quot;&gt;this one&lt;/a&gt; and more to come.&lt;/li&gt;
&lt;li&gt;[X] Discuss with Nikolas as our visitor on symbolic calculus and quantum simulations in Julia.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A side note: I have to skip a month for preparing the workshop/conference and JuliaQuantum activities. Writing notes took much more time than I had expected as there were some Jekyll and plugin problems I had to solve on the first time. I will skip the topic on cooling processes for this summer study and will pick up a little bit on matrix product states before July 29th and will write some notes and discuss some important topics with JuliaQuantum members in the coming weeks. So, no further plan for the rest of summer study. Sorry about that. Please continue on if you are willing to learn more.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>SQuInT Workshop 2016</title>
   <link href="https://www.qixiaodong.tk/en/2016/02/17/SQuInT-workshop-2016.html"/>
   <updated>2016-02-17T00:00:00+00:00</updated>
   <id>/2016/02/17/SQuInT-workshop-2016</id>
   <content type="html">&lt;p&gt;I am going to present our recent work in &lt;a href=&quot;http://physics.unm.edu/SQuInT/2016/index.php&quot;&gt;the 18th SQuInT Workshop&lt;/a&gt; at Albuquerque, NM, USA. Below you can find my poster.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.qixiaodong.tk/assets/posters/SQuInT2016-Nanofiber.pdf&quot;&gt;Link to the PDF&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;abstract&quot;&gt;Abstract:&lt;/h2&gt;
&lt;p&gt;While optical fibers have been used for primary quantum communications, atom-fiber and atom-waveguide based quantum interfaces have been proposed as effective elements to implement a broad range of quantum information processing applications. We study the strong coupling between photons and atoms that can be achieved in an optical nanofiber geometry when the interaction is dispersive. While the Purcell enhancement factor for spontaneous emission into the guided mode does not reach the strong-coupling regime for individual atoms, one can obtain high cooperativity for ensembles of a few thousand atoms due to the tight confinement of the guided modes and constructive interference over the entire chain of trapped atoms. We studied the theory of the phase shift and polarization rotation induced on the guided light by the trapped atoms using the dyadic Green’s function method. The Green’s function is related to a full Heisenberg-Langevin treatment of the dispersive response of the quantized field to tensor polarizable atoms. In this talk, I will illustrate how do we apply our formalism to quantum nondemolition (QND) measurement of the atoms via polarimetry. We study shot-noise-limited detection of atom number for atoms in a completely mixed spin state and the squeezing of projection noise for atoms in clock states. Compared with squeezing of atomic ensembles in free space, we capitalize on unique features that arise in the nanofiber geometry including anisotropy of both the intensity and polarization of the guided modes. We use a first principles stochastic master equation to model the squeezing as function of time in the presence of decoherence due to optical pumping. We find a peak metrological squeezing of ~5 dB is achievable with current technology for ~2500 atoms. The theory established can be used to guide the design of nanofiber- or waveguide-based quantum interfaces.&lt;/p&gt;
&lt;h2 id=&quot;note&quot;&gt;Note:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;There are some researchers contacted me and my supervisor before the workshop for some chat, and hence the chat time over the poster session may be limited. But if you are interested in my poster, we can talk about it at any break time during the workshop.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Since I am also serving for a few other duties recently, this poster was made in a hurry and was not well organized in a normal order. You may want to talk to me or contact me if you find an error or anywhere confusing.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;More details can be found in our publication: &lt;a href=&quot;https://journals.aps.org/pra/abstract/10.1103/PhysRevA.93.023817&quot;&gt;X. Qi, B. Q. Baragiola, P. S. Jessen, and I. H. Deutsch, Phys. Rev. A 93, 023817 (2016)&lt;/a&gt;. ArXiv online: &lt;a href=&quot;https://arxiv.org/abs/1509.02625&quot;&gt;https://arxiv.org/abs/1509.02625&lt;/a&gt;. The full title is &lt;strong&gt;&lt;em&gt;Dispersive response of atoms trapped near the surface of an optical nanofiber with applications to quantum nondemolition measurement and spin squeezing&lt;/em&gt;&lt;/strong&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Thanks for your interest, and hopefully see you in SQuInT!&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Step 7 - Automate the tests</title>
   <link href="https://www.qixiaodong.tk/en/2015/05/29/automate_tests.html"/>
   <updated>2015-05-29T00:00:00+00:00</updated>
   <id>/2015/05/29/automate_tests</id>
   <content type="html">&lt;p&gt;Welcome to step 7 in &lt;a href=&quot;/2015/05/10/rock_solid_code.html&quot;&gt;your training as a scientific Python code ninja&lt;/a&gt;: &lt;strong&gt;test automation&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Tests are extremely useful, as long as you run them. Unfortunately, a common pattern in many projects is this:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Tests are written and run by the person who wrote them.&lt;/li&gt;
&lt;li&gt;Others, and even the test-writer at a future date, forget to run the tests before committing new code. Or they decide not to run the tests because they forget how, or they don’t want to wait for the tests to finish.&lt;/li&gt;
&lt;li&gt;The new code breaks the tests. By the time somebody notices, it’s too much trouble to go back and figure out where things went wrong, much less how to fix them.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;How do you avoid this? You make running the tests dead simple and fully automatic. This step is about making the tests run with a single command; step 8 is about having a machine run them whenever you commit code, without any action on your part.&lt;/p&gt;
&lt;p&gt;As a matter of fact, in &lt;a href=&quot;/2015/05/15/write_tests.html&quot;&gt;Step 5&lt;/a&gt; we set things up so that the tests in one file could by run with a single command. But eventually, you will have tests in multiple files. Besides doctests, you may write additional tests. If you need to type 10, or even 3 commands to run them all, there will be a mental barrier and eventually you’ll get lazy.&lt;/p&gt;
&lt;h1 id=&quot;nose&quot;&gt;nose&lt;/h1&gt;
&lt;p&gt;There are a number of test automation tools for Python, but to keep things simple I will focus on the one I know best: &lt;a href=&quot;https://nose.readthedocs.org/en/latest/&quot;&gt;nose&lt;/a&gt;. Nose does one simple thing: it automatically finds all the tests in your project and runs them. How does it know where the tests are? Well, it can easily recognize doctests, and it will also pick up any function whose name contains “test” and that is in file whose name contains “test”.&lt;/p&gt;
&lt;h1 id=&quot;what-to-do&quot;&gt;What to do:&lt;/h1&gt;
&lt;p&gt;As usual, this should only take two minutes.&lt;/p&gt;
&lt;ol start=&quot;0&quot; type=&quot;1&quot;&gt;
&lt;li&gt;In case it isn’t installed already, do &lt;code&gt;pip install nose&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;First, go to your project directory and type &lt;code&gt;nosetests --with-doctest&lt;/code&gt;. The nose executable is named “nosetests” and the option &lt;code&gt;--with-doctest&lt;/code&gt; tells it to also run any doctests it finds. You should get a message saying that some number of tests were run, with an “OK” at the end.&lt;/li&gt;
&lt;li&gt;To see how nosetests becomes really useful, either: (a) add a doctest in another file; or (b) add a file called &lt;code&gt;tests.py&lt;/code&gt; containing at least one function with “test” in the name. The test function should check something and raise an exception if things are wrong. See &lt;a href=&quot;https://github.com/ketch/rock-solid-code-demo/blob/master/tests.py&quot;&gt;this example in my demo project&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Now type &lt;code&gt;nosetests --with-doctest&lt;/code&gt; again. You should see that your new tests were also run. To get more detailed output, try &lt;code&gt;nosetests --with-doctest --vs&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That’s it. Now, if you add more doctests or other tests, you can run them all just by typing &lt;code&gt;nosetests --with-doctest&lt;/code&gt;. That’s the kind of thing you might want to add to your README. Your rule now should be:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Always run the tests before you commit code.&lt;/strong&gt;&lt;/p&gt;
&lt;h4 id=&quot;note-this-post-was-originally-written-by-david-ketcheson-and-posted-at-httpwww.davidketcheson.info20150529automate_tests.html&quot;&gt;Note: this post was originally written by David Ketcheson and posted at &lt;a href=&quot;http://www.davidketcheson.info/2015/05/29/automate_tests.html&quot;&gt;http://www.davidketcheson.info/2015/05/29/automate_tests.html&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;under the &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/deed.en_US&quot;&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Step 6 - Keep track of issues</title>
   <link href="https://www.qixiaodong.tk/en/2015/05/16/track_issues.html"/>
   <updated>2015-05-16T00:00:00+00:00</updated>
   <id>/2015/05/16/track_issues</id>
   <content type="html">&lt;p&gt;Welcome to step 6 in &lt;a href=&quot;/2015/05/10/rock_solid_code.html&quot;&gt;your training as a scientific Python code ninja&lt;/a&gt;: &lt;strong&gt;issue tracking&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Look at you! You’ve got your nice code with some docstrings and tests, and you’re humming along analyzing data, simulating widgets, and whatnot. In the middle of it all, you realize that your regression analysis function breaks if you feed it more than 57 data points. And wouldn’t it be nice if it made a plot in addition to just printing out the correlation coefficient? And it would all be easier to use if your functions had default values for some of their arguments.&lt;/p&gt;
&lt;p&gt;But you can’t stop to (fix that bug)/(add that feature)/(refactor that function) right now – you’re deep in all that beautiful data! Besides, maybe nobody will ever try to use this script with more than 57 data values. What should you do?&lt;/p&gt;
&lt;h2 id=&quot;raise-an-issue.&quot;&gt;Raise an issue.&lt;/h2&gt;
&lt;p&gt;An issue may be:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A bug&lt;/li&gt;
&lt;li&gt;A bit of code that works but needs to be improved&lt;/li&gt;
&lt;li&gt;A potential feature enhancement&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Github – like other code repository services – has a built-in feature for tracking issues. When you raise an issue on your code’s Github repository, awesome things become possible:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You have a reminder to yourself of that thing that needs to be fixed&lt;/li&gt;
&lt;li&gt;Everyone else who uses your code can be aware of it too&lt;/li&gt;
&lt;li&gt;You and they can have a public discussion of what’s wrong and how to fix it (or what could be improved)&lt;/li&gt;
&lt;li&gt;After it’s fixed/improved, you have a permanent record of the discussion and the improvements, that can be seen by anyone&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;With Github’s issue tracker, there’s all kinds of additional goodness: issues are searchable, can reference one another, can reference people, can be tagged/labeled, and more. Check out &lt;a href=&quot;https://guides.github.com/features/issues/&quot;&gt;Github’s 10-minute explanation&lt;/a&gt; to learn all about it.&lt;/p&gt;
&lt;h1 id=&quot;what-to-do&quot;&gt;What to do:&lt;/h1&gt;
&lt;p&gt;As usual, this should only take two minutes.&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Think of at least one or two bugs, potential features, or improvements related to your project code. If you can’t think of any, either you haven’t been using the code much or you’re not thinking very hard.&lt;/li&gt;
&lt;li&gt;Go to your project’s page in Github and click the issues button on the right side: &lt;img src=&quot;/assets/img/github-issues-button.png&quot; /&gt;&lt;/li&gt;
&lt;li&gt;Click that big green “New Issue” button. Give the issue a title and an explanation. If it’s a bug, write down the exact sequence of commands that triggers it.&lt;/li&gt;
&lt;li&gt;Click “Submit new issue”.&lt;/li&gt;
&lt;li&gt;(for the future) When you eventually get around to solving the issue, you can mark it as “Closed”. This doesn’t delete it, but it removes it from the list of “Open” issues.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;You’re now at a page that lists all the issues for your project (presumably there’s just one so far). If you click on an issue, you find a page where you can write further comments and even have a conversation with other developers. If you’ve never seen such a conversation, take a look at some issues for bigger projects like &lt;a href=&quot;https://github.com/ipython/ipython/issues&quot;&gt;IPython&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;the-benefits-of-openness&quot;&gt;The benefits of openness&lt;/h2&gt;
&lt;p&gt;It’s nice that you can keep your reminder list there in the issue tracker, but you may be worried about exposing all the shortcomings of your code in public. Don’t be! It’s much better to have them out in the open than to get surprised by them. In fact, the real magic happens when other people start reporting issues. If other people start using your code, you’ll find that somehow they run into a lot more problems than you do. Why? Because there are all kinds of unstated assumptions in your head that silently went into your code – but your users know nothing about them. So they will stress your code in completely different ways and help you find all sorts of wonderful bugs. They may even fix some of them for you – but that’s another subject. Just remember to be grateful – it’s easy to get your feathers ruffled when someone points out a flaw in your code, but in fact they are doing you a service.&lt;/p&gt;
&lt;p&gt;This goes both ways. Your code almost certainly relies on a host of other projects, many of which are on Github or other servers with an issue tracker. Do you use Pandas, numpy, scipy, or scikit-learn? The next time you run into what might be a bug in those packages, be proactive. Of course you should first check Stack Overflow, but if it seems like a bug to you, you can go raise an issue on the project’s issue tracker. That’s right, anybody in the world can raise an issue – you don’t need to be one of the project developers. Just remember to be polite, and &lt;a href=&quot;http://coenjacobs.me/effective-bug-reports-on-github/&quot;&gt;follow a few best practices&lt;/a&gt; when you report an issue.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ketch/rock-solid-code-demo/issues&quot;&gt;Here’s what the issues page for my demo project looks like&lt;/a&gt; after raising a couple of issues. And &lt;a href=&quot;https://github.com/clawpack/pyclaw/issues&quot;&gt;here’s the issue tracker for a larger collaborative project&lt;/a&gt;. In academic research, I find that I open a lot more issues than I close. That’s okay – the issue tracker is not a to-do list that has to be fully completed at some point. It’s just a way of keeping track of useful improvements that could be made.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/2015/05/29/automate_tests.html&quot;&gt;Continue to step seven&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&quot;note-this-post-was-originally-written-by-david-ketcheson-and-posted-at-httpwww.davidketcheson.info20150516track_issues.html&quot;&gt;Note: this post was originally written by David Ketcheson and posted at &lt;a href=&quot;http://www.davidketcheson.info/2015/05/16/track_issues.html&quot;&gt;http://www.davidketcheson.info/2015/05/16/track_issues.html&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;under the &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/deed.en_US&quot;&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Step 5 - write tests</title>
   <link href="https://www.qixiaodong.tk/en/2015/05/15/write_tests.html"/>
   <updated>2015-05-15T00:00:00+00:00</updated>
   <id>/2015/05/15/write_tests</id>
   <content type="html">&lt;p&gt;This is step 5 in your journey toward &lt;a href=&quot;/2015/05/10/rock_solid_code.html&quot;&gt;rock-solid scientific Python code&lt;/a&gt;: &lt;strong&gt;write tests&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Tests? Ugh.&lt;/p&gt;
&lt;p&gt;I hear you. Writing tests is not an inherently fun process. However, the alternative is debugging, staring at code and thinking real hard about what could be wrong, and more debugging. I’ll take writing tests any day of the week.&lt;/p&gt;
&lt;p&gt;You may still not be convinced. Fortunately, I don’t have to convince you, because I’m not going to ask you to write tests in this step. As a matter of fact, I tricked you into writing tests in step 4. Remember those examples you put in your docstring?&lt;/p&gt;
&lt;p&gt;Yeah, I’m sneaky like that.&lt;/p&gt;
&lt;p&gt;What is a test? It’s a bit of code that uses your project code, together with assertions regarding the output. Here’s how you can use the docstring you wrote as a test:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Go to your project directory and identify the file to which you added one or more docstrings in step 4. We’ll refer to that as &lt;code&gt;my_file.py&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;At the command line (i.e., in a terminal), type &lt;code&gt;python -m doctest -v my_file.py&lt;/code&gt; (but substitute the name of your file).&lt;/li&gt;
&lt;li&gt;Look at the printed output to see if your test(s) passed.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;What just happened? Doctest is a python module that takes all the examples in your docstrings, runs them, and checks whether the output in the docstring matches the actual output. If any of your doctests failed, you should compare the actual output with your docstring and correct things.&lt;/p&gt;
&lt;p&gt;I always forget how to invoke doctest, so I put the following code at the bottom of all my &lt;code&gt;.py&lt;/code&gt; files:&lt;/p&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;__name__&lt;/span&gt; == &lt;span class=&quot;st&quot;&gt;&amp;quot;__main__&amp;quot;&lt;/span&gt;:
    &lt;span class=&quot;ch&quot;&gt;import&lt;/span&gt; doctest
    doctest.testmod()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After adding that, I can just do&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python my_file.py -v&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and it will automatically run the doctests. One warning: if you don’t add the &lt;code&gt;-v&lt;/code&gt; flag (for verbose) on the command line, then there will be no printed output at all unless some test fails. And if you put &lt;code&gt;-v&lt;/code&gt; before your filename, you’ll get something totally different.&lt;/p&gt;
&lt;p&gt;Doctests are certainly not all there is to testing in Python, but for me they are a minimal-effort approach that makes my code much more reliable. If you add a docstring with a doctest to each function and module in your code, you’ll spend a lot less time debugging later on. I bet you’ll also find some bugs as you add the doctests.&lt;/p&gt;
&lt;p&gt;From now on, just make it a habit to add a docstring and a doctest whenever you write a new function. Your future self will thank you.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ketch/rock-solid-code-demo/blob/13ab3f8af4e6be813eaee512897948e4c5a178a7/factor.py&quot;&gt;Here’s what my demo repository looks like at this stage&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/2015/05/16/track_issues.html&quot;&gt;Continue to step six&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&quot;note-this-post-was-originally-written-by-david-ketcheson-and-posted-at-httpwww.davidketcheson.info20150515write_tests.html&quot;&gt;Note: this post was originally written by David Ketcheson and posted at &lt;a href=&quot;http://www.davidketcheson.info/2015/05/15/write_tests.html&quot;&gt;http://www.davidketcheson.info/2015/05/15/write_tests.html&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;under the &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/deed.en_US&quot;&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Step 4 - write docstrings</title>
   <link href="https://www.qixiaodong.tk/en/2015/05/14/write_docstrings.html"/>
   <updated>2015-05-14T00:00:00+00:00</updated>
   <id>/2015/05/14/write_docstrings</id>
   <content type="html">&lt;p&gt;This is step 4 in your journey toward &lt;a href=&quot;/2015/05/10/rock_solid_code.html&quot;&gt;rock-solid scientific Python code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Steps 1-3 were language-agnostic, but now I’m going to assume you’re using Python. The Python language has a built-in feature for documenting functions, classes, and modules; it is the &lt;strong&gt;docstring&lt;/strong&gt;. A docstring for a very simple function looks like this:&lt;/p&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; square(x):
    &lt;span class=&quot;co&quot;&gt;&amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;    Takes a number x and returns x*x.&lt;/span&gt;

&lt;span class=&quot;co&quot;&gt;    Examples:&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;    &amp;gt;&amp;gt;&amp;gt; square(5)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;    25&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;    &amp;gt;&amp;gt;&amp;gt; square(2)&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;    4&lt;/span&gt;
&lt;span class=&quot;co&quot;&gt;    &amp;quot;&amp;quot;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;kw&quot;&gt;return&lt;/span&gt; x*x&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The docstring is, of course, the part inside the triple quotes. If you type a function name followed by a “?” at the Python interpreter (or in a Jupyter notebook):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; my_function?&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;then Python shows you the docstring for the function. If you’ve ever tried to get help on a function that had no docstring, you know the dark feeling of despair that attends such a moment. Don’t let your code be that code. Write docstrings!&lt;/p&gt;
&lt;p&gt;For a somewhat longer docstring, see &lt;a href=&quot;https://github.com/ketch/rock-solid-code-demo/blob/master/factor.py&quot;&gt;my Gaussian elimination example&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;What should go in a docstring? Obviously, you should describe the arguments to the function and values returned by the function. But usually the most useful part of a docstring is examples. I’ll repeat that, because it’s important:&lt;/p&gt;
&lt;h2 id=&quot;examples-are-the-most-useful-part-of-a-docstring.&quot;&gt;Examples are the most useful part of a docstring.&lt;/h2&gt;
&lt;p&gt;Why? Often, the docstring written by the person who wrote the code includes a bunch of stuff that mattered when writing the code, but isn’t really important when using the code. Examples show precisely what you need to know to use the code.&lt;/p&gt;
&lt;p&gt;Each example should show the function being called and its arguments, as well as the output. You should format your examples like those above, using “&amp;gt;&amp;gt;&amp;gt;” before the input and putting the output on the next line. This is helpful not only because users are used to the convention, but because as we’ll see later it allows the computer to automatically run your examples and check that they give the expected outputs!&lt;/p&gt;
&lt;p&gt;Here’s what to do:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Open the file with the most important functions in your project code. If you don’t have functions, open the main script file.&lt;/li&gt;
&lt;li&gt;Add a docstring for one or two of the main functions (or at the top of the script). Make sure you include at least one example.&lt;/li&gt;
&lt;li&gt;Open an IPython session or Jupyter notebook. Import your code and then call up the docstring using “?”. Make sure this works correctly.&lt;/li&gt;
&lt;li&gt;Commit and push.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/ketch/rock-solid-code-demo/blob/3784b04109b2ca92633a788cc02562898064282c/factor.py&quot;&gt;Here’s what my demo repository looks like at this stage&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;when-should-i-write-docstrings&quot;&gt;When should I write docstrings?&lt;/h1&gt;
&lt;p&gt;That’s easy: when you start writing a new function, before you write the code itself, add the docstring. Make it a habit! Of course, you can come back and refine the docstring as necessary after writing the code.&lt;/p&gt;
&lt;p&gt;Now go to &lt;a href=&quot;/2015/05/15/write_tests.html&quot;&gt;step five&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&quot;note-this-post-was-originally-written-by-david-ketcheson-and-posted-at-httpwww.davidketcheson.info20150514write_docstrings.html&quot;&gt;Note: this post was originally written by David Ketcheson and posted at &lt;a href=&quot;http://www.davidketcheson.info/2015/05/14/write_docstrings.html&quot;&gt;http://www.davidketcheson.info/2015/05/14/write_docstrings.html&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;under the &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/deed.en_US&quot;&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Step 3 - Add a README and a License</title>
   <link href="https://www.qixiaodong.tk/en/2015/05/13/add_a_readme.html"/>
   <updated>2015-05-13T00:00:00+00:00</updated>
   <id>/2015/05/13/add_a_readme</id>
   <content type="html">&lt;p&gt;This is step 3 in your journey toward &lt;a href=&quot;/2015/05/10/rock_solid_code.html&quot;&gt;rock-solid scientific Python code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So your code is &lt;a href=&quot;/2015/05/11/use_version_control.html&quot;&gt;under version control&lt;/a&gt; and it’s &lt;a href=&quot;/2015/05/12/code_in_the_open.html&quot;&gt;floating up there in the cloud&lt;/a&gt;. In principle, someone else could use it. But how will they know it’s there? How will they know what it does, and how to install and use it?&lt;/p&gt;
&lt;h1 id=&quot;you-need-a-readme-file.&quot;&gt;You need a README file.&lt;/h1&gt;
&lt;p&gt;A README is minimalist documentation – just what is absolutely necessary for someone to start using your code. Most often, that someone is your future self, who has forgotten things. Here’s what to do:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Go to your project directory and open a new file. Call it README.md. The .md extension stands for Markdown, which is just an embellished format for text files that lets you add text formatting in simple ways that will automatically show up on Github. You can learn more about Markdown &lt;a href=&quot;https://help.github.com/articles/markdown-basics/&quot;&gt;here&lt;/a&gt;, but for the moment just think of it as a text file.&lt;/li&gt;
&lt;li&gt;Write the contents of the README file. You should probably include:
&lt;ul&gt;
&lt;li&gt;a brief description of what your code does;&lt;/li&gt;
&lt;li&gt;instructions for installing your code;&lt;/li&gt;
&lt;li&gt;what other code needs to be installed for it to work;&lt;/li&gt;
&lt;li&gt;one or two examples of how to invoke your code;&lt;/li&gt;
&lt;li&gt;optionally: who wrote the code, how to cite it, and who to contact for help. One good example of a README file is &lt;a href=&quot;https://github.com/github/markup/blob/master/README.md&quot;&gt;here&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Save and close the file.&lt;br /&gt;&lt;/li&gt;
&lt;li&gt;Add it to your repository with &lt;code&gt;git add&lt;/code&gt; and &lt;code&gt;git commit&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Push the file to github with &lt;code&gt;git push&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Go to the page for your project on Github. You should see the contents of your README file displayed automatically right below the directory listing. It should look &lt;a href=&quot;https://github.com/ketch/rock-solid-code-demo&quot;&gt;something like this&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Note: it’s also possible (and even easier) to add a README directly on Github, by clicking that nice green button:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/assets/img/github-readme-button.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Nice work! Now others (or your future self) stand a decent chance of being able to use your code. But they may not want to use it in exactly the same way you do. In fact, there’s a good chance they may want to modify it, or incorporate it into some other code they have. By default, copyright laws don’t allow them to do that. If you want others to be able to use your code for their purposes…&lt;/p&gt;
&lt;h1 id=&quot;you-need-a-license-file.&quot;&gt;You need a License file.&lt;/h1&gt;
&lt;p&gt;This part is fairly painless because, unlike a README, the license you use should NOT generally be customized for your project. It’s much better to choose a standard license, so that other people don’t need to agonize over all the fine print. The most common licenses for open source scientific software are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://choosealicense.com/licenses/bsd-2-clause/&quot;&gt;BSD&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://choosealicense.com/licenses/mit/&quot;&gt;MIT&lt;/a&gt;, and&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://choosealicense.com/licenses/gpl-2.0/&quot;&gt;GPL&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;All of these allow others to use, redistribute, and modify your code. The GPL license imposes one restriction that is absent from the others: other code that uses yours must also be GPL. Some view this as a great way to encourage more free, open-source code. Others view it as an impediment to your code being used. My suggestion is to use a BSD license, but if you want to investigate in more detail, try &lt;a href=&quot;http://choosealicense.com/&quot;&gt;Choose A License&lt;/a&gt; or go read &lt;a href=&quot;http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3406002/&quot;&gt;this paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Here’s what to do:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Create a file called LICENSE.txt in your project directory.&lt;/li&gt;
&lt;li&gt;Paste the license text (from one of the links above) into the file, save, and close.&lt;/li&gt;
&lt;li&gt;Commit and push the file to Github.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;That’s it! Other folks can now legally adapt your code for their own purposes.&lt;/p&gt;
&lt;p&gt;Congratulations on making it this far. Now go to &lt;a href=&quot;/2015/05/14/write_docstrings.html&quot;&gt;step four&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;extra-credit-contributing.md-and-thanks.md&quot;&gt;Extra credit: Contributing.md and Thanks.md&lt;/h1&gt;
&lt;p&gt;It’s great that other people can now make improvements to your code. It would be even better if they sent those improvements back to you! To encourage that, you should add a Contributing.md file to tell them what your standards for acceptable code are and what the process is for adding code to your repository. Github provides a &lt;a href=&quot;https://raw.githubusercontent.com/contribute-md/contribute-md-template/master/contribute.md&quot;&gt;standard template for such a file&lt;/a&gt;, though for small projects you can provide something much simpler. Some good examples of contributing files are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/puppetlabs/puppet/blob/master/CONTRIBUTING.md&quot;&gt;Puppet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/thoughtbot/factory_girl_rails/blob/master/CONTRIBUTING.md&quot;&gt;Factory_girl_rails&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If people have contributed to your project, it’s standard to have a file called Thanks.md that lists their names and contributions.&lt;/p&gt;
&lt;h4 id=&quot;note-this-post-was-originally-written-by-david-ketcheson-and-posted-at-httpwww.davidketcheson.info20150513add_a_readme.html&quot;&gt;Note: this post was originally written by David Ketcheson and posted at &lt;a href=&quot;http://www.davidketcheson.info/2015/05/13/add_a_readme.html&quot;&gt;http://www.davidketcheson.info/2015/05/13/add_a_readme.html&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;under the &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/deed.en_US&quot;&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Step 2 - Code in the open</title>
   <link href="https://www.qixiaodong.tk/en/2015/05/12/code_in_the_open.html"/>
   <updated>2015-05-12T00:00:00+00:00</updated>
   <id>/2015/05/12/code_in_the_open</id>
   <content type="html">&lt;p&gt;This is step 2 in your journey toward &lt;a href=&quot;/2015/05/10/rock_solid_code.html&quot;&gt;rock-solid scientific Python code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So you have your code under version control. Nice. But it’s sitting there on your computer. How do you share it with somebody else? And if they improve it, how do you incorporate their changes?&lt;/p&gt;
&lt;p&gt;Version control is your first tool in this regard, too. Your second tool is Github (or Bitbucket, Google Code, etc.). Github is a website that will keep a backup copy of your code for free, and will allow others to download it, change it, and send you their changes. If that sounds great, read on. If you’re scared to put your code in the open because somebody might read it, ponder on &lt;a href=&quot;http://www.siam.org/news/news.php?id=2064&quot;&gt;this&lt;/a&gt; and then read on.&lt;/p&gt;
&lt;h2 id=&quot;two-minutes-to-open-code&quot;&gt;Two minutes to open code&lt;/h2&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Go to &lt;a href=&quot;http://github.com/&quot;&gt;Github&lt;/a&gt; and create an account.&lt;/li&gt;
&lt;li&gt;Once you’re logged in, click on the “+” in the upper-right part of the screen and select “New repository”.&lt;/li&gt;
&lt;li&gt;Give it the same name as your project, and write a short description.&lt;/li&gt;
&lt;li&gt;Don’t initialize it with a README or license file (we’ll do that in Step #3).&lt;/li&gt;
&lt;li&gt;Preferably, select “public” repository.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Github will take you to a screen with different sets of instructions. Choose that one that says “…or push an existing repository from the command line” and type what is shown there into a terminal (in your project directory):&lt;/p&gt;
&lt;pre class=&quot;sh&quot;&gt;&lt;code&gt;cd /my/project/directory
git remote add origin git@github.com:username/projectname.git
git push -u origin master&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Tada! You’ve just “pushed” your code to Github where it is made available to all the world! As a bonus, you can sleep soundly knowing that if your office floods and your house burns down tomorrow, your code will still be there waiting for you. The result should look something like &lt;a href=&quot;https://github.com/ketch/rock-solid-code-demo&quot;&gt;my demo&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;To learn more about using Github, take a few minutes to read the &lt;a href=&quot;http://www.software-carpentry.org/v5/novice/git/02-collab.html&quot;&gt;Software Carpentry lesson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now &lt;a href=&quot;/2015/05/13/add_a_readme.html&quot;&gt;go on to step three&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&quot;note-this-post-was-originally-written-by-david-ketcheson-and-posted-at-httpwww.davidketcheson.info20150512code_in_the_open.html&quot;&gt;Note: this post was originally written by David Ketcheson and posted at &lt;a href=&quot;http://www.davidketcheson.info/2015/05/12/code_in_the_open.html&quot;&gt;http://www.davidketcheson.info/2015/05/12/code_in_the_open.html&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;under the &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/deed.en_US&quot;&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Step 1 - Use version control</title>
   <link href="https://www.qixiaodong.tk/en/2015/05/11/use_version_control.html"/>
   <updated>2015-05-11T00:00:00+00:00</updated>
   <id>/2015/05/11/use_version_control</id>
   <content type="html">&lt;p&gt;Welcome to step 1 in &lt;a href=&quot;/2015/05/10/rock_solid_code.html&quot;&gt;your training as a scientific Python code ninja&lt;/a&gt;: version control. This is not going to be an in-depth course, so if you’re already using distributed version control (like Git or Mercurial), feel free to skip ahead to &lt;a href=&quot;/2015/05/12/code_in_the_open.html&quot;&gt;step 2&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;life-before-version-control&quot;&gt;&lt;a href=&quot;http://phdcomics.com/comics.php?f=1531&quot;&gt;Life before version control&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;Programs change. That script I wrote last week to process my data needs to be adapted to a new file format or to produce a different kind of analysis. So I copy it to a new file and make some changes. I add a few lines and comment out others. The next week, I copy everything to a new directory so I can apply the code to a new project. A couple of months later, I realize that I have a mess of seven different directories, each with a dozen almost-identically-named files, and I am no longer sure which is the latest or what file does what. I spend a lot of time searching through and comparing the various files and directories to find what I need.&lt;/p&gt;
&lt;p&gt;Meanwhile, I email some version of the script to my collaborator, who also copies and modifies it. Each of us makes different improvements to it. I’d like to have one version with all the improvements, but how to extract the right bits from all the copies?&lt;/p&gt;
&lt;p&gt;Later, I find that my current version of the script doesn’t work with some old data that I need to re-analyze in order to revise a paper. Where is the old version of the script that worked with that data? Or does it even exist?&lt;/p&gt;
&lt;h2 id=&quot;version-control&quot;&gt;Version control&lt;/h2&gt;
&lt;p&gt;Version control software can help you solve all of these problems. It keeps a record of the history of your code and shows you the changes you made at each step. You can easily switch between different versions, or merge contributions from different authors.&lt;/p&gt;
&lt;p&gt;There are many version control systems in use. If you haven’t used one before, it’s best to find out what your collaborators use and start with that. If nobody you work with is using version control, I recommend that you use Git. It has become the most widely used version control system for new projects.&lt;/p&gt;
&lt;h2 id=&quot;two-minutes-to-version-control&quot;&gt;Two minutes to version control&lt;/h2&gt;
&lt;p&gt;If you’re on a Mac- or Linux-based system, you probably already have git. To check, just open a terminal and type&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you don’t have it, get it here: http://git-scm.com/downloads. Then take a moment to &lt;a href=&quot;https://help.github.com/articles/set-up-git/#setting-up-git&quot;&gt;set up git&lt;/a&gt;. You’ll only have to do that once on a given computer.&lt;/p&gt;
&lt;p&gt;Then do the following (replacing the directory and file names with the directory and files pertaining to your project):&lt;/p&gt;
&lt;pre class=&quot;sh&quot;&gt;&lt;code&gt;cd my/project/
git init
git add project_file1
git add project_file2
...&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Go ahead and add all the relevant files. When you’re done, tell git to start keeping track of them by doing&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git commit -m &amp;quot;Starting to keep this project under version control.&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s it! To get a first idea of what’s going on, try&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git status&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;git log&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get a much better idea, take 15 minutes and go read the &lt;a href=&quot;http://www.software-carpentry.org/v5/novice/git/01-backup.html&quot;&gt;first software carpentry lesson on version control&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can get by for awhile with just the few git commands listed above. Eventually, you will want to go beyond what is described in the Software Carpentry lesson. When you do, it’s worth reading an extended introduction &lt;a href=&quot;http://git-scm.com/book/en/v2&quot;&gt;like this one&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;/2015/05/12/code_in_the_open.html&quot;&gt;Continue to step two&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;extra-credit-dont-copy-paste&quot;&gt;Extra credit: Don’t copy-paste&lt;/h2&gt;
&lt;p&gt;Version control is really just one tool that will help you with a general principle of code development:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Don’t duplicate.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In practice, this means things like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If you have two functions that are almost identical, combine them (or the identical parts of them) into one.&lt;/li&gt;
&lt;li&gt;Don’t comment/uncomment lines of code in order to control the behavior of your code. Instead, use “if” statements and function arguments.&lt;/li&gt;
&lt;li&gt;If you need to apply some code to two different projects, don’t copy the file. Put it on your path.&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;note-this-post-was-originally-written-by-david-ketcheson-and-posted-at-httpwww.davidketcheson.info20150511use_version_control.html&quot;&gt;Note: this post was originally written by David Ketcheson and posted at &lt;a href=&quot;http://www.davidketcheson.info/2015/05/11/use_version_control.html&quot;&gt;http://www.davidketcheson.info/2015/05/11/use_version_control.html&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;under the &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/deed.en_US&quot;&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>12 steps toward rock-solid scientific Python code</title>
   <link href="https://www.qixiaodong.tk/en/2015/05/10/rock_solid_code.html"/>
   <updated>2015-05-10T00:00:00+00:00</updated>
   <id>/2015/05/10/rock_solid_code</id>
   <content type="html">&lt;p&gt;Much of my research is based on computer code. My code has bugs.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Does that mean that my research has errors?&lt;/em&gt; Quite possibly.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Are you, my fellow scientist, in the same boat?&lt;/em&gt; Probably.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;What can we do about it?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;We must adopt practices that are known to lead to more correct code. We must be willing to devote the time and energy that those practices require. Most of the time, this is neither fun nor glorious. We don’t try to cut corners when developing a mathematical proof or preparing an experiment – we know that leads to error. Writing computer code is no different; if anything, it requires that we take an even more methodical approach. It is time for computational scientists to own up to this. If we want to have confidence in our results, and if we want others to be able to build on them, there is no other choice.&lt;/p&gt;
&lt;p&gt;The bonus is that adopting these practices can lead to cleaner, simpler code that is easier to understand, maintain, and debug. In the long term, I believe that these practices lead to an overall time &lt;em&gt;savings&lt;/em&gt;, and the opportunity to spend more time using our computational tools to perform research.&lt;/p&gt;
&lt;p&gt;In short, what I’m about to show you will allow you to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Have confidence in your computed results&lt;/li&gt;
&lt;li&gt;Accelerate your research&lt;/li&gt;
&lt;li&gt;Better communicate your research&lt;/li&gt;
&lt;li&gt;Collaborate more effectively&lt;/li&gt;
&lt;li&gt;Help others build on your work&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;twelve-baby-steps&quot;&gt;Twelve (baby) steps&lt;/h2&gt;
&lt;p&gt;So here it is: my 12-step program to writing scientific code that you can believe in:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;a href=&quot;/2015/05/11/use_version_control.html&quot;&gt;Use version control&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/05/12/code_in_the_open.html&quot;&gt;Put your code in the cloud, in the open&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/05/13/add_a_readme.html&quot;&gt;Add a README and a License&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/05/14/write_docstrings.html&quot;&gt;Write docstrings&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/05/15/write_tests.html&quot;&gt;Write tests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/05/16/track_issues.html&quot;&gt;Keep track of issues&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;/2015/05/29/automate_tests.html&quot;&gt;Automate the tests&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Automate the build (&lt;em&gt;coming soon&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Use continuous integration (&lt;em&gt;coming soon&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Monitor test coverage (&lt;em&gt;coming soon&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Write narrative documentation (&lt;em&gt;coming soon&lt;/em&gt;)&lt;/li&gt;
&lt;li&gt;Catch errors as you type them (&lt;em&gt;coming soon&lt;/em&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I know what you’re thinking: that sounds like a lot of work. It is. But my goal in this series is to make each of these steps as straightforward and painless as possible. Thanks to a number of recently-developed tools, &lt;strong&gt;most of these tasks can be done very quickly&lt;/strong&gt;, at least for small and simple projects.&lt;/p&gt;
&lt;p&gt;There is nothing magical about this precise set of steps; I could have broken them down in a different way or included others. What’s essential are the underlying principles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Automation (steps 1, 5, 6,7, 8, 9, 10, 12): Removal of manual processes makes code more reliable.&lt;/li&gt;
&lt;li&gt;Documentation (steps 3, 4, 5, 6, 11): Writing and thinking about the code makes it more reliable.&lt;/li&gt;
&lt;li&gt;Communication/collaboration (steps 1, 2, 3, 4, 5, 6, 11): Code that is read and used by more than one person is more reliable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;the-12-step-challenge&quot;&gt;The 12-step challenge&lt;/h2&gt;
&lt;p&gt;You could casually read through this series of posts and think about implementing these changes someday. But don’t. &lt;strong&gt;Pick a current scientific project with code&lt;/strong&gt;, and commit yourself now to getting it in order by following these steps. Then go through the posts and &lt;strong&gt;apply the instructions at each step&lt;/strong&gt; to the project you’ve chosen. When you’re done, you’ll have one rock-solid code project and the know-how to run all of your projects that way. The next one will be even easier.&lt;/p&gt;
&lt;h2 id=&quot;pre-requisites&quot;&gt;Pre-requisites&lt;/h2&gt;
&lt;p&gt;I’ve tried to make these posts very simple, but there is a minimal amount of know-how I assume. In particular, you must be able to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open a terminal, navigate your file system, and execute commands&lt;/li&gt;
&lt;li&gt;Edit text files&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you’ve taken a &lt;a href=&quot;http://software-carpentry.org/&quot;&gt;Software Carpentry&lt;/a&gt; course, you’re more than prepared.&lt;/p&gt;
&lt;h2 id=&quot;what-these-steps-wont-do&quot;&gt;What these steps won’t do&lt;/h2&gt;
&lt;p&gt;I’m not going to tell you how to actually &lt;em&gt;design&lt;/em&gt; better code. That’s much harder! For that, you should read a book on programming style, like &lt;a href=&quot;https://pragprog.com/the-pragmatic-programmer&quot;&gt;The Pragmatic Programmer&lt;/a&gt; or &lt;a href=&quot;http://cc2e.com/&quot;&gt;Code Complete&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I’m not going to make you an expert in the topics listed above. My goal is just to get you over the initial psychological bump, from “&lt;em&gt;I have no idea what that is&lt;/em&gt;” to “&lt;em&gt;yeah, I can basically do that&lt;/em&gt;”. This is the 20% effort that gives 80% of the benefit.&lt;/p&gt;
&lt;h2 id=&quot;questions&quot;&gt;Questions&lt;/h2&gt;
&lt;h3 id=&quot;my-code-is-just-some-simple-scripts-does-this-stuff-still-apply&quot;&gt;My code is just some simple scripts; does this stuff still apply?&lt;/h3&gt;
&lt;p&gt;Yes! In fact, I suggest starting with a small and simple project – the smaller the better. To demonstrate, I’ve written &lt;a href=&quot;https://github.com/ketch/rock-solid-code-demo&quot;&gt;a tiny package that does LU factorization (Gaussian elimination) for square matrices&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;why-python&quot;&gt;Why Python?&lt;/h3&gt;
&lt;p&gt;Useful tutorials need to be concrete. The steps are applicable to any language, but the best tools for achieving them vary by language. Python is a popular language, and is what I use most.&lt;/p&gt;
&lt;h3 id=&quot;why-are-you-so-sure-my-code-has-bugs&quot;&gt;Why are you so sure my code has bugs?&lt;/h3&gt;
&lt;p&gt;If you’re asking this, go read &lt;a href=&quot;http://statweb.stanford.edu/~donoho/Reports/2008/15YrsReproResch-20080426.pdf&quot;&gt;Donoho et. al.’s paper on reproducible computing&lt;/a&gt;, from which I quote:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“&lt;em&gt;Error is ubiquitous in scientific computing, and one needs to work very diligently and energetically to eliminate it.&lt;/em&gt;”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Okay, what are you waiting for? Go read &lt;a href=&quot;/2015/05/11/use_version_control.html&quot;&gt;step one&lt;/a&gt;!&lt;/p&gt;
&lt;h4 id=&quot;note-this-post-was-originally-written-by-david-ketcheson-and-posted-at-httpwww.davidketcheson.info20150510rock_solid_code.html&quot;&gt;Note: this post was originally written by David Ketcheson and posted at &lt;a href=&quot;http://www.davidketcheson.info/2015/05/10/rock_solid_code.html&quot;&gt;http://www.davidketcheson.info/2015/05/10/rock_solid_code.html&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;under the &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/deed.en_US&quot;&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Testing whether your code produces the correct plots -- in Python and on Travis</title>
   <link href="https://www.qixiaodong.tk/en/2015/01/13/using_matplotlib_image_comparison.html"/>
   <updated>2015-01-13T00:00:00+00:00</updated>
   <id>/2015/01/13/using_matplotlib_image_comparison</id>
   <content type="html">&lt;p&gt;A few years ago I was introduced to the idea of testing the scientific code I write, and now I am a huge fan of this approach. It saves huge amounts of time and vastly improves the quality of my research by helping me catch bugs early and often. I use &lt;a href=&quot;https://nose.readthedocs.org/en/latest/&quot;&gt;nose&lt;/a&gt; for automatically finding and running all the tests. I use &lt;a href=&quot;https://travis-ci.org/&quot;&gt;Travis&lt;/a&gt; to automatically run the tests every time I update the code – or issue a pull request – on Github.&lt;/p&gt;
&lt;h1 id=&quot;image-regression-tests&quot;&gt;Image regression tests&lt;/h1&gt;
&lt;p&gt;Usually, I can test the output of a routine by comparing numbers (generally, by taking norms of large arrays of numbers). However, I also develop routines that are used to visualize numerical output, using matplotlib and other Python plotting tools. Sometimes the numerical output is fine but the visualization code breaks. It’s easy to write tests that just make sure the visualization code still runs, and that perhaps check some assertions about the properties of the resulting matplotlib objects in memory. But that doesn’t ensure that the image still looks right. How does one automatically check whether an image is correct?&lt;/p&gt;
&lt;p&gt;Obviously, &lt;em&gt;correct&lt;/em&gt; in this case must refer to some reference image that you produced once and whose correctness you confirmed by visual inspection. In other words, I’m talking about &lt;em&gt;regression testing&lt;/em&gt;, which simply ensures that things function as they did before. To regresion test an image, you could write an image file and check whether it is bitwise identical to the reference image. But this is very problematic, since running the same bit of matplotlib code on two different machines will often lead to slightly different output, depending on the versions of other libraries that are installed, the fonts available, etc. Some more intelligent method of comparison is needed.&lt;/p&gt;
&lt;h1 id=&quot;the-image_comparison-decorator&quot;&gt;The image_comparison decorator&lt;/h1&gt;
&lt;p&gt;Fortunately, the matplotlib developers have been grappling with these issues for a long time and have a nice packaged solution, in the form of a Python decorator &lt;code&gt;@image_comparison&lt;/code&gt;, whose usage within matplotlib is &lt;a href=&quot;http://matplotlib.org/devel/testing.html&quot;&gt;explained here&lt;/a&gt;. The decorator automatically deals with saving the test image and comparing it to the reference image; all you do is add the decorator before your test function.&lt;/p&gt;
&lt;p&gt;Clearly, I thought, it would be great if I could use this decorator for image testing in my own projects. So I followed the instructions linked above, but things didn’t immediately work. Apparently &lt;a href=&quot;http://matplotlib.1069221.n5.nabble.com/Image-comparison-decorators-outside-matplotlib-td42215.html&quot;&gt;others have had the same experience&lt;/a&gt;, so I thought I’d share what I had to do to get things working.&lt;/p&gt;
&lt;h1 id=&quot;getting-things-to-work-locally&quot;&gt;Getting things to work locally&lt;/h1&gt;
&lt;p&gt;The decorator makes a few assumptions that are based on the directory structure of matplotlib’s own test directories. So you have two options:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Make your project’s test directory structure conform to matplotlib’s.&lt;/li&gt;
&lt;li&gt;Create a modified version of matplotlib’s image_comparison decorator for your own project.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I went with option 1, since I generally prefer to outsource as much functionality as reasonably possible. I had to do the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Your tests must live in a submodule named &lt;code&gt;tests&lt;/code&gt;. Thus if your package is named &lt;em&gt;pystuff&lt;/em&gt;, you might have your tests in &lt;code&gt;pystuff/tests/my_tests.py&lt;/code&gt; and there should be an &lt;code&gt;__init__.py&lt;/code&gt; file in the &lt;code&gt;tests&lt;/code&gt; directory (it can be just an empty file).&lt;/li&gt;
&lt;li&gt;The baseline images should be in a directory &lt;code&gt;pystuff/tests/baseline_images/my_tests/&lt;/code&gt; (replace &lt;code&gt;my_tests&lt;/code&gt; with the name of the file containing your tests). Note that the image names are specified as arguments to the decorator.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Once I did that the tests passed on my machine. However, they didn’t pass on Travis.&lt;/p&gt;
&lt;h1 id=&quot;getting-things-to-work-on-travis&quot;&gt;Getting things to work on Travis&lt;/h1&gt;
&lt;p&gt;I ran into two issues on Travis:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Generating matplotlib figures on Travis with a backed that requires DISPLAY will fail if it is not set.&lt;/li&gt;
&lt;li&gt;Even if display is set, Travis may use a different backend than you do locally, which may lead to test failure (e.g., because the images produced have different numbers of pixels).&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Both of these are solved by ensuring that matplotlib uses the &lt;em&gt;agg&lt;/em&gt; backend for the tests (both locally and on Travis). To set the backend to &lt;em&gt;agg&lt;/em&gt;, just add the command&lt;/p&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;matplotlib.use(&lt;span class=&quot;st&quot;&gt;&amp;#39;agg&amp;#39;&lt;/span&gt;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This line must be executed before you import &lt;em&gt;pylab&lt;/em&gt; or &lt;code&gt;matplotlib.pyplot&lt;/code&gt;. This is very tricky if you are using nose, because nose actually imports every file in your package during the test collection phase. What I had to do to get things to work (and the matplotlib package itself does the same!) is to put a &lt;code&gt;tests.py&lt;/code&gt; script in the top directory of my package. This script has the following contents:&lt;/p&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;#!/usr/bin/env python&lt;/span&gt;

&lt;span class=&quot;ch&quot;&gt;import&lt;/span&gt; matplotlib
&lt;span class=&quot;ch&quot;&gt;import&lt;/span&gt; nose
matplotlib.use(&lt;span class=&quot;st&quot;&gt;&amp;#39;agg&amp;#39;&lt;/span&gt;)

nose.main()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Instead of calling nosetests directly on Travis, I use the following in my &lt;code&gt;.travis.yml&lt;/code&gt; file:&lt;/p&gt;
&lt;pre class=&quot;sourceCode yaml&quot;&gt;&lt;code class=&quot;sourceCode yaml&quot;&gt;&lt;span class=&quot;fu&quot;&gt;script:&lt;/span&gt;
  &lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt; cd $HOME/build/my/package
  &lt;span class=&quot;kw&quot;&gt;-&lt;/span&gt; python tests.py&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That’s it! Since examples are the best documentation, you can check out my working setup &lt;a href=&quot;https://github.com/ketch/griddle&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&quot;note-this-post-was-originally-written-by-david-ketcheson-and-posted-at-httpwww.davidketcheson.info20150113using_matplotlib_image_comparison.html&quot;&gt;Note: this post was originally written by David Ketcheson and posted at &lt;a href=&quot;http://www.davidketcheson.info/2015/01/13/using_matplotlib_image_comparison.html&quot;&gt;http://www.davidketcheson.info/2015/01/13/using_matplotlib_image_comparison.html&lt;/a&gt;&lt;/h4&gt;
&lt;p&gt;under the &lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/deed.en_US&quot;&gt;Creative Commons Attribution 3.0 Unported License&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Teaching in the open</title>
   <link href="https://www.qixiaodong.tk/en/2014/07/18/teaching_in_the_open.html"/>
   <updated>2014-07-18T00:00:00+00:00</updated>
   <id>/2014/07/18/teaching_in_the_open</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2014/07/18/teaching_in_the_open.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you examine the menu bar above, you’ll notice that my site has a new top-level page: &lt;a href=&quot;/teaching.html&quot;&gt;Teaching&lt;/a&gt;. This is a direct result of my attending &lt;a href=&quot;http://www.youtube.com/watch?v=1e26rp6qPbA&amp;amp;t=26m12s&quot;&gt;Greg Wilson’s inspiring keynote at Scipy 2014&lt;/a&gt;. That link will take you to the key (for me) part of the talk, but I recommend watching the whole thing. His message is: massive collaboration is the real revolution. Michael Nielsen made the same statement in &lt;em&gt;Reinventing Discovery&lt;/em&gt;; here Greg applies this statement to university education, and asks:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Why don’t instructors open-source their teaching materials?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This new page is my own effort to enable that revolution. In fact, I’ve been gradually putting my teaching materials online for the past couple of years, without giving it much thought. The teaching page collects all the resources I’ve made available in one place.&lt;/p&gt;
&lt;p&gt;Something even more exciting in this vein is coming in the fall. If you want to know a little about it, watch &lt;a href=&quot;http://www.youtube.com/watch?v=TWxwKDT88GU&amp;amp;t=56m2s&quot;&gt;the last few minutes of Lorena Barba’s excellent Scipy keynote on computational thinking and teaching&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Stay tuned.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Teaching with SageMathCloud</title>
   <link href="https://www.qixiaodong.tk/en/2014/05/31/teaching_with_SMC.html"/>
   <updated>2014-05-31T00:00:00+00:00</updated>
   <id>/2014/05/31/teaching_with_SMC</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2014/05/31/teaching_with_SMC.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;During the past Spring semester at KAUST, I again taught AMCS 252, our masters-level course on numerical analysis for differential equations. I’ve been teaching the course using Python for 5 years now. This year, for the first time, &lt;em&gt;I didn’t spend any time helping students install Python, numpy, matplotlib, or scipy&lt;/em&gt;. In fact, I even had them use Clawpack – and they didn’t need to install it. Why? Because they all used &lt;a href=&quot;http://cloud.sagemath.com&quot;&gt;SageMathCloud&lt;/a&gt; for the course.&lt;/p&gt;
&lt;h2 id=&quot;a-little-history&quot;&gt;A little history&lt;/h2&gt;
&lt;p&gt;For the past several years, I have been increasingly integrating into the course &lt;a href=&quot;https://github.com/ketch/AMCS252&quot;&gt;a set of electronic notebooks&lt;/a&gt; in which the students are presented with some explanations and code, followed by exercises that involve modifying, running, and understanding the numerical algorithms implemented in the notebook. At first these were a set of Sage worksheets, and I ran a local Sage server within the KAUST network. When the VM that held the server died a horrible and irreversible death, I decided to switch to the IPython notebook format that had become increasingly popular. It wasn’t too hard to &lt;a href=&quot;http://www.davidketcheson.info/2013/01/16/sage_to_ipython.html&quot;&gt;convert all my Sage worksheets to IPython notebooks&lt;/a&gt;. But my students had to either do all their work in the computer lab or figure out how to install the necessary Python packages on their own machines. This was a bit of a time sink for me, although it has gotten easier each year thanks to packages like &lt;a href=&quot;https://store.continuum.io/cshop/anaconda/&quot;&gt;Anaconda&lt;/a&gt; and &lt;a href=&quot;https://www.enthought.com/products/canopy/&quot;&gt;Canopy&lt;/a&gt;. This also meant that they all ended up working in slightly different environments, which occasionally caused problems.&lt;/p&gt;
&lt;h2 id=&quot;ipython-notebooks-in-the-cloud&quot;&gt;IPython notebooks in the cloud&lt;/h2&gt;
&lt;p&gt;In the last year, two new cloud services emerged, both offering free accounts with the ability to run IPython notebooks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://wakari.io&quot;&gt;Wakari&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://cloud.sagemath.com&quot;&gt;Sage Math Cloud&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I realized that by using one of these services, I could avoid dealing with installation issues and ensure that everyone worked in an identical environment. Though I have found both Wakari and SMC to be useful, I ended up going with SMC for the course because it has, in my opinion, a more intuitive user interface.&lt;/p&gt;
&lt;h2 id=&quot;getting-started&quot;&gt;Getting started&lt;/h2&gt;
&lt;p&gt;On the first day of class, students had only to create a free SMC account, create a new project, and type the URL of the course github repo into the “new file” box, which automatically caused it to be cloned into their SMC project. As I updated materials during the semester, all they had to do was open a SMC terminal and type “git pull” (in fact, none of the students had ever used git before, but none of them had any difficulty with this during the course).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cloud.sagemath.com/art/templates.png&quot; alt=&quot;Git clone via SMC&quot; height=&quot;200&quot; align=&quot;center&quot;&gt;&lt;/p&gt;
&lt;p&gt;Another great advantage of using a cloud service was that students could work or show their work from any computer. Since it was a small class, I had them present homework solutions in-class. They could all present solutions using the computer attached to the projector in the room by just logging into their own SMC account. That meant we avoided losing 5 or 10 minutes of class time in order to switch cables or transfer files.&lt;/p&gt;
&lt;h2 id=&quot;feedback&quot;&gt;Feedback&lt;/h2&gt;
&lt;p&gt;Overall, the students’ feedback was very positive. Most notably, although some of them did eventually install Python and the related packages locally on their laptops, they all chose to use SMC for their homework assignments throughout the course. There were some noticeable latency issues (the ping time between Saudi Arabia and Seattle is 200ms), and SMC currently has a 10-20 second delay the first time you open an IPython notebook (there’s no such delay for Sage worksheets). But those were not showstoppers, and I think by the time I teach my next course those issues will be resolved (by an IPython upgrade on SMC and by the launch of a European SMC server, respectively). William Stein, creator of SMC (and Sage) was extremely responsive and helpful (in fact, he created a trial European server recently in response to my and others’ comments about latency).&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://dl.dropboxusercontent.com/u/656693/smc_screenshot.png&quot; alt=&quot;SMC&quot; align=&quot;center&quot;&gt;&lt;/p&gt;
&lt;p&gt;I used SMC again to &lt;a href=&quot;https://github.com/ketch/HyperPython/blob/master/README.md&quot;&gt;teach a 1-day tutorial&lt;/a&gt; at &lt;a href=&quot;http://jkk.sze.hu/en_GB/program&quot;&gt;a workshop&lt;/a&gt; this month. Other than a couple of minor hiccups, it again worked very well. I plan to continue using it for teaching in the future. One feature I haven’t used yet (but intend to) is the ability to “collaborate” on a project so that multiple users can edit it at the same time. I understand that &lt;a href=&quot;http://sagemath.blogspot.com/2014/04/the-sagemathcloud-roadmap.html&quot;&gt;many other great features are in the works&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I would strongly recommend SMC to other teachers of computationally-oriented courses, even if you’re not using IPython notebooks or Sage worksheets. As long as all the software for your course is freely available, you can install it all on SMC so that students have identical environments, accessible from anything with a web browser, with no need to do any installation of their own.&lt;/p&gt;
&lt;p&gt;If you’re interested in my notebooks, you can find them here:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/ketch/finite-difference-course&quot;&gt;Spring 2013 course&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/ketch/AMCS252&quot;&gt;Spring 2014 course&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/ketch/HyperPython&quot;&gt;HyperPython tutorial&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Just be warned that some are more polished than others, and they’re likely to all get a makeover soon.&lt;/p&gt;
&lt;p&gt;Now that I keep a lot of my &lt;a href=&quot;https://github.com/ketch/shallow_water_periodic_bathymetry/blob/master/pyclaw/shallow_water_diffraction.ipynb&quot;&gt;research in IPython notebooks on Github&lt;/a&gt;, I’m also thinking that SMC is a way to be able to show that research to anyone, anywhere. Heck, I can create a project, clone a Github repo, and run PyClaw in a notebook &lt;strong&gt;on my phone!&lt;/strong&gt; Just amazing.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>HyperPython</title>
   <link href="https://www.qixiaodong.tk/en/2014/05/28/hyperpython.html"/>
   <updated>2014-05-28T00:00:00+00:00</updated>
   <id>/2014/05/28/hyperpython</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2014/05/28/hyperpython.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/ketch/HyperPython/master/figures/finite_volume.png&quot; alt=&quot;Finite volumes&quot; height=&quot;200&quot; align=&quot;center&quot;&gt;&lt;/p&gt;
&lt;p&gt;Last week, I ran a 1-day tutorial at the &lt;a href=&quot;http://jkk.sze.hu/en_GB/program&quot;&gt;Workshop on Design, Simulation, Optimization and Control of Green Vehicles and Transportation&lt;/a&gt;. The idea was to teach attendees about Python programming, basic theory of hyperbolic conservation laws, finite volume methods, and how to use &lt;a href=&quot;http://clawpack.github.io/doc/pyclaw/&quot;&gt;PyClaw&lt;/a&gt;, all in the space of a few hours.&lt;/p&gt;
&lt;p&gt;Inspired by Lorena Barba’s recent release of &lt;a href=&quot;http://lorenabarba.com/blog/announcing-aeropython/&quot;&gt;AeroPython&lt;/a&gt;, I decided to develop a short set of IPython notebooks for the tutorial. The result is &lt;a href=&quot;https://github.com/ketch/HyperPython&quot;&gt;HyperPython&lt;/a&gt;, a set of 5 lessons (plus Python crash course):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://nbviewer.ipython.org/github/ketch/HyperPython/blob/master/Lesson_00_Python.ipynb&quot;&gt;Lesson 0: Python&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://nbviewer.ipython.org/github/ketch/HyperPython/blob/master/Lesson_01_Advection.ipynb&quot;&gt;Lesson 1: Advection&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://nbviewer.ipython.org/github/ketch/HyperPython/blob/master/Lesson_02_Traffic.ipynb&quot;&gt;Lesson 2: Traffic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://nbviewer.ipython.org/github/ketch/HyperPython/blob/master/Lesson_03_High-resolution_methods.ipynb&quot;&gt;Lesson 3: High-resolution methods&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://nbviewer.ipython.org/github/ketch/HyperPython/blob/master/Lesson_04_Fluid_dynamics.ipynb&quot;&gt;Lesson 4: Fluid dynamics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://nbviewer.ipython.org/github/ketch/HyperPython/blob/master/Lesson_05_PyClaw.ipynb&quot;&gt;Lesson 5: PyClaw&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These won’t make you an expert, but if you’re looking for something short, practical, and fun, please give them a try. You may also find the last two notebooks useful if you’re looking for a good introduction to PyClaw.&lt;/p&gt;
&lt;p&gt;These may be greatly expanded in the future into a full-fledged semester-length course.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Dispersion relations for linear systems of PDEs</title>
   <link href="https://www.qixiaodong.tk/en/2014/05/28/dispersion_relations.html"/>
   <updated>2014-05-28T00:00:00+00:00</updated>
   <id>/2014/05/28/dispersion_relations</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2014/05/28/dispersion_relations.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Fourier analysis is an essential tool for understanding the behavior of solutions to linear equations. Often, this analysis is introduced to students in the context of scalar equations with real coefficients. If nothing more is said, students may mistakenly apply assumptions based on the scalar case to systems, leading to erroneous conclusions. I’m surprised at how often I’ve seen this, and I’ve even made the mistake myself.&lt;/p&gt;
&lt;h2 id=&quot;scalar-equations&quot;&gt;Scalar equations&lt;/h2&gt;
&lt;p&gt;Students in any undergraduate PDE course learn that solutions of the heat equation&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[
\label{heat}
u_t(x,t) = u_{xx}(x,t)
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;diffuse in time whereas solutions of the wave equation&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[
\label{wave}
u_{tt} = u_{xx}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;oscillate in time without growing or decaying. They may even be introduced to a general approach for the Cauchy problem: given an evolution equation&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[ \label{evol}
u_t = \sum_{j=0}^n a_j \frac{\partial^j u}{\partial x^j},
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;one inserts the Fourier mode solution&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[ \label{fourier}
u(x,t) = e^{i(kx - \omega(k) t)}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;to obtain&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[-i\omega(k) = \sum_{j=0}^n a_j (ik)^j\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;or simply&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[\omega(k) = \sum_{j=0}^n a_j i^{j+1} k^j.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;The function &lt;span class=&quot;math&quot;&gt;\(\omega(k)\)&lt;/span&gt; is often referred to as the &lt;em&gt;dispersion relation&lt;/em&gt; for the PDE. Any solution can be expressed as a sum of Fourier modes, and each mode propagates in a manner dictated by the dispersion relation. It’s easy to see that&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If &lt;span class=&quot;math&quot;&gt;\(\omega(k)\)&lt;/span&gt; is &lt;strong&gt;real&lt;/strong&gt;, then energy is conserved and each mode simply translates. This occurs if only odd-numbered spatial derivatives appear in the evolution equation \eqref{evol}.&lt;/li&gt;
&lt;li&gt;If &lt;span class=&quot;math&quot;&gt;\(\omega(k)\)&lt;/span&gt; has &lt;strong&gt;negative imaginary part&lt;/strong&gt;, energy decays in time. The heat equation \eqref{heat} behaves this way.&lt;/li&gt;
&lt;li&gt;If &lt;span class=&quot;math&quot;&gt;\(\omega(k)\)&lt;/span&gt; has &lt;strong&gt;positive imaginary part&lt;/strong&gt;, then the energy will grow exponentially in time. This doesn’t usually occur in physical systems. An example of this behavior is obtained by changing the sign of the right side in the heat equation to get &lt;span class=&quot;math&quot;&gt;\(u_t = - u_{xx}\)&lt;/span&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What about the wave equation, which has two time derivatives? Using the same Fourier mode ansatz \eqref{fourier}, one obtains &lt;span class=&quot;math&quot;&gt;\[
\begin{align}
\omega^2 &amp;amp; = k^2
\end{align}
\]&lt;/span&gt; or &lt;span class=&quot;math&quot;&gt;\(\omega = \pm k\)&lt;/span&gt;. Since &lt;span class=&quot;math&quot;&gt;\(\omega\)&lt;/span&gt; is real, energy is conserved.&lt;/p&gt;
&lt;p&gt;In the discussion above, we have assumed that &lt;span class=&quot;math&quot;&gt;\(u\)&lt;/span&gt; is a scalar and that the coefficients &lt;span class=&quot;math&quot;&gt;\(a_j\)&lt;/span&gt; are real. Many undergraduate courses stop at this point, and students are left with the intuition that &lt;strong&gt;even-numbered derivative terms are diffusive&lt;/strong&gt; while &lt;strong&gt;odd-numbered derivative terms are dispersive&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;In practice, we often deal with systems of PDEs or PDEs with complex coefficients, and this intuition is then no longer correct. There is nothing deep or mysterious about this topic, but it’s easy to jump to incorrect conclusions if one is not careful. To take a common example, consider the time-dependent Schroedinger equation: &lt;span class=&quot;math&quot;&gt;\[i \psi_t = \psi_{xx} + V\psi.\]&lt;/span&gt; At first glance, we have on the right side a diffusion term (&lt;span class=&quot;math&quot;&gt;\(\psi_{xx}\)&lt;/span&gt;) and a reaction term (&lt;span class=&quot;math&quot;&gt;\(V\psi\)&lt;/span&gt;). But what about that pesky factor of &lt;span class=&quot;math&quot;&gt;\(i\)&lt;/span&gt; (the imaginary unit) on the left hand side? It’s easy to find the answer using the usual ansatz, but let’s take a little detour first.&lt;/p&gt;
&lt;h2 id=&quot;systems-of-equations&quot;&gt;Systems of equations&lt;/h2&gt;
&lt;p&gt;Consider the linear system &lt;span class=&quot;math&quot;&gt;\[
\begin{align*}
u_t = A  \frac{\partial^j u}{\partial x^j},
\end{align*}
\]&lt;/span&gt; where &lt;span class=&quot;math&quot;&gt;\(u\in \mathbb{R}^m\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; is a square real matrix. Let &lt;span class=&quot;math&quot;&gt;\(\lambda_m\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(s_m\)&lt;/span&gt; denote the eigenvalues and eigenvectors (respectively) of &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt;. Inserting the Fourier mode solution &lt;span class=&quot;math&quot;&gt;\[u(x,t) = s_m e^{i(kx - \omega(k) t)},\]&lt;/span&gt; we obtain &lt;span class=&quot;math&quot;&gt;\[\omega(k) = i^{j+1} k^j \lambda_m s_m,\]&lt;/span&gt; and any solution can be written as a superposition of these. We see now that the behavior of the energy with respect to time depends on both the number &lt;span class=&quot;math&quot;&gt;\(j\)&lt;/span&gt; of spatial derivatives and the nature of the eigenvalues of &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt;. For instance, if &lt;span class=&quot;math&quot;&gt;\(j=1\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; has imaginary eigenvalues, energy is conserved. We can obtain just such an example by rewriting the wave equation \eqref{wave} as a first-order system: &lt;span class=&quot;math&quot;&gt;\[
\begin{align}
u_t &amp;amp; = v_x \label{w1} \\
v_t &amp;amp; = u_x. \label{w2}
\end{align}
\]&lt;/span&gt; (If you’re not familiar with this, just differentiate \eqref{w1} w.r.t. &lt;span class=&quot;math&quot;&gt;\(t\)&lt;/span&gt; and \eqref{w2} w.r.t. &lt;span class=&quot;math&quot;&gt;\(x\)&lt;/span&gt;, then equate partial derivatives to get back the second-order wave equation \eqref{wave}). We have a linear system with &lt;span class=&quot;math&quot;&gt;\(j=1\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\[ A = \begin{pmatrix}
0 &amp;amp; 1 \\ 1 &amp;amp; 0
\end{pmatrix}.\]&lt;/span&gt; This matrix has eigenvalues &lt;span class=&quot;math&quot;&gt;\(\lambda=\pm 1\)&lt;/span&gt;, so &lt;span class=&quot;math&quot;&gt;\(\omega(k)\)&lt;/span&gt; has zero imaginary part.&lt;/p&gt;
&lt;p&gt;In this example, our intuition from the scalar case works: our first-order system, with only odd-numbered derivatives, leads to wave-like behavior. But notice that if &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; had imaginary eigenvalues, our intuition would be wrong; for instance, the system &lt;span class=&quot;math&quot;&gt;\[
\begin{align*}
u_t &amp;amp; = -v_x \\
v_t &amp;amp; = u_x,
\end{align*}
\]&lt;/span&gt; corresponding to the second-order equation &lt;span class=&quot;math&quot;&gt;\(u_{tt} = - u_{xx},\)&lt;/span&gt; admits exponentially growing solutions.&lt;/p&gt;
&lt;h2 id=&quot;scalar-problems-with-complex-coefficients&quot;&gt;Scalar problems with complex coefficients&lt;/h2&gt;
&lt;p&gt;Now that we understand the dispersion relation for systems, it’s easy to understand the dispersion relation for the Schrodinger equation. Multiply by &lt;span class=&quot;math&quot;&gt;\(-i\)&lt;/span&gt; to get &lt;span class=&quot;math&quot;&gt;\[\psi_t = -i\psi_{xx} + -iV\psi.\]&lt;/span&gt; Now we can think of this in the same way as a system, where the coefficient matrices have purely imaginary eigenvalues. Then it’s clear that the (even-derivative) terms on the right hand side are both related to wave behavior (i.e., energy is conserved).&lt;/p&gt;
&lt;h2 id=&quot;systems-with-derivatives-of-different-orders&quot;&gt;Systems with derivatives of different orders&lt;/h2&gt;
&lt;p&gt;In the most general case, we have systems of linear PDEs with multiple spatial derivatives of different order: &lt;span class=&quot;math&quot;&gt;\[ \label{gensys}
u_t = \sum_{j=0}^n A_j  \frac{\partial^j u}{\partial x^j}.
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Here’s a real example from my research. It comes from homogenization of the wave equation in a spatially varying medium (see Equation (5.17) of &lt;a href=&quot;http://faculty.washington.edu/rjl/pubs/solitary/40815.pdf&quot;&gt;this paper&lt;/a&gt; for more details). It’s the wave equation plus some second-derivative terms: &lt;span class=&quot;math&quot;&gt;\[
u_t = v_x + v_{xx} \\
v_t = u_x - u_{xx}.
\]&lt;/span&gt; You might (if you hadn’t read the example above) assume that this system is dissipative due to the second derivatives. This system is of the form \eqref{gensys} with &lt;span class=&quot;math&quot;&gt;\[
\begin{align}
A_1 &amp;amp; = \begin{pmatrix}
0 &amp;amp; 1 \\ 1 &amp;amp; 0
\end{pmatrix}
&amp;amp;
A_2 &amp;amp; = \begin{pmatrix}
0 &amp;amp; 1 \\ -1 &amp;amp; 0
\end{pmatrix}.
\end{align}
\]&lt;/span&gt; Of course, &lt;span class=&quot;math&quot;&gt;\(A_1\)&lt;/span&gt; has real eigenvalues and leads to wave-like behavior. But &lt;span class=&quot;math&quot;&gt;\(A_2\)&lt;/span&gt; has pure imaginary eigenvalues, so it also leads to wave-like behavior! The second derivative terms are &lt;em&gt;dispersive&lt;/em&gt;. In fact, it’s easy to show that the energy &lt;span class=&quot;math&quot;&gt;\(E=u^2+v^2\)&lt;/span&gt; is a conserved quantity for this system (try it!).&lt;/p&gt;
&lt;p&gt;Strictly speaking, Fourier analysis like what we’ve described can’t usually be applied to \eqref{gensys} because the matrices &lt;span class=&quot;math&quot;&gt;\(A_j\)&lt;/span&gt; will not generally be simultaneously diagonalizable (though this analysis can still give us intuition for what each set of terms may do). Worse yet, the individual matrices may not be diagonalizable. Let’s illustrate with a simple case.&lt;/p&gt;
&lt;p&gt;Returning to the wave equation, let’s consider a different way of writing it as a system: &lt;span class=&quot;math&quot;&gt;\[
\begin{align*}
u_t &amp;amp; = v \\
v_t &amp;amp; = u_{xx}.
\end{align*}
\]&lt;/span&gt; It’s easy to check that this system is equivalent to the wave equation – but notice that it’s composed of parts with only even derivatives! (&lt;em&gt;reaction&lt;/em&gt; and &lt;em&gt;diffusion&lt;/em&gt; equations in the terminology of scalar PDEs). This system is of the form \eqref{gensys} with &lt;span class=&quot;math&quot;&gt;\[
\begin{align}
A_0 &amp;amp; = \begin{pmatrix}
0 &amp;amp; 1 \\ 0 &amp;amp; 0
\end{pmatrix}
&amp;amp;
A_2 &amp;amp; = \begin{pmatrix}
0 &amp;amp; 0 \\ 1 &amp;amp; 0
\end{pmatrix}.
\end{align}
\]&lt;/span&gt; Notice that both eigenvalues of both matrices are equal to zero.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>The PETSc DMDA is not lightweight</title>
   <link href="https://www.qixiaodong.tk/en/2014/03/11/DMDA_memory.html"/>
   <updated>2014-03-11T00:00:00+00:00</updated>
   <id>/2014/03/11/DMDA_memory</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2014/03/11/DMDA_memory.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In &lt;a href=&quot;http://lists.mcs.anl.gov/pipermail/petsc-users/2014-January/020018.html&quot;&gt;this PETSc-users thread&lt;/a&gt;, my good friend Matt Knepley claims that the DMDA object is lightweight, and suggests that it is okay to make them willy- nilly. Unfortunately, my experience indicates otherwise. But words are cheap; let’s investigate.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;%load_ext memory_profiler&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;memory-profiling-with-memory_profiler&quot;&gt;Memory profiling with &lt;code&gt;memory_profiler&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;I’ve written a little script that just creates a DA and 3 vecs. In order to make use of &lt;code&gt;memory_profiler&lt;/code&gt;, I’ll call it with system commands. But I’ve pasted the contents here for completeness. If you’re running the notebook, you don’t need to run the next cell.&lt;/p&gt;
&lt;pre class=&quot;sourceCode python&quot;&gt;&lt;code class=&quot;sourceCode python&quot;&gt;&lt;span class=&quot;co&quot;&gt;# contents of da.py&lt;/span&gt;
&lt;span class=&quot;ch&quot;&gt;from&lt;/span&gt; petsc4py &lt;span class=&quot;ch&quot;&gt;import&lt;/span&gt; PETSc
&lt;span class=&quot;ch&quot;&gt;import&lt;/span&gt; sys

&lt;span class=&quot;ot&quot;&gt;@profile&lt;/span&gt;
&lt;span class=&quot;kw&quot;&gt;def&lt;/span&gt; foo(size=&lt;span class=&quot;dv&quot;&gt;128&lt;/span&gt;,ndim=&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;,dof=&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;):
    da = PETSc.DA().create(sizes=[size]*ndim,dof=dof)
    q1 = da.createGlobalVec()
    q2 = da.createGlobalVec()
    q3 = da.createGlobalVec()

&lt;span class=&quot;kw&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ot&quot;&gt;__name__&lt;/span&gt; == &lt;span class=&quot;st&quot;&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;:
    foo(&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt;(sys.argv[&lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;]),&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt;(sys.argv[&lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;]),&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt;(sys.argv[&lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;]))&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Notice that the command line arguments are&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;The size of the grid&lt;/li&gt;
&lt;li&gt;The number of dimensions&lt;/li&gt;
&lt;li&gt;The number of DOFs&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Now let’s run some tests.&lt;/p&gt;
&lt;h3 id=&quot;the-cost-of-a-da&quot;&gt;The cost of a DA&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;!python -m memory_profiler da.py 128 3 1

Filename: da.py

Line #    Mem usage    Increment   Line Contents
================================================
     4   23.473 MiB    0.000 MiB   @profile
     5                             def foo(size=128,ndim=3,dof=1):
     6   72.395 MiB   48.922 MiB       da = PETSc.DA().create([size]*ndim,dof)
     7   72.480 MiB    0.086 MiB       q1 = da.createGlobalVec()
     8   88.484 MiB   16.004 MiB       q2 = da.createGlobalVec()
     9  104.488 MiB   16.004 MiB       q3 = da.createGlobalVec()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The third column (“increment”) is the key here – it shows the increase in total memory usage after executing each line.&lt;/p&gt;
&lt;p&gt;The first thing you notice is that the DA is NOT lightweight. It takes as much memory as 3 Vecs! But that will look cheap in a moment.&lt;/p&gt;
&lt;p&gt;Notice also that the first vec seems to use no memory. I think this is because memory_profiler just tracks peak usage, and the DA creation creates and destroys a vec.&lt;/p&gt;
&lt;p&gt;In what follows, I’ve used sed to extract just the essential lines of the output.&lt;/p&gt;
&lt;p&gt;Let’s try that again, with 2 DOFs.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!python -m memory_profiler da.py 128 3 2 / | sed -n -e 7p -e 10p

     6  296.215 MiB  272.945 MiB       da = PETSc.DA().create([size]*ndim,dof)
     9  328.309 MiB   32.004 MiB       q3 = da.createGlobalVec()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Whoa! Now the DA is 8.5 times as large as a Vec!&lt;/p&gt;
&lt;p&gt;As expected, the Vec is just twice as large. What if we keep increasing the number of DOFs?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!python -m memory_profiler da.py 128 3 3 / | sed -n -e 7p -e 10p
!python -m memory_profiler da.py 128 3 4 / | sed -n -e 7p -e 10p

     6  408.219 MiB  384.949 MiB       da = PETSc.DA().create([size]*ndim,dof)
     9  504.316 MiB   48.004 MiB       q3 = da.createGlobalVec()
     6  520.219 MiB  496.949 MiB       da = PETSc.DA().create([size]*ndim,dof)
     9  648.316 MiB   64.004 MiB       q3 = da.createGlobalVec()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s clear that each additional DOF increases the size of the DA by 112 MB. That’s more than double the size of the whole DA we had with dof=1. And the size of the Vec only increases (appropriately) by 16 MB. So for large numbers of DOFs, the DA will be as large as 7 Vecs.&lt;/p&gt;
&lt;h3 id=&quot;d-and-1d-results&quot;&gt;2D and 1D results&lt;/h3&gt;
&lt;p&gt;The same phenomenon is evident in two dimensions:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!python -m memory_profiler da.py 1024 2 1 / | sed -n -e 7p -e 10p
!python -m memory_profiler da.py 1024 2 2 / | sed -n -e 7p -e 10p
!python -m memory_profiler da.py 1024 2 3 / | sed -n -e 7p -e 10p

     6   48.371 MiB   24.895 MiB       da = PETSc.DA().create([size]*ndim,dof)
     9   64.469 MiB    8.004 MiB       q3 = da.createGlobalVec()
     6  160.398 MiB  136.922 MiB       da = PETSc.DA().create([size]*ndim,dof)
     9  176.492 MiB   16.004 MiB       q3 = da.createGlobalVec()
     6  216.402 MiB  192.926 MiB       da = PETSc.DA().create([size]*ndim,dof)
     9  264.500 MiB   24.004 MiB       q3 = da.createGlobalVec()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Again we see that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The 1-DOF DA costs 3 Vecs&lt;/li&gt;
&lt;li&gt;The 2-DOF DA costs about 8.5 Vecs&lt;/li&gt;
&lt;li&gt;Asymptotically, a DA with many DOFs costs 7 Vecs&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What about 1D?&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;!python -m memory_profiler da.py 1000000 1 1 / | sed -n -e 7p -e 10p
!python -m memory_profiler da.py 1000000 1 2 / | sed -n -e 7p -e 10p
!python -m memory_profiler da.py 1000000 1 3 / | sed -n -e 7p -e 10p

     6   47.164 MiB   23.688 MiB       da = PETSc.DA().create([size]*ndim,dof)
     9   70.168 MiB    7.648 MiB       q3 = da.createGlobalVec()
     6   77.684 MiB   54.207 MiB       da = PETSc.DA().create([size]*ndim,dof)
     9  123.582 MiB   15.285 MiB       q3 = da.createGlobalVec()
     6  100.570 MiB   77.094 MiB       da = PETSc.DA().create([size]*ndim,dof)
     9  169.355 MiB   22.914 MiB       q3 = da.createGlobalVec()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These results are relatively sane: regardless of the number of DOFs, the ratio is 3-3.5.&lt;/p&gt;
&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;So DAs are not lightweight. They cost as much as 3-8.5 Vecs, and their cost increases with the number of DOFs. It is not clear to me &lt;em&gt;a priori&lt;/em&gt; why their cost should even depend on the number of DOFs.&lt;/p&gt;
&lt;p&gt;In PyClaw, this means that the DAs always occupy much more memory than the Vecs themselves! This is becoming a serious bottleneck for our current 3D simulations on Shaheen.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>The Schrodinger equation is not a reaction-diffusion equation</title>
   <link href="https://www.qixiaodong.tk/en/2014/02/22/schrodinger-is-not-diffusion.html"/>
   <updated>2014-02-22T00:00:00+00:00</updated>
   <id>/2014/02/22/schrodinger-is-not-diffusion</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2014/02/22/schrodinger-is-not-diffusion.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Recently, a stackexchange answer claimed that &lt;a href=&quot;http://scicomp.stackexchange.com/a/10878/123&quot;&gt;the Schrodinger equation is effectively a reaction-diffusion equation&lt;/a&gt;. I’ll set aside semantic arguments about the meaning of “effectively”, and give a more obvious example to explain why I think this statement is misleading.&lt;/p&gt;
&lt;p&gt;Consider the wave equation&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[u_{tt} = u_{xx}\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Introducing a new variable &lt;span class=&quot;math&quot;&gt;\(v=u_t\)&lt;/span&gt; we can rewrite the wave equation as&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[
\begin{align*}
v_t &amp;amp; = u_{xx} \\
u_t &amp;amp; = v.
\end{align*}
\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Observe that the first of these equation is the diffusion equation, while the second is a reaction equation. Thus we have reaction-diffusion!&lt;/p&gt;
&lt;p&gt;Right?&lt;/p&gt;
&lt;p&gt;Wrong. We’ve disguised the true nature of this equation by applying our intuition (which is based on scalar PDEs) to a system of PDEs. In the same way, the “reaction-diffusion” label for Schrodinger is obtained by applying intuition based on PDEs with real coefficients to a PDE with complex coefficients.&lt;/p&gt;
&lt;p&gt;Of course, in both cases you can use numerical methods that are appropriate for reaction-diffusion problems in order to solve a wave equation.&lt;br /&gt;&lt;a href=&quot;http://nbviewer.ipython.org/github/ketch/exposition/blob/master/Wave%20equation%20as%20reaction-diffusion.ipynb&quot;&gt;Here is a quick ipython notebook implementation of the obvious method for the system above&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Open access is about open access, not journals</title>
   <link href="https://www.qixiaodong.tk/en/2013/12/13/open_access_means_open_access.html"/>
   <updated>2013-12-13T00:00:00+00:00</updated>
   <id>/2013/12/13/open_access_means_open_access</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2013/12/13/open_access_means_open_access.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In October, &lt;a href=&quot;http://news.sciencemag.org/sites/default/files/media/Open%20Access%20SurveySummary_11082013_0.pdf&quot;&gt;Science Magazine conducted a survey regarding open access&lt;/a&gt;. Among the questions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;How important is it for scientific papers to be freely accessible to the public?&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Of the papers that you published in the last 3 years, what percentage did you submit to fully open access journals?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;72%&lt;/strong&gt; replied “extremely important” to the first question, while only &lt;strong&gt;58%&lt;/strong&gt; indicated they had submitted any paper to an open access journal. Does this mean that scientists are not acting in agreement with their own principles?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;No!&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;It may shock the editors of Science, but the open access movement is not about changing the funding model for academic publishers.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Open access means that research results can be read by anyone, for free.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Scientists can accomplish that without any help from publishers. The fact is that most scientists don’t view &lt;em&gt;open access journals&lt;/em&gt; as the best way to make their work accessible. Another question from the Science survey asked&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Which options for making papers freely available do you prefer?&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The most common answer (66%) was &lt;strong&gt;“Immediate access through a repository, such as PubMedCentral or Arxiv, or on an author’s web site”&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;This is quick and painless. &lt;a href=&quot;http://www.sherpa.ac.uk/romeo/statistics.php?la=en&amp;amp;fIDnum=|&amp;amp;mode=simple&quot;&gt;It is allowed by an overwhelming majority of publishers&lt;/a&gt;. It requires no mandates from governments or universities. It requires no extra funding. Anyone can do it, and every scientist who cares a whit about open access already has done it.&lt;/p&gt;
&lt;p&gt;If someone tells you that we need governments or publishers to intervene to make open access possible, you can be sure that his agenda is something other than open access. The only obstacle left is our own apathy.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>A Tale of Two Theorems</title>
   <link href="https://www.qixiaodong.tk/en/2013/10/14/CFL-disk.html"/>
   <updated>2013-10-14T00:00:00+00:00</updated>
   <id>/2013/10/14/CFL-disk</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2013/10/14/CFL-disk.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In their &lt;a href=&quot;http://dx.doi.org/10.1147/rd.112.0215&quot;&gt;celebrated 1928 paper&lt;/a&gt;, Courant, Friedrichs, and Lewy proved a geometric condition that must be satisfied by a convergent &lt;strong&gt;partial&lt;/strong&gt; differential equation discretization – the famous CFL condition. Briefly, the CFL theorem says that the numerical method must transport information at least as quickly as information travels in the true PDE solution. The proof is geometric and is conveyed through numerous diagrams.&lt;/p&gt;
&lt;p&gt;Exactly fifty years later, in 1978, Rolf Jeltsch and Olavi Nevanlinna &lt;a href=&quot;http://dx.doi.org/10.1007/BF01932030&quot;&gt;published a theorem&lt;/a&gt; [JN] that deals with bounding the modulus of a polynomial &lt;span class=&quot;math&quot;&gt;\(\psi(z)\)&lt;/span&gt; over a disk of the form &lt;span class=&quot;math&quot;&gt;\[D_r = {z \in \{\mathbb C} : |z-r|\le r\}.\]&lt;/span&gt; Their theorem says that if &lt;span class=&quot;math&quot;&gt;\(\psi(z) = 1 + z + a_2 z^2 + \cdots + a_s z^s\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(|\psi(z)|\le 1\)&lt;/span&gt; for all &lt;span class=&quot;math&quot;&gt;\(z\)&lt;/span&gt; in such a disk &lt;span class=&quot;math&quot;&gt;\(D_r\)&lt;/span&gt;, then the disk radius &lt;span class=&quot;math&quot;&gt;\(r\)&lt;/span&gt; is at most &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt;. The proof of this result is, of course, purely algebraic.&lt;/p&gt;
&lt;p&gt;These results apparently have nothing to do with one another. And yet it turns out that &lt;strong&gt;they are equivalent statements!&lt;/strong&gt; That is, the CFL theorem can be proved using the JN disk theorem. And the JN disk theorem can be proved using the CFL condition (and no algebraic techniques). This was explained in &lt;a href=&quot;http://dx.doi.org/10.1007/BF01389633&quot;&gt;a beautiful paper of Sanz-Serna and Spijker&lt;/a&gt; [SS] in 1986, and the result deserves to be much more well known.&lt;/p&gt;
&lt;h3 id=&quot;first-order-upwinding&quot;&gt;First order upwinding&lt;/h3&gt;
&lt;p&gt;Consider the problem of approximating the value &lt;span class=&quot;math&quot;&gt;\(u(x_i,t_n)\)&lt;/span&gt; for the advection equation &lt;span class=&quot;math&quot;&gt;\[u_t + u_x = 0.\]&lt;/span&gt; The exact solution can be obtained by characteristics from the previous time level: &lt;span class=&quot;math&quot;&gt;\[u(x_i,t_n) = u(x_i-k,t_{n-1}),\]&lt;/span&gt; where &lt;span class=&quot;math&quot;&gt;\(k\)&lt;/span&gt; is the time step size. The CFL theorem says that the stencil used for approximating &lt;span class=&quot;math&quot;&gt;\(u(x_i,t_n)\)&lt;/span&gt; must enclose the point &lt;span class=&quot;math&quot;&gt;\(x_i-k\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let’s discretize the advection equation in space using upwind differences: &lt;span class=&quot;math&quot;&gt;\[U_i&amp;#39;(t) = -\left(U_i-U_{i-1}\right).\]&lt;/span&gt; Here for simplicity we’ve assumed a spatial mesh width of 1. Taking periodic boundary conditions, this semi-discretization is a system of ODEs of the form &lt;span class=&quot;math&quot;&gt;\(U&amp;#39;=LU\)&lt;/span&gt; where &lt;span class=&quot;math&quot;&gt;\(L\)&lt;/span&gt; is the circulant matrix &lt;span class=&quot;math&quot;&gt;\[
\begin{pmatrix}
-1 &amp;amp; &amp;amp; &amp;amp; 1 \\
1  &amp;amp; -1 &amp;amp; &amp;amp; \\
&amp;amp; \ddots &amp;amp; \ddots \\
&amp;amp; &amp;amp; 1 &amp;amp; -1 \\
\end{pmatrix}\]&lt;/span&gt; (as usual, all the omitted entries are zero). The eigenvalues of this matrix all lie on the boundary of the disk of radius one centered at &lt;span class=&quot;math&quot;&gt;\(z=-1\)&lt;/span&gt;, which we denote by &lt;span class=&quot;math&quot;&gt;\(D_1\)&lt;/span&gt;. Here are the eigenvalues of a 50-point discretization:&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;https://dl.dropboxusercontent.com/u/656693/wiki_images/disk_eigen.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;If we discretize in time with Euler’s method, we get the scheme &lt;span class=&quot;math&quot;&gt;\[U^n_i = U^{n-1}_i - k\left(U_i-U_{i-1}\right).\]&lt;/span&gt; This scheme computes the solution at &lt;span class=&quot;math&quot;&gt;\((x_i,t_n)\)&lt;/span&gt; using values at &lt;span class=&quot;math&quot;&gt;\((x_{i-1},t_{n-1})\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\((x_i,t_{n-1})\)&lt;/span&gt;, so the CFL theorem says it can be convergent only if &lt;span class=&quot;math&quot;&gt;\(x_i-k\)&lt;/span&gt; lies in the interval &lt;span class=&quot;math&quot;&gt;\((x_{i-1},x_i)\)&lt;/span&gt;. Since &lt;span class=&quot;math&quot;&gt;\(x_{i-1} = x_i - 1\)&lt;/span&gt;, this holds iff the step size &lt;span class=&quot;math&quot;&gt;\(k\)&lt;/span&gt; is smaller than 1.&lt;/p&gt;
&lt;p&gt;This result – that the first-order upwind method is stable and convergent only for CFL number at most one – is well known, and can also be derived using basic method of lines stability theory. The stability function for Euler’s method is &lt;span class=&quot;math&quot;&gt;\(\psi(z) = 1 + z\)&lt;/span&gt;, so it is stable only if &lt;span class=&quot;math&quot;&gt;\(z=k\lambda\)&lt;/span&gt; lies in the disk &lt;span class=&quot;math&quot;&gt;\(\{z : |1+z|\le 1\} = D_1\)&lt;/span&gt; for each eigenvalue &lt;span class=&quot;math&quot;&gt;\(\lambda\)&lt;/span&gt; of &lt;span class=&quot;math&quot;&gt;\(L\)&lt;/span&gt;. What we have seen in the foregoing is that this stability condition can be derived directly from the CFL condition, without considering the eigenvalues of &lt;span class=&quot;math&quot;&gt;\(L\)&lt;/span&gt; or the stability region of Euler’s method.&lt;/p&gt;
&lt;h3 id=&quot;proving-the-jn-disk-theorem-via-the-cfl-theorem&quot;&gt;Proving the JN disk theorem via the CFL theorem&lt;/h3&gt;
&lt;p&gt;For higher order discretizations, the CFL condition is necessary but not generally sufficient for stability. Nevertheless, we can use it to derive the JN disk theorem. I’ll restrict the explanation here to Runge-Kutta methods, but the extension to multistep methods is very simple. Suppose that we discretize in time using a Runge-Kutta method with &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt; stages. In each stage, one point further to the left is used, so typically the stencil for computing &lt;span class=&quot;math&quot;&gt;\(u(x_i,t_n)\)&lt;/span&gt; includes the values from the previous step at &lt;span class=&quot;math&quot;&gt;\(x_{i-s}, x_{i-s+1}, \dots, x_i\)&lt;/span&gt;. Thus the CFL theorem says the method cannot be convergent unless &lt;span class=&quot;math&quot;&gt;\(x_i-k\)&lt;/span&gt; lies in the interval &lt;span class=&quot;math&quot;&gt;\((x_{i-s},x_i)\)&lt;/span&gt;; i.e., unless &lt;span class=&quot;math&quot;&gt;\(k\le s\)&lt;/span&gt;. Meanwhile, the stability function &lt;span class=&quot;math&quot;&gt;\(\psi(z)\)&lt;/span&gt; of the Runge-Kutta method is a polynomial of degree at most &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt;. Method of lines analysis tells us that the full discretization is stable if &lt;span class=&quot;math&quot;&gt;\(kD_1\)&lt;/span&gt; lies inside the region &lt;span class=&quot;math&quot;&gt;\(\{z : |\psi(z)|\le 1\}.\)&lt;/span&gt; Since we know it is unstable for &lt;span class=&quot;math&quot;&gt;\(k&amp;gt;s\)&lt;/span&gt;, this implies that if &lt;span class=&quot;math&quot;&gt;\(|\psi(z)|\le 1\)&lt;/span&gt; over the disk &lt;span class=&quot;math&quot;&gt;\(D_k\)&lt;/span&gt;, then &lt;span class=&quot;math&quot;&gt;\(k \le s\)&lt;/span&gt;.&lt;/p&gt;
&lt;h3 id=&quot;recap&quot;&gt;Recap&lt;/h3&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;An &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt;-stage upwind discretization has stencil width &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The CFL condition implies that this discretization cannot be convergent for Courant numbers larger than &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;The spectrum of the semi-discretization is the boundary of the disk &lt;span class=&quot;math&quot;&gt;\(D_1\)&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;Stability analysis implies that the full discretization is convergent if the scaled spectrum &lt;span class=&quot;math&quot;&gt;\(kD_1 = D_k\)&lt;/span&gt; lies inside the stability region of the time discretization.&lt;/li&gt;
&lt;li&gt;Thus no &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt;-stage time discretization can have a stability region including the disk larger than &lt;span class=&quot;math&quot;&gt;\(D_s\)&lt;/span&gt; (this is the content of the JN disk theorem).&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;ellipses&quot;&gt;Ellipses&lt;/h3&gt;
&lt;p&gt;Of course, we didn’t have to choose first-order upwinding in space; we could have taken any spatial discretization. For instance, if we use centered differences: &lt;span class=&quot;math&quot;&gt;\[U_i&amp;#39;(t) = -\left(U_{i+1}-U_{i-1}\right)\]&lt;/span&gt; then the spectrum of the semi-discretization lies on the imaginary axis in the interval &lt;span class=&quot;math&quot;&gt;\([-i,i]\)&lt;/span&gt;. Then the same line of reasoning then tells us that the largest imaginary-axis interval of stability for an &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt;-stage method is &lt;span class=&quot;math&quot;&gt;\([-is,is]\)&lt;/span&gt;. By considering convex combinations of upwind and centered differences, we get similar results for a family of ellipses; this is the content of Theorem 5 of [SS].&lt;/p&gt;
&lt;h3 id=&quot;parabolic-problems&quot;&gt;Parabolic problems&lt;/h3&gt;
&lt;p&gt;It’s well known that the largest interval of stability of a consistent &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt;-stage method on the negative real axis has length &lt;span class=&quot;math&quot;&gt;\(s^2\)&lt;/span&gt;; the corresponding polynomials are (shifted) Chebyshev polynomials. You might hope that this could also be deduced by considering a centered difference semi-discretization of the heat equation and applying the CFL theorem. That would be very neat, since it would provide a connection between PDE stability theory and the optimality of Chebyshev polynomials.&lt;/p&gt;
&lt;p&gt;Indeed, explicit time discretizations generally lead to step size restrictions depending on the square of the spatial mesh width when paired with the usual centered spatial discretization. But the CFL theorem is not sharp for these discretizations; it only tells us that &lt;span class=&quot;math&quot;&gt;\(k\)&lt;/span&gt; must vanish vanish more quickly than the spatial mesh width. So no deduction along these lines seems possible.&lt;/p&gt;
&lt;p&gt;#spnetwork #recommend doi:/10.1007/BF01389633&lt;/p&gt;
&lt;p&gt;#discusses doi:10.1147/rd.112.0215 #discusses doi:10.1007/BF01932030&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Documentation, testing, and default arguments for your MATLAB packages</title>
   <link href="https://www.qixiaodong.tk/en/2013/10/12/MATLAB-docs-testing.html"/>
   <updated>2013-10-12T00:00:00+00:00</updated>
   <id>/2013/10/12/MATLAB-docs-testing</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2013/10/12/MATLAB-docs-testing.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I primarily develop code in Python and Fortran, but I also use MATLAB for certain things. For instance, I haven’t found a Python-friendly nonlinear optimization package that measures up to the capabilities of MATLAB’s optimization toolbox (fmincon). So my RK-opt package for optimising Runge-Kutta methods is written all in MATLAB.&lt;/p&gt;
&lt;p&gt;The trouble is that working in Python has spoiled me for other languages. Python has the excellent &lt;a href=&quot;http://sphinx-doc.org/&quot;&gt;Sphinx&lt;/a&gt; package for writing &lt;strong&gt;beautiful documentation&lt;/strong&gt;. Python has the &lt;a href=&quot;http://nose.readthedocs.org/&quot;&gt;nosetests&lt;/a&gt; harness for easily writing and running &lt;strong&gt;tests&lt;/strong&gt;. And Python has &lt;a href=&quot;http://www.diveintopython.net/power_of_introspection/optional_arguments.html&quot;&gt;a simple syntax for including &lt;strong&gt;optional function arguments&lt;/strong&gt; with default values&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;MATLAB doesn’t support any of these things so elegantly*.&lt;/p&gt;
&lt;p&gt;*&lt;em&gt;This was true one year ago, when I started writing this. But it seems things have improved – see below&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;In any case, all is not lost – I have found reasonable approximations in the MATLAB ecosystem, and in some cases I’ve adapted the Python tools to work with MATLAB.&lt;/p&gt;
&lt;h3 id=&quot;documenting-matlab-projects-using-sphinx&quot;&gt;Documenting MATLAB projects using Sphinx&lt;/h3&gt;
&lt;p&gt;In principle, Sphinx can be used to write documentation for packages written in any language. However, its &lt;a href=&quot;http://sphinx-doc.org/ext/autodoc.html&quot;&gt;autodoc&lt;/a&gt; functionality, which automatically extracts Python docstrings, doesn’t work with MATLAB. For RK-Opt, I hacked together a simple workaround in &lt;a href=&quot;https://github.com/ketch/RK-opt/blob/master/doc/m2rst.py&quot;&gt;this 74-line Python file&lt;/a&gt;. It goes through a given directory, extracts the MATLAB docstring for each function, and compiles them into an .rst file for Sphinx processing. You can see an &lt;a href=&quot;http://numerics.kaust.edu.sa/RK-opt/RK-coeff-opt.html&quot;&gt;example of the results here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;: &lt;em&gt;as I’m writing this, I’ve discovered a new &lt;a href=&quot;https://bitbucket.org/bwanamarko/sphinx-contrib/src/tip/matlabdomain/README.rst&quot;&gt;MATLAB extension for Sphinx’s autodoc&lt;/a&gt;. I will have to try it out sometime; please let me know in the comments if you’ve used it.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id=&quot;automated-testing-in-matlab&quot;&gt;Automated testing in MATLAB&lt;/h3&gt;
&lt;p&gt;I’ve become convinced that writing at least one or two tests is worthwhile for even small, experimental packages. In Python, it’s simple to include test in the docs and run them with doctest, or write test suites and run them with nosetest. For MATLAB, I would have recommended the third-party &lt;a href=&quot;http://www.mathworks.com/matlabcentral/fileexchange/22846-matlab-xunit-test-framework&quot;&gt;xunit framework&lt;/a&gt;. But it seems that this year &lt;a href=&quot;http://www.mathworks.com/help/matlab/matlab-unit-test-framework.html&quot;&gt;Mathworks finally added this functionality to MATLAB&lt;/a&gt;. Even so, you might want to use xunit because &lt;a href=&quot;https://github.com/tgs/matlab-xunit-doctest&quot;&gt;it’s possible to run doctests with it&lt;/a&gt; but not with MATLAB’s new built-in framework. Also, you can get XML output from xunit, which a number of other tools can analyze (for instance, to tell you about code coverage). For an example of how to use xunit, &lt;a href=&quot;https://github.com/ketch/RK-opt/blob/master/RK-coeff-opt/test_rkopt.m&quot;&gt;see RK-Opt&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Again, I’d be interested to hear from you in the comments if you’ve used MATLAB’s new built-in test harness.&lt;/p&gt;
&lt;h3 id=&quot;optional-arguments-with-default-values&quot;&gt;Optional arguments with default values&lt;/h3&gt;
&lt;p&gt;MATLAB does allow the user to specify only some subset of the input arguments to a function – as long as the omitted ones all come after the included ones. I used to take advantage of this, with this kind of code inside the function:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;if nargin&amp;lt;5 rmax=50; end
if nargin&amp;lt;4 eps=1.e-10; end&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This is a reasonable solution in very small functions, but it breaks if you want to add new arguments that don’t come at the end, and if you want to specify the very last value then you have to specify them all. A better general solution is the &lt;a href=&quot;http://www.mathworks.com/help/matlab/ref/inputparserclass.html&quot;&gt;inputParser object&lt;/a&gt;. It’s much less natural than Python’s syntax, but the result for the user is the same: arbitrary subsets of the optional arguments can be specified; default values will be used for the rest. As a bonus, you can check the types of the inputs. &lt;a href=&quot;https://github.com/ketch/RK-opt/blob/master/polyopt/opt_poly_bisect.m#L258&quot;&gt;Here’s an example of usage&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If you know of better ways to do any of these things, please let me know in the comments!&lt;/p&gt;
&lt;p&gt;Of course, it’s entirely possible to develop large, well-documented, well-tested, user-friendly packages in MATLAB – &lt;a href=&quot;http://www.chebfun.org/&quot;&gt;Chebfun&lt;/a&gt; is one example. It’s just that this is the exception and not the rule in the MATLAB community. Hopefully better integration with testing and documentation tools will improve this situation.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Giving a math talk using IPython notebook slides and Wakari</title>
   <link href="https://www.qixiaodong.tk/en/2013/09/21/ipython_notebook_slides_talks.html"/>
   <updated>2013-09-21T00:00:00+00:00</updated>
   <id>/2013/09/21/ipython_notebook_slides_talks</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2013/09/21/ipython_notebook_slides_talks.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;giving-a-math-talk-using-ipython-notebook-slides-and-wakari&quot;&gt;Giving a math talk using IPython notebook slides and Wakari&lt;/h1&gt;
&lt;p&gt;Last week I gave my first full-length &lt;em&gt;executable talk&lt;/em&gt;: one in which I showed the code that produced (almost) all the results I presented. You can &lt;a href=&quot;http://www.davidketcheson.info/talks/SciCADE-talk.slides.html#/&quot;&gt;see the talk&lt;/a&gt; and &lt;a href=&quot;https://www.wakari.io/sharing/bundle/ketch/SciCADE-talk&quot;&gt;run the talk on Wakari&lt;/a&gt; (or download it and run it locally). All you need is Python with its scientific packages (numpy, scipy, sympy – I recommend just installing &lt;a href=&quot;http://www.continuum.io/downloads&quot;&gt;Anaconda Python&lt;/a&gt; if you haven’t already). I took things a step further and actually ran a bunch of demo code live on Wakari. I was excited beforehand, and judging by the number of people that came into the room right immediately before my talk (and left immediately afterward), so was the audience. But I was disappointed with how it went. Here’s why.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Composing a talk in an IPython notebook is counterintuitive&lt;/strong&gt;. When I give a talk, I try to tell a compelling and coherent story. This requires a certain mindset, and somehow the IPython notebook helps rather than hinders – at least, for me. I think there is too much of a disconnect between how things look when I’m writing them and how they look as slides. In theory Beamer is worse in this respect, but it felt worse with the notebook.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It is hard to engage your audience with code&lt;/strong&gt;. Almost nobody can digest complicated formulas during a talk, which is why even when I speak to mathematicians I usually have very few equations and lots of pictures. Well, the same goes for code – nobody can digest more than a few simple lines on a slide. I think I did a good job of keeping the code short, high-level, and intuitive, but it still felt flat.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Code in the talk needs to execute very quickly&lt;/strong&gt;. This is obvious for code that you run as a live demo, but I found it necessary also for code snippets that I didn’t run live (but where I wanted to show the results). That’s because when you recompile your talk (which I do &lt;em&gt;many, many times&lt;/em&gt; during the composing process), you have to wait for all that code to execute again. It doesn’t help that things seem to run significantly slower on Wakari than on my laptop.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The IPython notebook format is not (yet) good at displaying graphs and tables&lt;/strong&gt;. Talks full of text put people to sleep, and code is text, so this kind of talk already has a strike against it. But to makes matters worse, I can’t insert images into my notebook slides without putting an ugly line of code above them. And the notebook refuses to let me embed vector graphics formats (like PDF), so I have to degrade them to slightly blurry pngs.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;It’s hard to judge how long a code-based talk will take&lt;/strong&gt;. I usually judge conservatively so I can move at a relaxed pace. But my demo took much longer than I planned (partly due to the difficulty of using a Spanish keyboard), and I had to rush through the last third of the talk in about 2 minutes. I guess this is something to learn with practice.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;The default fonts in notebook-converted slides are just too small&lt;/strong&gt;. They are fine for someone sitting at a computer screen, but much too small for the projector screen at the front of a large screen. You can adjust the size in the browser using ‘+’, but the result looks ugly for some reason. I know the fonts can be changed using CSS, and I’ll make them larger next time.&lt;/p&gt;
&lt;p&gt;For me, the worst condemnation of any talk is that no questions are asked afterward. I haven’t had that happen in a long time, but this was close: there was only one question, and that question demonstrated that I had completely failed to convey what was going on behind a lot of the code I had showed.&lt;/p&gt;
&lt;p&gt;It feels too soon to give up on this approach to talks; I will try it again some time. Perhaps I just haven’t found the right use for this medium. If you have tried giving a similar talk, I’d love to hear your opinion or suggestions.&lt;/p&gt;
&lt;p&gt;One note about the slides: parts of them will not make sense in the absence of my verbal explanations. I generally avoid including a lot of explanatory text in the slides. I actually added a lot more than usual in this case because I was planning to post them online.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Open scientific collaboration</title>
   <link href="https://www.qixiaodong.tk/en/2012/12/22/habits-of-open-scientist-4-collab.html"/>
   <updated>2012-12-22T00:00:00+00:00</updated>
   <id>/2012/12/22/habits-of-open-scientist-4-collab</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2012/12/22/habits-of-open-scientist-4-collab.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This is the fourth post in my &lt;a href=&quot;http://davidketcheson.info/2012/07/31/habits-of-open-scientist.html&quot;&gt;series on habits of the open scientist&lt;/a&gt;. Here I discuss the fourth habit, &lt;strong&gt;open collaboration&lt;/strong&gt;. The previous post was on &lt;a href=&quot;http://davidketcheson.info/2012/08/22/habits-of-open-scientist-3-pre.html&quot;&gt;Pre-publication dissemination of research&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;As mentioned in the introduction to this series, the first three habits are truly essential for any conscientious scientist. With the fourth habit, we’re moving into things that are valuable but less essential – &lt;em&gt;advanced open science&lt;/em&gt;, if you will.&lt;/p&gt;
&lt;p&gt;What do I mean by open collaboration? The use of online tools and social media to connect with new collaborators and provide your own expertise where it is needed most. For an excellent introduction to the subject, go read &lt;a href=&quot;http://michaelnielsen.org/blog/reinventing-discovery/&quot;&gt;Michael Nielsen’s book, &lt;em&gt;Reinventing Discovery&lt;/em&gt;&lt;/a&gt;. Here I’ll just focus on a few examples from my own experience:&lt;/p&gt;
&lt;h3 id=&quot;scientific-qa-sites&quot;&gt;Scientific Q&amp;amp;A sites&lt;/h3&gt;
&lt;p&gt;Often scientific research involves elements of work that have been done before or are already well understood – by someone, somewhere. Sometimes this work is published and readily available, but other times it is unpublished or perhaps published in a place you wouldn’t know to look. Finding the person with the specialized knowlege you need might take much longer than “reinventing the wheel”, i.e. redoing the work yourself. Enter StackExchange, an engine for connecting questions with correct answers and making them readily available.&lt;/p&gt;
&lt;p&gt;I’m an avid participant in (and former moderator of) the &lt;a href=&quot;http://scicomp.stackexchange.com&quot;&gt;Stack Exchange for Computational Science&lt;/a&gt;. I also use &lt;a href=&quot;http://mathoverflow.net&quot;&gt;Mathoverflow&lt;/a&gt; and &lt;a href=&quot;http://stackoverflow.com&quot;&gt;Stack Overflow&lt;/a&gt;. Some personal examples of the kind of connections I’m talking about are &lt;a href=&quot;http://math.stackexchange.com/questions/86977/polynomials-that-are-orthogonal-over-curves-in-the-complex-plane/&quot;&gt;here&lt;/a&gt; and &lt;a href=&quot;http://scicomp.stackexchange.com/questions/65/are-there-operator-splitting-approaches-for-multiphysics-pdes-that-achieve-high&quot;&gt;here&lt;/a&gt;. These are conversations that would never have taken place “in real life” simply because the people involved have never met each other.&lt;/p&gt;
&lt;p&gt;I also find the &lt;a href=&quot;http://tex.stackexchange.com&quot;&gt;TeX stack exchange&lt;/a&gt; to be a gold mine, and typically far more useful than browsing through package documentation on CTAN.&lt;/p&gt;
&lt;h3 id=&quot;social-networks-like-google&quot;&gt;Social networks like &lt;a href=&quot;http://plus.google.com&quot;&gt;Google+&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I use Google+ (and previously Reader, which was a far superior tool) for sharing new papers that I think may be of interest to my collaborators. I’ve also used it to debate journals’ editorial policies (with the editors) and for preliminary planning of conferences and proposals – to find out who may be interested in participating. It’s certainly not suited to discussing scientific or mathematical concepts in any detail, and it is annoyingly difficult to sort through new things that are posted. I think that Facebook is less useful for this purpose because Facebook is used primarily for personal content whereas a large community of G+ users (of which I am part) consider it to be a platform for sharing professional content. But I’m not a good judge – I don’t even have a Facebook account.&lt;/p&gt;
&lt;h3 id=&quot;github&quot;&gt;&lt;a href=&quot;http://github.com&quot;&gt;Github&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;I wanted to say “sites like Github”, but I don’t think there are any others. Online code hosting sites have long facilitated collaboration between existing teams, but Github takes this to a new level by explicitly promoting collaboration between people who have never met. Surprisingly, this paradigm shift didn’t require any new technology. Rather, it stems from a combination of their “code first, ask permission later” pull-request mindset and subtle differences in the user interface – like a “fork me” button on every page, just begging you to modify some stranger’s code.&lt;/p&gt;
&lt;p&gt;Now this philosophy – and use 0f Github – has moved beyond just sharing what we usually think of as computer code. For instance, Carl Boettiger puts &lt;a href=&quot;http://github.com/cboettig/labnotebook&quot;&gt;the full source of his Jekyll-based website on Github&lt;/a&gt;, which enabled me (simply by forking it) to easily set up this site.&lt;/p&gt;
&lt;h3 id=&quot;a-word-of-caution&quot;&gt;A word of caution&lt;/h3&gt;
&lt;p&gt;As useful as all the above are, I’ve found that they can also be a way of wasting time. You may find this to be the case if you’re merely trading opinions with strangers or consuming tidbits of information that aren’t really relevant to your research – for instance, I find that my time spent on the &lt;a href=&quot;http://academia.stackexchange.com&quot;&gt;Academia Stack Exchange&lt;/a&gt; is of dubious value. I stepped down from moderating the SciComp Stack Exchange because I felt it was too time-consuming. But if used in a focused way, open collaboration tools can accelerate, enrich, and expand your research.&lt;/p&gt;
&lt;p&gt;What other tools or sites ought to be mentioned here? Let me know in the comments.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Adopting the Reproducible Research Standard</title>
   <link href="https://www.qixiaodong.tk/en/2012/12/06/reproducible-research-standard.html"/>
   <updated>2012-12-06T00:00:00+00:00</updated>
   <id>/2012/12/06/reproducible-research-standard</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2012/12/06/reproducible-research-standard.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Back in July, I read Victoria Stodden’s work on licensing reproducible research. Victoria has proposed the Reproducible Research Standard (RRS), which is an amalgamation of recommended licenses for what she calls the &lt;em&gt;research compendium&lt;/em&gt;. The research compendium is the full set of outputs of a research project, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The research paper&lt;/li&gt;
&lt;li&gt;Additional media, such as movies&lt;/li&gt;
&lt;li&gt;Computer code&lt;/li&gt;
&lt;li&gt;Data&lt;/li&gt;
&lt;li&gt;A record of the computing environment used to process the code and data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The idea is that all of these components are part of your research and someone wanting to understand your research may need access to all of them. The RRS consists of the following licenses:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://creativecommons.org/licenses/by/3.0/&quot;&gt;Creative Commons Attribution (BY)&lt;/a&gt; for &lt;strong&gt;media&lt;/strong&gt; (text, figures, movies)&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/BSD_licenses%233-clause_license_.28.22New_BSD_License.22_or_.22Modified_BSD_License.22.29&quot;&gt;Modified BSD&lt;/a&gt; for &lt;strong&gt;code&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://sciencecommons.org/resources/faq/database-protocol&quot;&gt;Science Commons Database Protocol&lt;/a&gt; for &lt;strong&gt;data&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For the most part, this is easy enough to implement: the current academic research system frankly doesn’t care what you do with your code, data or miscellaneous media outputs. And I think that actually releasing those is the most important part of the RRS. But the text and figures of the paper itself must be published in a journal, and typically the journal will want the copyright – preventing you from releasing those media under CC-BY.&lt;/p&gt;
&lt;p&gt;Nevertheless, I’ve attempted to follow the full RRS with each of the two papers I’ve had accepted since then. &lt;a href=&quot;http://arxiv.org/abs/1111.3499&quot;&gt;The first&lt;/a&gt; (still in press) was accepted to the SIAM Journal on Scientific Computing (SISC). The code is licensed under modified BSD as part of the &lt;a href=&quot;https://github.com/clawpack/sharpclaw&quot;&gt;SharpClaw&lt;/a&gt; package (now rolled into &lt;a href=&quot;https://github.com/clawpack/pyclaw&quot;&gt;PyClaw&lt;/a&gt;). After reading &lt;a href=&quot;http://adamdsmith.wordpress.com/2009/07/07/copyright-copywrong/&quot;&gt;one author’s experience retaining copyright to an article published by SIAM&lt;/a&gt;, I decided to try the same approach of modifying the copyright transfer agreement by &lt;a href=&quot;http://adamdsmith.wordpress.com/2009/07/07/copyright-copywrong/#jp-carousel-138&quot;&gt;striking out the transfer of copyright&lt;/a&gt;. I suspected that the instance just linked to went “below the radar”, and I wanted to be completely above-board, so I pointed out to SIAM that I had modified the agreement. What made this particularly interesting is that one of my co-authors on the paper is Randy LeVeque, chair of the SIAM journals committee.&lt;/p&gt;
&lt;p&gt;Eventually, SIAM objected “on the grounds that non-exclusive right to publish doesn’t prohibit others from publishing for profit, which may be to [the authors’] disadvantage as well.” They agreed instead to an addendum generated via http://scholars.sciencecommons.org/ that retains for the authors the right to post the final article on any public server, as long as publication in SISC is stated. Since this gave me what I wanted in practical terms, I agreed and signed the copyright transfer + addendum. I’ve been told that an ad hoc committee of SIAM leadership is now discussing how SIAM should handle these copyright questions like this.&lt;/p&gt;
&lt;p&gt;I came away from this feeling like we had made progress, but I still wanted to see if I could implement the full RRS with respect to the next paper. My &lt;a href=&quot;http://arxiv.org/pdf/1201.3035v3.pdf&quot;&gt;next accepted paper&lt;/a&gt; (also still in press) was a submission to &lt;a href=&quot;msp.org/camcos/&quot;&gt;Communications in Applied Mathematics and Computational Science&lt;/a&gt;, published by the extremely progressive not-for-profit &lt;a href=&quot;http://msp.org/about/&quot;&gt;Math­em­at­ic­al Sci­ences Pub­lish­ers&lt;/a&gt;. This is a truly remarkable journal that will be the subject of another blog post in the near future, but what’s important in this context is that the journal doesn’t require authors to transfer copyright! They only require a &lt;a href=&quot;http://msp.berkeley.edu/editorial/uploads/camcos/accepted/120712-Qi/copyright.pdf&quot;&gt;license to publish&lt;/a&gt; which includes this clause:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;The copyright holder retains the right to duplicate the Work by any means and to permit others to do the same with the exception of reproduction by services that collect fees for delivery of documents, which may be licensed only by the Publisher. In each case of authorized duplication of the Work in whole or in part, the Author(s) must still ensure that the original publication by the Publisher is properly credited.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After discussion with my co-author Aron Ahmadia, we’re retaining copyright and licensing the paper under CC-BY-NC. The NC (non-commercial clause) seems necessary to comply with the paragraph above, and seems reasonable to me. The code for the paper is released as part of the &lt;a href=&quot;https://github.com/ketch/RK-opt&quot;&gt;RK-opt package&lt;/a&gt;. So I’m calling this mission accomplished.&lt;/p&gt;
&lt;p&gt;I have mixed feelings about whether it makes sense for journals to let authors keep copyright – I can see some sense in SIAM’s objection, and I think that non-profit publishers need to protect enough of a revenue stream to support their activities. I think it is better that that revenue come from (low-cost) subscriptions than from author fees. It will be interesting to see where SIAM’s policy falls.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>The parallel EPPEER code</title>
   <link href="https://www.qixiaodong.tk/en/2012/10/17/eppeer.html"/>
   <updated>2012-10-17T00:00:00+00:00</updated>
   <id>/2012/10/17/eppeer</id>
   <content type="html">&lt;p&gt;Note: this post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2012/10/17/eppeer.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I tried out the EPPEER code, which uses two-step Runge-Kutta methods and OpenMP, because I’m thinking of writing a shared-memory parallel ODE solver code myself.&lt;/p&gt;
&lt;p&gt;I downloaded the code from&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.mathematik.uni-marburg.de/~schmitt/peer/eppeer.zip&quot; title=&quot;Go to wiki page&quot;&gt;http://www.mathematik.uni-marburg.de/~schmitt/peer/eppeer.zip&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;unzipped, and ran&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gfortran -c mbod4h.f90
gfortran -c ivprkp.f90
gfortran -c -fopenmp ivpepp.f90
gfortran -fopenmp ivprkp.o ivpepp.o mbod4h.o ivp_pmain.f90
./a.out&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I had to fix one line that was trying to open a logfile and failed. I also set&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export OMP_NUM_THREADS=4&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This runs the code with increasingly tight tolerances on a 400-body problem. The output was (I killed it before it finished the really tight tolerance run(s)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; tol, err, otime, cpu  0.10E-01 0.10702      2.9556      10.534    
 steps,rej,nfcn:  337   88     1399
 tol, err, otime, cpu  0.10E-02 0.93692E-01  4.9853      18.585    
 steps,rej,nfcn:  605  159     2465
 tol, err, otime, cpu  0.10E-03 0.66604E-01  7.9798      30.365    
 steps,rej,nfcn:  994  244     4015
 tol, err, otime, cpu  0.10E-04 0.47637E-01  12.026      46.477    
 steps,rej,nfcn: 1534  324     6175
 tol, err, otime, cpu  0.10E-05 0.24241E-01  18.239      70.756    
 steps,rej,nfcn: 2338  415     9391&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If I understand correctly, the last column is total CPU time; the next to last is wall time. For comparison, I ran it without parallelism:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;export OMP_NUM_THREADS=1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then I got the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; tol, err, otime, cpu  0.10E-01 0.10702      10.382      10.382    
 steps,rej,nfcn:  337   88     1399
 tol, err, otime, cpu  0.10E-02 0.93692E-01  18.297      18.297    
 steps,rej,nfcn:  605  159     2465
 tol, err, otime, cpu  0.10E-03 0.66604E-01  29.814      29.815    
 steps,rej,nfcn:  994  244     4015
 tol, err, otime, cpu  0.10E-04 0.47637E-01  45.854      45.855    
 steps,rej,nfcn: 1534  324     6175
 tol, err, otime, cpu  0.10E-05 0.24241E-01  69.725      69.726    
 steps,rej,nfcn: 2338  415     9391
 tol, err, otime, cpu  0.10E-06 0.53727E-02  105.47      105.48    
 steps,rej,nfcn: 3539  484    14195&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The numbers of function evaluations were identical, confirming that the computations being performed were the same. The speedup (about 3x) is very nice. We should be able to achieve something similar with extrapolation.&lt;/p&gt;
&lt;p&gt;These results are actually plotted in &lt;a href=&quot;http://www.mathematik.uni-marburg.de/~schmitt/peer/man_epp.pdf&quot;&gt;the user guide&lt;/a&gt;, at the end of Section 4.&lt;/p&gt;
&lt;p&gt;This was originally posted on &lt;a href=&quot;https://mathwiki.kaust.edu.sa/david/eppeer&quot;&gt;mathwiki&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Blogging with notebooks and Jekyll</title>
   <link href="https://www.qixiaodong.tk/en/2012/10/11/blogging-with-notebooks-and-jekyll.html"/>
   <updated>2012-10-11T00:00:00+00:00</updated>
   <id>/2012/10/11/blogging-with-notebooks-and-jekyll</id>
   <content type="html">&lt;p&gt;First off, if you know &lt;a href=&quot;https://github.com/yihui/knitr-jekyll&quot;&gt;KnitR&lt;/a&gt;, you can write code in R markdown directly and then compile in R/RStudio to generate the blog post easily. My blog repo has the knitr plugin installed and you can use &lt;code&gt;Python&lt;/code&gt;, &lt;code&gt;Mathlab&lt;/code&gt; and even &lt;code&gt;Julia&lt;/code&gt; engines to compile code lines. More information can be found in &lt;a href=&quot;http://yihui.name/knitr/&quot;&gt;Yihui Xie’s site&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Below, I will mention some methods that I use to blog with Jupyter notebooks with &lt;code&gt;Julia&lt;/code&gt;, &lt;code&gt;Python&lt;/code&gt; and &lt;code&gt;R&lt;/code&gt; based on the built in functionality of this &lt;a href=&quot;https://github.com/i2000s/i2000s.github.io&quot;&gt;Jekyll repo&lt;/a&gt; firstly introduced by Yihui Xie and &lt;a href=&quot;http://www.carlboettiger.info/&quot;&gt;Carl Boettiger&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In short, you can write ideas in Jupyter (iPython) notebooks and then output in Jykell markdown blog posts in various ways while keep tracking the edit history using version control.&lt;/p&gt;
&lt;p&gt;The most easiest way is to post your Jupyter notebook on GitGist, which has a preview function to Jupyter notebooks and can record your version history easily. I have a &lt;code&gt;notebooks.html&lt;/code&gt; template in my &lt;a href=&quot;https://github.com/i2000s/i2000s.github.io&quot;&gt;repo&lt;/a&gt; which automatically retrieves links to all your notebook gist repos and shows them on one page. This has been developed and used by &lt;a href=&quot;http://www.davidketcheson.info/&quot;&gt;David Ketcheson&lt;/a&gt; and others.&lt;/p&gt;
&lt;p&gt;The second method is to put your Jupyter notebooks in the blog repo and then export the markdown version for posting online. A lot of scripts have been written to make this converting process easy to commit. Here are two examples.&lt;/p&gt;
&lt;p&gt;One is introduced in &lt;a href=&quot;http://cscorley.github.io/2014/02/21/blogging-with-ipython-and-jekyll/&quot;&gt;Christop Corley’s blog&lt;/a&gt; to export markdown to your draft folder. I have the customized code in my &lt;a href=&quot;https://github.com/i2000s/i2000s.github.io&quot;&gt;repo&lt;/a&gt; in the &lt;code&gt;notebooks&lt;/code&gt; directory.&lt;/p&gt;
&lt;p&gt;The other one was introduced by &lt;a href=&quot;http://www.davidketcheson.info/2012/10/11/blogging_ipython_notebooks_with_jekyll.html&quot;&gt;David Ketcheson&lt;/a&gt;. I will just repost his original blog below for a quick preview. Please comment on his blog if you have question regarding this code. In the mean time, I have customized the &lt;code&gt;nbconv.sh&lt;/code&gt; code in my &lt;a href=&quot;https://github.com/i2000s/i2000s.github.io&quot;&gt;repo&lt;/a&gt; to work better with importing images within the notebook folder.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;David&lt;/em&gt;&lt;/strong&gt;: I’ve been playing around with &lt;a href=&quot;http://ipython.org/ipython-doc/dev/interactive/htmlnotebook.html&quot;&gt;iPython notebooks&lt;/a&gt; for a while and planning to use them instead of &lt;a href=&quot;http://www.sagemath.org/&quot;&gt;SAGE&lt;/a&gt; worksheets for my numerical analysis course next spring. As a warmup, I wrote an iPython notebook explaining a bit about internal stability of Runge-Kutta methods and showing some new research results using &lt;a href=&quot;http://numerics.kaust.edu.sa/nodepy/&quot;&gt;NodePy&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I also wanted to post the notebook on my blog here; the ability to more easily include math and code in blog posts was one of my main motivations for moving away from Blogger to my own site. I first tried following &lt;a href=&quot;http://blog.fperez.org/2012/09/blogging-with-ipython-notebook.html&quot;&gt;the instructions given by Fernando Perez&lt;/a&gt;. That was quite painless and worked flawlessly, using &lt;code&gt;nbconvert.py&lt;/code&gt; to convert the .ipynb file directly to HTML, with graphics embedded. The only issue was that I didn’t love the look of the output quite as much as I love how Carl Boettiger’s Markdown + Jekyll posts with code and math look (see an example &lt;a href=&quot;http://www.carlboettiger.info/2012/09/14/analytic-solution-to-multiple-uncertainty.html&quot;&gt;here&lt;/a&gt;). Besides, Markdown is so much nicer than HTML, and &lt;code&gt;nbconvert.py&lt;/code&gt; has a Markdown output option.&lt;/p&gt;
&lt;p&gt;So I tried the markdown option:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nbconvert.py my_nb.ipynb -f markdown&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I copied the result to my &lt;code&gt;_posts/&lt;/code&gt; directory, added the &lt;a href=&quot;https://github.com/mojombo/jekyll/wiki/YAML-Front-Matter&quot;&gt;YAML front-matter&lt;/a&gt; that Jekyll expects, and took a look. Everything was great except that all my plots were gone, of course. After considering a few options, I decided for now to put plots for such posts in a subfolder &lt;code&gt;jekyll_images/&lt;/code&gt; of my public Dropbox folder. Then it was a simple matter of search/replace all the paths to the images. At that point, it looked great; you can see the &lt;a href=&quot;https://github.com/ketch/nodepy/blob/master/examples/Internal_stability.ipynb&quot;&gt;source&lt;/a&gt; and the &lt;a href=&quot;http://davidketcheson.info/2012/10/11/Internal_stability.html&quot;&gt;result&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The only issue was that I didn’t want to manually do all that work every time. I considered creating a new Converter class in &lt;code&gt;nbconvert&lt;/code&gt; to handle it, but finally decided that it would be more convenient to just write a shell script that calls &lt;code&gt;nbconvert&lt;/code&gt; and then operates on the result.&lt;br /&gt;Here it is:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;#!/bin/bash

fname=$1

nbconvert.py ${fname}.ipynb -f markdown
sed  -i &amp;#39;&amp;#39; &amp;quot;s#${fname}_files#https:\/\/dl.dropbox.com\/u\/656693\/jekyll_images\/${fname}_files#g&amp;quot;  ${fname}.md

dt=$(date &amp;quot;+%Y-%m-%d&amp;quot;)

echo &amp;quot;0a
---
layout:    post
time:      ${dt}
title:     TITLE-ME
subtitle:  SUBTITLE-ME
tags:      TAG-ME
---
.
w&amp;quot; | ed ${fname}.md

mv ${fname}.md ~/labnotebook/_posts/${dt}-${fname}.md&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It’s also on Github &lt;a href=&quot;https://github.com/ketch/labnotebook/blob/master/nbconv.sh&quot;&gt;here&lt;/a&gt;. This was a nice educational exercise in constructing shell scripts, in which I learned or re-learned:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;how to use command-line arguments&lt;/li&gt;
&lt;li&gt;how to use sed and ed&lt;/li&gt;
&lt;li&gt;how to use data&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;You can expect a lot more iPython-notebook based posts in the future.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Internal stability of Runge-Kutta methods</title>
   <link href="https://www.qixiaodong.tk/en/2012/10/11/Internal_stability.html"/>
   <updated>2012-10-11T00:00:00+00:00</updated>
   <id>/2012/10/11/Internal_stability</id>
   <content type="html">&lt;p&gt;Note: this post was generated from an iPython notebook. You can &lt;a href=&quot;https://github.com/ketch/nodepy/blob/master/examples/Internal_stability.ipynb&quot;&gt;download the notebook from github&lt;/a&gt; and execute all the code yourself. This post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2012/10/11/Internal_stability.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Internal stability deals with the growth of errors (such as roundoff) introduced at the Runge-Kutta stages during a single Runge-Kutta step. It is usually important only for methods with a large number of stages, since that is when the internal amplification factors can be large. An excellent explanation of internal stability is given in &lt;a href=&quot;http://oai.cwi.nl/oai/asset/1652/1652A.pdf&quot;&gt;this paper&lt;/a&gt;. Here we demonstrate some tools for studying internal stability in NodePy.&lt;/p&gt;
&lt;p&gt;First, let’s load a couple of RK methods:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;nodepy&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;reload&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rk4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loadRKM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;RK44&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ssprk4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loadRKM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;SSP104&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk4&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssprk4&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;Classical RK4
The original four-stage, fourth-order method of Kutta
 0   |
 1/2 |  1/2
 1/2 |  0    1/2
 1   |  0    0    1
_____|____________________
     |  1/6  1/3  1/3  1/6
SSPRK(10,4)
The optimal ten-stage, fourth order SSP Runge-Kutta method
 0   |
 1/6 |  1/6
 1/3 |  1/6   1/6
 1/2 |  1/6   1/6   1/6
 2/3 |  1/6   1/6   1/6   1/6
 1/3 |  1/15  1/15  1/15  1/15  1/15
 1/2 |  1/15  1/15  1/15  1/15  1/15  1/6
 2/3 |  1/15  1/15  1/15  1/15  1/15  1/6   1/6
 5/6 |  1/15  1/15  1/15  1/15  1/15  1/6   1/6   1/6
 1   |  1/15  1/15  1/15  1/15  1/15  1/6   1/6   1/6   1/6
_____|____________________________________________________________
     |  1/10  1/10  1/10  1/10  1/10  1/10  1/10  1/10  1/10  1/10&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;absolute-stability-regions&quot;&gt;Absolute stability regions&lt;/h2&gt;
&lt;p&gt;First we can use NodePy to plot the region of absolute stability for each method. The absolute stability region is the set&lt;/p&gt;
&lt;center&gt;
&lt;span class=&quot;math&quot;&gt;\(\\{ z \in C : |\phi (z)|\le 1 \\}\)&lt;/span&gt;
&lt;/center&gt;

&lt;p&gt;where &lt;span class=&quot;math&quot;&gt;\(\phi(z)\)&lt;/span&gt; is the &lt;em&gt;stability function&lt;/em&gt; of the method:&lt;/p&gt;
&lt;center&gt;
&lt;span class=&quot;math&quot;&gt;\(1 + z b^T (I-zA)^{-1}\)&lt;/span&gt;
&lt;/center&gt;

&lt;p&gt;If we solve &lt;span class=&quot;math&quot;&gt;\(u&amp;#39;(t) = \lambda u\)&lt;/span&gt; with a given method, then &lt;span class=&quot;math&quot;&gt;\(z=\lambda \Delta t\)&lt;/span&gt; must lie inside this region or the computation will be unstable.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stability_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rk4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_stability_region&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;         4          3       2
0.04167 x + 0.1667 x + 0.5 x + 1 x + 1&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_00.png&quot; /&gt;
&lt;/figure&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssprk4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stability_function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ssprk4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;plot_stability_region&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;           10             9            8             7           6
3.969e-09 x  + 2.381e-07 x + 6.43e-06 x + 0.0001029 x + 0.00108 x
            5           4          3       2
 + 0.00787 x + 0.04167 x + 0.1667 x + 0.5 x + 1 x + 1&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_01.png&quot; /&gt;
&lt;/figure&gt;
&lt;h1 id=&quot;internal-stability&quot;&gt;Internal stability&lt;/h1&gt;
&lt;p&gt;The stability function tells us by how much errors from one step are amplified in the next one. This is important since we introduce truncation errors at every step. However, we also introduce roundoff errors at the each stage within a step. Internal stability tells us about the growth of those. Internal stability is typically less important than (step-by-step) absolute stability for two reasons:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Roundoff errors are typically much smaller than truncation errors, so moderate amplification of them typically is not significant&lt;/li&gt;
&lt;li&gt;Although the propagation of stage errors within a step is governed by internal stability functions, in later steps these errors are propagated according to the (principal) stability function&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Nevertheless, in methods with many stages, internal stability can play a key role.&lt;/p&gt;
&lt;p&gt;Questions: &lt;em&gt;In the solution of PDEs, large spatial truncation errors enter at each stage. Does this mean internal stability becomes more significant? How does this relate to stiff accuracy analysis and order reduction?&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;internal-stability-functions&quot;&gt;Internal stability functions&lt;/h2&gt;
&lt;p&gt;We can write the equations of a Runge-Kutta method compactly as&lt;/p&gt;
&lt;center&gt;
&lt;span class=&quot;math&quot;&gt;\(y = u^n e + h A F(y)\)&lt;/span&gt;
&lt;/center&gt;

&lt;center&gt;
&lt;span class=&quot;math&quot;&gt;\(u^{n+1} = u^n + h b^T F(y),\)&lt;/span&gt;
&lt;/center&gt;

&lt;p&gt;where &lt;span class=&quot;math&quot;&gt;\(y\)&lt;/span&gt; is the vector of stage values, &lt;span class=&quot;math&quot;&gt;\(u^n\)&lt;/span&gt; is the previous step solution, &lt;span class=&quot;math&quot;&gt;\(e\)&lt;/span&gt; is a vector with all entries equal to 1, &lt;span class=&quot;math&quot;&gt;\(h\)&lt;/span&gt; is the step size, &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(b\)&lt;/span&gt; are the coefficients in the Butcher tableau, and &lt;span class=&quot;math&quot;&gt;\(F(y)\)&lt;/span&gt; is the vector of stage derivatives. In floating point arithmetic, roundoff errors will be made at each stage. Representing these errors by a vector &lt;span class=&quot;math&quot;&gt;\(r\)&lt;/span&gt;, we have&lt;/p&gt;
&lt;center&gt;
&lt;span class=&quot;math&quot;&gt;\(y = u^n e + h A F(y) + r.\)&lt;/span&gt;
&lt;/center&gt;

&lt;p&gt;Considering the test problem &lt;span class=&quot;math&quot;&gt;\(F(y)=\lambda y\)&lt;/span&gt; and solving for &lt;span class=&quot;math&quot;&gt;\(y\)&lt;/span&gt; gives&lt;/p&gt;
&lt;center&gt;
&lt;span class=&quot;math&quot;&gt;\(y = u^n (I-zA)^{-1}e + (I-zA)^{-1}r,\)&lt;/span&gt;
&lt;/center&gt;

&lt;p&gt;where &lt;span class=&quot;math&quot;&gt;\(z=h\lambda\)&lt;/span&gt;. Substituting this result in the equation for &lt;span class=&quot;math&quot;&gt;\(u^{n+1}\)&lt;/span&gt; gives&lt;/p&gt;
&lt;center&gt;
&lt;span class=&quot;math&quot;&gt;\(u^{n+1} = u^n (1 + zb^T(I-zA)^{-1}e) + zb^T(I-zA)^{-1}r = \psi(z) u^n + \theta(z)^T r.\)&lt;/span&gt;
&lt;/center&gt;

&lt;p&gt;Here &lt;span class=&quot;math&quot;&gt;\(\psi(z)\)&lt;/span&gt; is the &lt;em&gt;stability function&lt;/em&gt; of the method, that we already encountered above. Meanwhile, the vector &lt;span class=&quot;math&quot;&gt;\(\theta(z)\)&lt;/span&gt; contains the &lt;em&gt;internal stability functions&lt;/em&gt; that govern the amplification of roundoff errors &lt;span class=&quot;math&quot;&gt;\(r\)&lt;/span&gt; within a step:&lt;/p&gt;
&lt;center&gt;
&lt;span class=&quot;math&quot;&gt;\(\theta(z) = z b^T (I-zA)^{-1}.\)&lt;/span&gt;
&lt;/center&gt;

&lt;p&gt;Let’s compute &lt;span class=&quot;math&quot;&gt;\(\theta\)&lt;/span&gt; for the classical RK4 method:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rk4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;internal_stability_polynomials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;
    [poly1d([1/24, 1/12, 1/6, 1/6, 0], dtype=object),
     poly1d([1/12, 1/6, 1/3, 0], dtype=object),
     poly1d([1/6, 1/3, 0], dtype=object),
     poly1d([1/6, 0], dtype=object)]
&lt;/pre&gt;


&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta_j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta_j&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;         4           3          2
0.04167 x + 0.08333 x + 0.1667 x + 0.1667 x
         3          2
0.08333 x + 0.1667 x + 0.3333 x
        2
0.1667 x + 0.3333 x

0.1667 x&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Thus the roundoff errors in the first stage are amplified by a factor &lt;span class=&quot;math&quot;&gt;\(z^4/24 + z^3/12 + z^2/6 + z/6\)&lt;/span&gt;, while the errors in the last stage are amplified by a factor &lt;span class=&quot;math&quot;&gt;\(z/6\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2 id=&quot;internal-instability&quot;&gt;Internal instability&lt;/h2&gt;
&lt;p&gt;Usually internal stability is unimportant since it relates to amplification of roundoff errors, which are very small. Let’s think about when things can go wrong in terms of internal instability. If &lt;span class=&quot;math&quot;&gt;\(|\theta(z)|\)&lt;/span&gt; is of the order &lt;span class=&quot;math&quot;&gt;\(1/\epsilon_{machine}\)&lt;/span&gt;, then roundoff errors could be amplified so much that they destroy the accuracy of the computation. More specifically, we should be concerned if &lt;span class=&quot;math&quot;&gt;\(|\theta(z)|\)&lt;/span&gt; is of the order &lt;span class=&quot;math&quot;&gt;\(tol/\epsilon_{machine}\)&lt;/span&gt; where &lt;span class=&quot;math&quot;&gt;\(tol\)&lt;/span&gt; is our desired error tolerance. Of course, we only care about values of &lt;span class=&quot;math&quot;&gt;\(z\)&lt;/span&gt; that lie inside the absolute stability region &lt;span class=&quot;math&quot;&gt;\(S\)&lt;/span&gt;, since internal stability won’t matter if the computation is not absolutely stable.&lt;/p&gt;
&lt;p&gt;We can get some idea about the amplification of stage errors by plotting the curves &lt;span class=&quot;math&quot;&gt;\(|\theta(z)|=1\)&lt;/span&gt; along with the stability region. Ideally these curves will all lie outside the stability region, so that all stage errors are damped.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;rk4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;internal_stability_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_02.png&quot; /&gt;
&lt;/figure&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;ssprk4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;internal_stability_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_03.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;For both methods, we see that some of the curves intersect the absolute stability region, so some stage errors are amplified. But by how much? We’d really like to know the maximum amplification of the stage errors under the condition of absolute stability. We therefore define the &lt;em&gt;maximum internal amplification factor&lt;/em&gt; &lt;span class=&quot;math&quot;&gt;\(M\)&lt;/span&gt;:&lt;/p&gt;
&lt;center&gt;
&lt;span class=&quot;math&quot;&gt;\(M = \max_j \max_{z \in S} |\theta_j(z)|\)&lt;/span&gt;
&lt;/center&gt;

&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ssprk4&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;2.15239281554
4.04399941143&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We see that both methods have small internal amplification factors, so internal stability is not a concern in either case. This is not surprising for the method with only four stages; it is a surprisingly good property of the method with ten stages.&lt;/p&gt;
&lt;p&gt;Questions: &lt;em&gt;Do SSP RK methods always (necessarily) have small amplification factors? Can we prove it?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Now let’s look at some methods with many stages.&lt;/p&gt;
&lt;h2 id=&quot;runge-kutta-chebyshev-methods&quot;&gt;Runge-Kutta Chebyshev methods&lt;/h2&gt;
&lt;p&gt;The paper of Verwer, Hundsdorfer, and Sommeijer deals with RKC methods, which can have very many stages. The construction of these methods is implemented in NodePy, so let’s take a look at them. The functions &lt;code&gt;RKC1(s)&lt;/code&gt; and &lt;code&gt;RKC2(s)&lt;/code&gt; construct RKC methods of order 1 and 2, respectively, with &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt; stages.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rkc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RKC1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rkc&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;RKC41

 0    |
 1/16 |  1/16
 1/4  |  1/8   1/8
 9/16 |  3/16  1/4   1/8
______|________________________
      |   1/4   3/8   1/4   1/8&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;rkc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;internal_stability_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_04.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;It looks like there could be some significant internal amplification here. Let’s see:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;rkc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;
    11.760869405962685
&lt;/pre&gt;


&lt;p&gt;Nothing catastrophic. Let’s try a larger value of &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rkc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RKC1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rkc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;
    42.665327220219126
&lt;/pre&gt;


&lt;p&gt;As promised, these methods seem to have good internal stability properties. What about the second-order methods?&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rkc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RKC2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;rkc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;
    106.69110992619214
&lt;/pre&gt;


&lt;p&gt;Again, nothing catastrophic. We could take &lt;span class=&quot;math&quot;&gt;\(s\)&lt;/span&gt; much larger than 20, but the calculations get to be rather slow (in Python) and since we’re using floating point arithmetic, the accuracy deteriorates.&lt;/p&gt;
&lt;p&gt;Remark: &lt;em&gt;we could do the calculations in exact arithmetic using Sympy, but things would get even slower. Perhaps there are some optimizations that could be done to speed this up. Or perhaps we should use Mathematica if we need to do this kind of thing.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Remark 2: &lt;em&gt;of course, for the RKC methods the internal stability polynomials are shifted Chebyshev polynomials. So we could evaluate them directly in a stable manner using the three-term recurrence (or perhaps scipy’s special functions library). This would also be a nice check on the calculations above.&lt;/em&gt;&lt;/p&gt;
&lt;h2 id=&quot;other-methods-with-many-stages&quot;&gt;Other methods with many stages&lt;/h2&gt;
&lt;p&gt;Three other classes of methods with many stages have been implemented in NodePy:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;SSP families&lt;/li&gt;
&lt;li&gt;Integral deferred correction (IDC) methods&lt;/li&gt;
&lt;li&gt;Extrapolation methods&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;ssp-families&quot;&gt;SSP Families&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ssprk&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SSPRK2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ssprk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;internal_stability_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ssprk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;
    2.0212921484995547
&lt;/pre&gt;


&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_05.png&quot; /&gt;
&lt;/figure&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;# # of stages&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ssprk&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SSPRK3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ssprk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;internal_stability_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ssprk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;
    3.8049237837215397
&lt;/pre&gt;


&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_06.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;The SSP methods seem to have excellent internal stability properties.&lt;/p&gt;
&lt;h3 id=&quot;idc-methods&quot;&gt;IDC methods&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#order&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;internal_stability_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idc&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;26&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;
    6.4140166271998815
&lt;/pre&gt;


&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_07.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;IDC methods also seem to have excellent internal stability.&lt;/p&gt;
&lt;h3 id=&quot;extrapolation-methods&quot;&gt;Extrapolation methods&lt;/h3&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#order&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;internal_stability_plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;16
6&lt;/code&gt;&lt;/pre&gt;
&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_08.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;Not so good. Let’s try a method with even more stages (this next computation will take a while; go stretch your legs).&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#order&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ex&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;46&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;
    28073.244376758907
&lt;/pre&gt;


&lt;p&gt;Now we’re starting to see something that might cause trouble, especially since such high order extrapolation methods are usually used when extremely tight error tolerances are required. Internal amplification will cause a loss of about 5 digits of accuracy here, so the best we can hope for is about 10 digits of accuracy in double precision. Higher order extrapolation methods will make things even worse. How large are their amplification factors? (Really long calculation here…)&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;pmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ampfac&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pmax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pmax&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ex&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rk&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;extrap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ampfac&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ex&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maximum_internal_amplification&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ampfac&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;&lt;code&gt;1 1.99777378912
2 2.40329384375
3
 5.07204078733
4
 17.747335803
5
 69.62805786
6
 97.6097450835
7
 346.277441462
8
 1467.40356089
9
 6344.16303534
10
 28073.2443768
11
 126011.586473
12
 169897.662582&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;
    [&lt;matplotlib.lines.Line2D at 0x2611bbe10&gt;]
&lt;/pre&gt;


&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_09.png&quot; /&gt;
&lt;/figure&gt;
&lt;div class=&quot;highlight&quot;&gt;
&lt;pre&gt;&lt;span class=&quot;n&quot;&gt;semilogy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ampfac&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linewidth&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/pre&gt;
&lt;/div&gt;
&lt;pre&gt;
    [&lt;matplotlib.lines.Line2D at 0x2611a6710&gt;]
&lt;/pre&gt;


&lt;figure&gt;
&lt;img src=&quot;https://dl.dropbox.com/u/656693/jekyll_images/Internal_stability_files/Internal_stability_fig_10.png&quot; /&gt;
&lt;/figure&gt;
&lt;p&gt;We see roughly geometric growth of the internal amplification factor as a function of the order &lt;span class=&quot;math&quot;&gt;\(p\)&lt;/span&gt;. It seems clear that very high order extrapolation methods applied to problems with high accuracy requirements will fall victim to internal stability issues.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>A curious upwind implicit scheme for advection</title>
   <link href="https://www.qixiaodong.tk/en/2012/10/11/A_curious_upwind_implicit_scheme_for_advection.html"/>
   <updated>2012-10-11T00:00:00+00:00</updated>
   <id>/2012/10/11/A_curious_upwind_implicit_scheme_for_advection</id>
   <content type="html">&lt;p&gt;Note: This post was originally published on the KAUST Mathwiki &lt;a href=&quot;https://mathwiki.kaust.edu.sa/david/A%20curious%20upwind%20implicit%20scheme%20for%20advection&quot;&gt;here&lt;/a&gt; (login required) by &lt;a href=&quot;http://www.davidketcheson.info/2012/10/11/A_curious_upwind_implicit_scheme_for_advection.html&quot;&gt;David Ketcheson&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;the-cfl-condition&quot;&gt;The CFL condition&lt;/h2&gt;
&lt;p&gt;The CFL condition is one of the most basic and intuitive principles in the numerical solution of hyperbolic PDEs. First formulated by Courant, Friedrichs and Lewy in their seminal paper (in English for free &lt;a href=&quot;http://www.stat.uchicago.edu/~lekheng/courses/302/classics/courant-friedrichs-lewy.pdf&quot;&gt;here&lt;/a&gt;), it states that the domain of dependence of a numerical method for solving a PDE must contain the true domain of dependence. Otherwise, the numerical method cannot be convergent.&lt;/p&gt;
&lt;p&gt;The CFL condition is geometric and easily understood in the context of, say, a first-order upwind discretization of advection. Usually it says nothing interesting about implicit schemes, since they include all points in their domain of dependence. But sometimes understanding the CFL condition for a particular scheme can be subtle.&lt;/p&gt;
&lt;h3 id=&quot;an-implicit-scheme&quot;&gt;An implicit scheme&lt;/h3&gt;
&lt;p&gt;Consider the advection equation&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[u_t + a u_x = 0.\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Discretization using a backward difference in space and in time gives the scheme&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\[U^{n+1}_j = U^n_j - \nu(U^{n+1}_j - U^{n+1}_{j-1}).\]&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Where &lt;span class=&quot;math&quot;&gt;\(\nu = ka/h\)&lt;/span&gt; is the CFL number and &lt;span class=&quot;math&quot;&gt;\(k,h\)&lt;/span&gt; are the step sizes in time and space, respectively. This very simple scheme illustrates the concepts of the CFL condition and stability in a remarkable way.&lt;/p&gt;
&lt;p&gt;For simplicity, suppose that the problem is posed on the domain &lt;span class=&quot;math&quot;&gt;\(0\le x \le 1\)&lt;/span&gt;, with an appropriate boundary condition. Since this scheme computes &lt;span class=&quot;math&quot;&gt;\(U^{n+1}_j\)&lt;/span&gt; in terms of &lt;span class=&quot;math&quot;&gt;\(U^n_j\)&lt;/span&gt; and &lt;span class=&quot;math&quot;&gt;\(U^{n+1}_{j-1}\)&lt;/span&gt;, it seems that the numerical domain of dependence for &lt;span class=&quot;math&quot;&gt;\(U^n_j\)&lt;/span&gt; is &lt;span class=&quot;math&quot;&gt;\((x,t)\in (0,x_j)\times[0,t_n]\)&lt;/span&gt;. Based on this, we may conclude that the scheme is not convergent for &lt;span class=&quot;math&quot;&gt;\(\nu&amp;lt;0\)&lt;/span&gt;. Simple enough.&lt;/p&gt;
&lt;p&gt;But what if &lt;span class=&quot;math&quot;&gt;\(\nu=-1\)&lt;/span&gt;? Then the scheme reads &lt;span class=&quot;math&quot;&gt;\[U^{n+1}_{j-1} = U^n_j,\]&lt;/span&gt; which gives &lt;strong&gt;the exact solution&lt;/strong&gt;! This is a sort of “anti-unit CFL condition”.&lt;/p&gt;
&lt;p&gt;How can this scheme be convergent (in fact, exact!) for a negative CFL number when it doesn’t use any values to the right?&lt;/p&gt;
&lt;h3 id=&quot;understanding-the-cfl-condition&quot;&gt;Understanding the CFL condition&lt;/h3&gt;
&lt;p&gt;Look at the exact formula above. In this case the scheme is not a method for computing &lt;span class=&quot;math&quot;&gt;\(U^{n+1}_j\)&lt;/span&gt; but for computing &lt;span class=&quot;math&quot;&gt;\(U^{n+1}_{j-1}\)&lt;/span&gt;, and it &lt;em&gt;does&lt;/em&gt; use a value from the previous time step that lies to the right.&lt;/p&gt;
&lt;p&gt;So we can view the scheme with &lt;span class=&quot;math&quot;&gt;\(\nu=-1\)&lt;/span&gt; as a method for computing &lt;span class=&quot;math&quot;&gt;\(U^{n+1}_j\)&lt;/span&gt;, in which case the CFL condition is satisfied only for &lt;span class=&quot;math&quot;&gt;\(\nu\ge0\)&lt;/span&gt;, or we can view the scheme as a method for computing &lt;span class=&quot;math&quot;&gt;\(U^{n+1}_{j-1}\)&lt;/span&gt;, in which case the CFL condition is satisfied only for &lt;span class=&quot;math&quot;&gt;\(\nu\le-1\)&lt;/span&gt;. &lt;strong&gt;Which viewpoint is correct?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;To answer that question, remember that the CFL condition is purely algebraic – that is, it relates to which values are actually used to compute which other values. To understand this scheme, we need to think about how we actually solve for &lt;span class=&quot;math&quot;&gt;\(U^{n+1}\)&lt;/span&gt; when using it. Notice that the scheme can be written as &lt;span class=&quot;math&quot;&gt;\[A U^{n+1} = U^n\]&lt;/span&gt; where the matrix &lt;span class=&quot;math&quot;&gt;\(A\)&lt;/span&gt; is lower-triangular. Hence the system can be solved by substitution. To go further, we must consider two cases:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\(\nu&amp;gt;0\)&lt;/span&gt;: in this case, boundary values must be supplied along the left boundary at &lt;span class=&quot;math&quot;&gt;\(x=0\)&lt;/span&gt;. Then, starting from the known value at the boundary, we work to the right by substitution: &lt;span class=&quot;math&quot;&gt;\[U^{n+1}_j = \frac{U^n_j+\nu U^{n+1}_{j-1}}{1+\nu}.\]&lt;/span&gt; Hence the scheme is truly a way of computing &lt;span class=&quot;math&quot;&gt;\(U^{n+1}_j\)&lt;/span&gt; based on &lt;span class=&quot;math&quot;&gt;\(U^n_j, U^{n+1}_{j-1}\)&lt;/span&gt; and the resulting CFL condition is &lt;span class=&quot;math&quot;&gt;\(\nu\ge0\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;span class=&quot;math&quot;&gt;\(\nu&amp;lt;0\)&lt;/span&gt;: in this case, boundary values must be supplied along the right boundary at &lt;span class=&quot;math&quot;&gt;\(x=1\)&lt;/span&gt;. Then, starting from the known value at the boundary, we work to the left by substitution: &lt;span class=&quot;math&quot;&gt;\[U^{n+1}_{j-1} = \frac{(1+\nu)U^{n+1}_j - U^n_j}{\nu}.\]&lt;/span&gt; Hence the scheme is truly a way of computing &lt;span class=&quot;math&quot;&gt;\(U^{n+1}_{j-1}\)&lt;/span&gt; based on &lt;span class=&quot;math&quot;&gt;\(U^n_j, U^{n+1}_{j}\)&lt;/span&gt; and the resulting CFL condition is &lt;span class=&quot;math&quot;&gt;\(\nu\le-1\)&lt;/span&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&quot;references&quot;&gt;References:&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Courant%E2%80%93Friedrichs%E2%80%93Lewy_condition&quot;&gt;CFL condition&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://http://dx.doi.org/10.1007%2FBF01448839&quot;&gt;their seminal paper&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.stanford.edu/class/cme324/classics/courant-friedrichs-lewy.pdf&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;div class=&quot;references&quot;&gt;

&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>7 Habits of the Open Scientist #3: Pre-publication dissemination of research</title>
   <link href="https://www.qixiaodong.tk/en/2012/08/22/habits-of-open-scientist-3-pre.html"/>
   <updated>2012-08-22T00:00:00+00:00</updated>
   <id>/2012/08/22/habits-of-open-scientist-3-pre</id>
   <content type="html">Note: This post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2012/08/03/habits-of-open-scientist-3.html&quot; target=&quot;_blank&quot;&gt;David Ketcheson&lt;/a&gt;.

&lt;p&gt;&lt;span style=&quot;font-family: Palatino;&quot;&gt;&lt;span style=&quot;font-size: 18px;&quot;&gt;Note: this post is part of &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/07/7-habits-of-open-scientist.html&quot;&gt;a series on habits of the open scientist&lt;/a&gt;.  Here I discuss the third habit, &lt;strong&gt;pre-publication dissemination of research&lt;/strong&gt;.  The previous post was on &lt;strong&gt;&lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/08/7-habits-of-open-scientist-2.html&quot;&gt;reproducible research&lt;/a&gt;.&lt;/strong&gt;&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 24px;&quot;&gt;&lt;strong&gt;A personal story&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In 2003-2004, as a senior undergraduate, I got involved in research on strong stability preserving (SSP) Runge--Kutta (RK) methods.  I noticed a number of &quot;numerical coincidences&quot; -- certain numbers characterizing ostensibly different properties of RK methods always happened to be exactly the same.  I didn&#39;t yet have the necessary background to fully prove the conjectured connection, but after months of work, I finally succeeded in completing a partial solution to the problem, which I wrote up as my undergraduate thesis.  Before I could submit a manuscript for publication, I discovered that two other researchers had just published the full result.  Hence my manuscript was, of course, unpublishable.&lt;/p&gt;&lt;p&gt;Occasionally, situations like this are inevitable.  But those researchers had worked out and written up the result at least a year ahead of me -- before I even began the work in earnest.  If their work had been available to me at the outset, I could have devoted my time to unanswered questions.&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 24px;&quot;&gt;&lt;strong&gt;Refereeing is slow; distribution is fast&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;In my field (applied math), it often takes more than 1 year for a submitted paper to be published.  This is because a thorough referee process of a manuscript takes time, and I think that time is worthwhile.  In contrast, I can &quot;publish&quot; a new paper on the arXiv in just 48 hours, or on my professional website instantaneously.&lt;/p&gt;&lt;p&gt;Many readers may not wish to see my work until it has been refereed.  But for those working on similar problems, reading my work 1 year earlier can be very useful by pointing out promising new avenues or avoiding duplication of effort.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The open scientist distributes his publishable research openly before the formal refereeing and publishing process, by placing completed manuscripts on a preprint server like the arXiv.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 18px;&quot;&gt;If you&#39;re brave, you can also &lt;a href=&quot;http://jabberwocky.weecology.org/2012/08/10/a-list-of-publicly-available-grant-proposals-in-the-biological-sciences/&quot;&gt;share your grant proposals&lt;/a&gt; openly.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-family: Palatino; font-size: 24px;&quot;&gt;&lt;strong&gt;Concerns&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;The first time you do this, you may feel worried that someone else will &#39;steal&#39; your preprint and publish it before you.  But posting it on the arXiv makes it public and stamps it with a date, so such theft would be obvious to everyone.  You may be worried that others will steal your ideas and immediately begin working on your next planned research question.  But if you&#39;re like me, the number of related research questions to pursue is essentially endless and you&#39;d be fortunate if your efforts attract others to work on closely related topics (for the truly self-interested, note that it will increase your citation count).  Finally, in some fields or subfields, there is cultural resistance to making preprints public; you can see my take on the issue in &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/01/what-is-this-thing-we-call-arxiv-really.html&quot;&gt;this prior blog post&lt;/a&gt;.  But there are &lt;a href=&quot;http://www.nature.com/news/geneticists-eye-the-potential-of-arxiv-1.11091&quot;&gt;signs that it is gaining wider acceptance&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;If everyone began to practice this, it would effectively transform the role of journals.  They would no longer be the primary distribution apparatus; their role would be that of &lt;a href=&quot;http://blogs.lse.ac.uk/impactofsocialsciences/2012/07/10/publish-then-filter-research/&quot;&gt;filtering the already-published literature&lt;/a&gt;.  This would make a lot more science available a lot sooner, without sacrificing the usefulness of peer review. &lt;/p&gt;&lt;div&gt;Next up: Habit #4 -- &lt;strong&gt;Open notebook science&lt;/strong&gt;.&lt;/div&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img width=&#39;1&#39; height=&#39;1&#39; src=&#39;https://blogger.googleusercontent.com/tracker/4660225022390848760-7777148585610164309?l=scienceinthesands.blogspot.com&#39; alt=&#39;&#39; /&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>7 Habits of the Open Scientist: #2 -- Reproducible Research</title>
   <link href="https://www.qixiaodong.tk/en/2012/08/03/habits-of-open-scientist-2.html"/>
   <updated>2012-08-03T00:00:00+00:00</updated>
   <id>/2012/08/03/habits-of-open-scientist-2</id>
   <content type="html">Note: This post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2012/08/03/habits-of-open-scientist-2.html&quot; target=&quot;_blank&quot;&gt;David Ketcheson&lt;/a&gt;.

&lt;p&gt;&lt;span style=&quot;font-family: Palatino;&quot;&gt;&lt;span style=&quot;font-size: 18px;&quot;&gt;Note: this post is part of &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/07/7-habits-of-open-scientist.html&quot;&gt;a series on habits of the open scientist&lt;/a&gt;.  Here I discuss the second habit, &lt;strong&gt;reproducible research&lt;/strong&gt;.  The previous post was on &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/08/7-habits-of-open-scientist-1-open.html&quot;&gt;&lt;strong&gt;open scientific publishing&lt;/strong&gt;&lt;/a&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;font-size: 18px;&quot;&gt;&lt;span style=&quot;font-size: 24px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-family: Helvetica;&quot;&gt;&lt;span style=&quot;font-size: 24px;&quot;&gt;&lt;span style=&quot;font-family: Palatino;&quot;&gt;&lt;span style=&quot;font-size: 24px;&quot;&gt;Reproducible research&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Reproducibility is part of the definition of science: if the results of your experiment cannot be replicated by different people in a different location, then you&#39;re not doing science.  Far from being a mere philosophic concern, reproducible research has been a key issue in prominent controversies like &lt;a href=&quot;http://en.wikipedia.org/wiki/Climatic_Research_Unit_email_controversy&quot;&gt;climategate&lt;/a&gt; and &lt;a href=&quot;http://magazine.amstat.org/blog/2011/01/01/scipolicyjan11/&quot;&gt;cancer research clinical trials&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;Especially disconcerting is the typical irreproducibility of scientific work involving computer code:&lt;/span&gt;&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;span&gt;“Computational science is facing a credibility crisis: it’s impossible to verify most of the computational results presented at conferences and in papers today.” (LeVeque, Mitchell, Stodden, &lt;em&gt;CiSE &lt;/em&gt;2012)&lt;/span&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Frankly, I used to find that I was often unable to reproduce &lt;em&gt;my own&lt;/em&gt; computational results after a few months, because I had not maintained sufficiently detailed notes about my code and my computing environment.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;The open scientist ensures that the entire &lt;em&gt;research compendium&lt;/em&gt; -- including not only the paper but the data, source code, parameters, post-processing, and computing environment -- is made freely available, preferably in a way that facilitates its reuse by others.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;I won&#39;t spend more time motivating reproducible research, since &lt;a href=&quot;http://www.bloomberg.com/news/2012-01-10/scientists-share-secrets-or-lose-funding-stodden-and-arbesman.html&quot;&gt;others have done that&lt;/a&gt; &lt;a href=&quot;http://biostatistics.oxfordjournals.org/content/11/3/385.full&quot;&gt;much better than I could&lt;/a&gt;.  Instead, let me focus on the relatively easy first steps you can take to make your research more reproducible.&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 24px;&quot;&gt;&lt;strong&gt;The bare minimum: publish your code and data&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;If you wish to set an example of good reproducible computational research practices, I have good news for you: the bar is very low at the moment.  The reason why &quot;it&#39;s impossible to verify most of the computational results&quot; is that &lt;/span&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;em&gt;most researchers don&#39;t release their code and data.&lt;/em&gt;&lt;/span&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;  The first step toward working reproducibly is simply to put the code and data that is used in your published research out in the open.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;If you don&#39;t want to release your code to the public, please read about &lt;a href=&quot;http://jarrodmillman.com/talks/siam2011/ms148/leveque.pdf&quot;&gt;why you should&lt;/a&gt; and &lt;a href=&quot;http://www.nature.com/news/2010/101013/full/467753a.html&quot;&gt;why you can&lt;/a&gt;.  Once you&#39;re convinced, go endorse the &lt;a href=&quot;http://sciencecodemanifesto.org/&quot;&gt;Science Code Manifesto&lt;/a&gt;.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;Releasing your code and data can be as simple as posting a tarball on your website with a reference to the paper it pertains to.  Or you may wish to start putting all your code out in the open on &lt;a href=&quot;http://bitbucket.org&quot;&gt;Bitbucket&lt;/a&gt; or &lt;a href=&quot;http://github.com&quot;&gt;Github&lt;/a&gt;, &lt;a href=&quot;http://github.com/ketch/&quot;&gt;like I do&lt;/a&gt;.  I don&#39;t claim that these are the &lt;em&gt;best&lt;/em&gt; solutions possible, but they are a big step forward from keeping everything on your own hard drive.&lt;/p&gt;&lt;p&gt;When you release your code and data, it is important to use an appropriate license.  &lt;a href=&quot;http://stodden.net&quot;&gt;Victoria Stodden&lt;/a&gt;, a leader in the reproducible research movement, recommends the use of a permissive license like &lt;a href=&quot;http://en.wikipedia.org/wiki/BSD_licenses#3-clause_license_.28.22New_BSD_License.22_or_.22Modified_BSD_License.22.29&quot;&gt;modified BSD&lt;/a&gt; for code and &lt;a href=&quot;http://sciencecommons.org/resources/faq/database-protocol/&quot;&gt;Science Commons Database Protocol&lt;/a&gt; for data.  Together with the &lt;a href=&quot;http://creativecommons.org/licenses/by/2.0/&quot;&gt;Creative Commons BY&lt;/a&gt; license for media (that I mentioned in &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/08/7-habits-of-open-scientist-1-open.html&quot;&gt;my last post&lt;/a&gt;), these comprise the &lt;a href=&quot;http://www.ijclp.net/files/ijclp_web-doc_1-13-2009.pdf&quot;&gt;&lt;em&gt;Reproducible Research Standard&lt;/em&gt;&lt;/a&gt;, a convenient amalgamation of licenses for open science.&lt;/p&gt;&lt;p&gt;Be sure to include a mention of reproducibility in your paper, along with links to the code and data.  If you release your work under the RRS, I suggest using &lt;a href=&quot;http://dx.doi.org/10.1109/MCSE.2009.19&quot;&gt;this citation&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 24px;&quot;&gt;&lt;strong&gt;Real benefits&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span&gt;The open scientist may adopt reproducible research practices for philosophical reasons, but he soon finds that they bring more direct benefits.  Because he writes code and prepares data with the expectation that it will be seen by others, the open scientist finds it much easier for himself, students, and colleagues to build on past work.  New collaborations are formed when others discover his work through openly released code and data.  And (as in the case of &lt;a href=&quot;http://numerics.kaust.edu.sa/papers/pyclaw-sisc/pyclaw-sisc.html&quot;&gt;this paper&lt;/a&gt;, for example) the code itself may be the main subject of publications in &lt;a href=&quot;http://scicomp.stackexchange.com/questions/660/venues-for-publishing-papers-that-emphasize-software&quot;&gt;journals that have come to recognize the importance&lt;/a&gt; of scientific software.&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;font-size: 24px;&quot;&gt;&lt;strong&gt;Taking it further&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;div&gt;Like free and open scientific publishing, reproducible research has become a very large movement, and only a book could hope to cover it all.  Here I&#39;ve merely distilled some basic practical suggestions.&lt;/div&gt;&lt;p&gt;Openly releasing code and data is only the first step.  Open scientists may wish to adopt tools that track code provenance and ensure a fully reproducible workflow, such as&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;a href=&quot;http://www.reproducibility.org/wiki/Main_Page&quot;&gt;Madagascar&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://www.vistrails.org&quot;&gt;VisTrails&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://yihui.name/knitr/&quot;&gt;knitr&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://neuralensemble.org/trac/sumatra&quot;&gt;Sumatra&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href=&quot;http://vcr.stanford.edu/&quot;&gt;VCR&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;div&gt;Next up: Habit #3 -- &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/08/7-habits-of-open-scientist-3-pre.html&quot;&gt;&lt;strong&gt;Pre-publication dissemination of research&lt;/strong&gt;&lt;/a&gt;.&lt;/div&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img width=&#39;1&#39; height=&#39;1&#39; src=&#39;https://blogger.googleusercontent.com/tracker/4660225022390848760-9151334296275912840?l=scienceinthesands.blogspot.com&#39; alt=&#39;&#39; /&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>7 Habits of the Open Scientist: #1 -- Open publishing</title>
   <link href="https://www.qixiaodong.tk/en/2012/08/01/habits-of-open-scientist-1-open.html"/>
   <updated>2012-08-01T00:00:00+00:00</updated>
   <id>/2012/08/01/habits-of-open-scientist-1-open</id>
   <content type="html">Note: This post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2012/08/01/habits-of-open-scientist-1-open.html&quot; target=&quot;_blank&quot;&gt;David Ketcheson&lt;/a&gt;.

&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 14px;&quot;&gt;&lt;span style=&quot;font-size: 18px;&quot;&gt;Note: this post is part of &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/07/7-habits-of-open-scientist.html&quot;&gt;a series on habits of the open scientist&lt;/a&gt;.  Here I discuss the first habit, &lt;strong&gt;open scientific publishing&lt;/strong&gt;.&lt;/span&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 24px;&quot;&gt;Why you should publish openly&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 24px;&quot;&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;A hallmark of important scientific work is that it is reused, modified, and built upon by other scientists.  As a scientist, I spend a great deal of time and effort advertising my work to others so that they will read it and use it.  &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;By default, scientific works fall subject to copyright law, which is intended to prevent reuse and modification.  To make matters worse, the copyrights are typically held by publishers who charge a fee just for access.   Copyright makes sense for musicians and popular authors, because they make a living by charging for access to their works.  But as a scientist, I don&#39;t get paid by those who read and use my work, nor do I seek to.  So &lt;strong&gt;copyright does not serve me, even from a purely self-interested perspective&lt;/strong&gt;.  &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;Stepping back from personal interest, I believe that academic scientists have a &lt;strong&gt;moral imperative&lt;/strong&gt; to freely distribute their work, for two reasons.  First, in academia science is primarily funded by taxes.  Therefore, it has been &#39;purchased&#39; by the public and cannot rightly be withheld from them.  Second, and more importantly, science is intended to benefit humanity.  If it is to do so, it must be shared and communicated.  That is why it has been said that &lt;a href=&quot;http://www.nature.com/nature/debates/e-access/Articles/stallman.html&quot;&gt;&quot;science must push copyright aside.&quot;&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;strong&gt;The  open scientist proactively ensures that published research is freely and conveniently available to all.  Ideally, the open scientist releases research under a license like Creative Commons BY that explicitly allows use in derivative works as long as attribution is given.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt; &lt;/p&gt;&lt;p style=&quot;font: normal normal normal 14px/normal Skia; min-height: 17px; margin: 0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;font-size: 24px;&quot;&gt;How you can provide free, open access to your work&lt;/span&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p style=&quot;font-size: x-large; font: normal normal normal 14px/normal Skia; margin: 0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;strong&gt;Green open access&lt;/strong&gt; (self archiving): independently of publication in a journal, the author uploads a pre-print, post-print, or final published version of the article to an institutional server, preprint server, or personal webpage.  Anyone can download this version of the article for free.  The author pays nothing and the reader pays nothing.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;font-size: x-large; font: normal normal normal 14px/normal Skia; margin: 0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;strong&gt;&lt;span style=&quot;font-family: Palatino;&quot;&gt;&lt;span style=&quot;font-size: 18px;&quot;&gt;Gold open access&lt;/span&gt;&lt;/span&gt;&lt;/strong&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;: The author pays the publishing journal a fee in order to have the article available for free on the publisher&#39;s website.  Author charges typically are in the range of hundreds to thousands of dollars. &lt;/span&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;I have &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2011/12/in-defense-of-submission-in-scientific.html&quot;&gt;written elsewhere about the dangers of the gold open access model&lt;/a&gt;.  Suffice it to say that the gold open access approach severely limits which journals I can submit to and consumes my research funds, whereas the green model does not.  &lt;a href=&quot;http://arxiv.org/find/math/1/au:+Qi_D/0/1/0/all/0/1&quot;&gt;I post all my preprints on the arXiv&lt;/a&gt; and &lt;a href=&quot;http://numerics.kaust.edu.sa/publications.html&quot;&gt;on my professional website&lt;/a&gt; before submission.  Where allowed, I post final versions as well.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;Many journals still have restrictive policies that prevent green open access.  If you believe this to be the case for journals that you publish in, it&#39;s worth checking to be sure.  You can easily find this information in the &lt;a href=&quot;http://www.sherpa.ac.uk/romeo/&quot;&gt;Sherpa/Romeo database&lt;/a&gt;.  The number of publishers who still don&#39;t allow any kind of green open access are surprisingly few.  For instance, even the evil &lt;a href=&quot;http://www.sherpa.ac.uk/romeo/search.php?id=30&amp;amp;fIDnum=|&amp;amp;mode=simple&amp;amp;la=en&amp;amp;format=full&quot;&gt;Elsevier typically allows archiving of pre- and post-prints&lt;/a&gt;.  &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt; &lt;/p&gt;&lt;p style=&quot;font: normal normal normal 14px/normal Skia; min-height: 17px; margin: 0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 24px;&quot;&gt;&lt;strong&gt;Best practices: pushing copyright aside&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;div&gt;&lt;span style=&quot;font-family: Palatino; font-size: 24px;&quot;&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;/span&gt;&lt;/div&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;If you are brave, you can even &lt;a href=&quot;http://scholars.sciencecommons.org/&quot;&gt;modify the journal&#39;s copyright transfer agreement&lt;/a&gt;, to allow you to retain copyright and release your work under &lt;a href=&quot;http://creativecommons.org/licenses/by/2.0/&quot;&gt;Creative Commons BY&lt;/a&gt;.  This is also (surprisingly) often &lt;a href=&quot;http://adamdsmith.wordpress.com/2009/07/07/copyright-copywrong/&quot;&gt;accepted by publishers&lt;/a&gt;.  I haven&#39;t done this yet, but I plan to do so with all of my future papers, including those currently under referee.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;This first habit of the open scientist is essential but no longer revolutionary.  The open access movement has really picked up speed in the past year, with many &lt;a href=&quot;http://access2research.org/Petition&quot;&gt;petitions&lt;/a&gt; and initiatives by &lt;a href=&quot;http://www.guardian.co.uk/science/2012/jul/25/uk-government-open-access-development-research&quot;&gt;governments&lt;/a&gt; and &lt;a href=&quot;http://www.wellcome.ac.uk/About-us/Policy/Policy-and-position-statements/WTD002766.htm&quot;&gt;funding agencies&lt;/a&gt; moving forward.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;&lt;br /&gt;&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-family: Palatino; font-size: 18px;&quot;&gt;Next up: Habit #2 -- &lt;strong&gt;&lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/08/7-habits-of-open-scientist-2.html&quot;&gt;Reproducible research: open code, open data&lt;/a&gt;.&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img width=&#39;1&#39; height=&#39;1&#39; src=&#39;https://blogger.googleusercontent.com/tracker/4660225022390848760-7172755368704394594?l=scienceinthesands.blogspot.com&#39; alt=&#39;&#39; /&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>7 Habits of the Open Scientist</title>
   <link href="https://www.qixiaodong.tk/en/2012/07/31/habits-of-open-scientist.html"/>
   <updated>2012-07-31T00:00:00+00:00</updated>
   <id>/2012/07/31/habits-of-open-scientist</id>
   <content type="html">Note: This post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2012/07/31/habits-of-open-scientist.html&quot; target=&quot;_blank&quot;&gt;David Ketcheson&lt;/a&gt;.

&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;Science has always been based on a fundamental culture of openness.  The scientific community rewards individuals for sharing their discoveries through perpetual attribution, and the community benefits by through the ability to build on discoveries made by individuals.  Furthermore, scientific discoveries are not generally accepted until they have been verified or reproduced independently, which requires open communication.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;Historically, openness simply meant publishing one&#39;s methods and results in the scientific literature.  This enabled scientists all over the world to learn about essential advances made by their colleagues, modulo a few barriers.  One needed to have access to expensive library collections, to spend substantial time and effort searching the literature, and to wait while research conducted by other groups was refereed, published, and distributed.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;Nowadays it is possible to practice a fundamentally more open kind of research -- one in which we have immediate, free, indexed, universal access to scientific discoveries.  The new vision of open science is painted in lucid tones in Michael Nielsen&#39;s &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2011/11/book-review-reinventing-discovery.html&quot;&gt;Reinventing Discovery&lt;/a&gt;.  After reading Nielsen&#39;s book, I was hungry to begin practicing open science, but not exactly sure where to start.  Here are seven ways I&#39;m aware of.  Each will be the subject of a longer forthcoming post.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;I believe that every scientist has a moral imperative to adopt the first two:&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;1. &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/08/7-habits-of-open-scientist-1-open.html&quot;&gt;&lt;strong&gt;Freely accessible publications&lt;/strong&gt;&lt;/a&gt;.  At a minimum, make sure that everyone is allowed to read your research.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;2. &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/08/7-habits-of-open-scientist-2.html&quot;&gt;&lt;strong&gt;Reproducible research&lt;/strong&gt;&lt;/a&gt;.  Release your code and data so  that anyone who wants to can verify or build directly on your work.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;The remaining five are marks of a truly open scientist:&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia; min-height: 17.0px;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt; &lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;3. &lt;a href=&quot;http://scienceinthesands.blogspot.co.uk/2012/08/7-habits-of-open-scientist-3-pre.html&quot;&gt;&lt;strong&gt;Pre-publication dissemination of research&lt;/strong&gt;&lt;/a&gt;.  Just because peer-review and journals take time, that doesn&#39;t mean you need to embargo your audience.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;4. &lt;strong&gt;Open collaboration through social media&lt;/strong&gt;.  Find the person who knows that one thing you need, through new scientific networking tools -- and share your own expertise where it&#39;s needed most.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;5. &lt;strong&gt;Live open science&lt;/strong&gt;.  Tell people about your marvelous discoveries -- as you make them.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;6. &lt;strong&gt;Open expository writing&lt;/strong&gt;.  Teach others about the field you work in through a blog or online book.&lt;/span&gt;&lt;/p&gt;&lt;p style=&quot;margin: 0.0px 0.0px 0.0px 0.0px; font: 14.0px Skia;&quot;&gt;&lt;span style=&quot;font-size: 18px; font-family: Palatino;&quot;&gt;7.  &lt;strong&gt;Open bibliographies and reviews&lt;/strong&gt;.  Let your colleagues know what you&#39;re reading, and what you&#39;ve learned from it.&lt;/span&gt;&lt;/p&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img width=&#39;1&#39; height=&#39;1&#39; src=&#39;https://blogger.googleusercontent.com/tracker/4660225022390848760-5195607085851158662?l=scienceinthesands.blogspot.com&#39; alt=&#39;&#39; /&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Can a region of absolute stability be rectangular?</title>
   <link href="https://www.qixiaodong.tk/en/2012/03/17/can-region-of-absolute-stability-be.html"/>
   <updated>2012-03-17T00:00:00+00:00</updated>
   <id>/2012/03/17/can-region-of-absolute-stability-be</id>
   <content type="html">Note: This post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2012/03/17/can-region-of-absolute-stability-be.html&quot; target=&quot;_blank&quot;&gt;David Ketcheson&lt;/a&gt;.

&lt;script type=&quot;text/x-mathjax-config&quot;&gt;// &lt;![CDATA[    MathJax.Hub.Config({tex2jax: {inlineMath: [[&#39;$&#39;,&#39;$&#39;], [&#39;\\(&#39;,&#39;\\)&#39;]]}}); // ]]&amp;gt; // ]]&amp;gt; // ]]&amp;gt; // ]]&amp;gt;&lt;/script&gt;&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML&quot;&gt; &lt;/script&gt;&lt;p&gt;When a one-step integrator is applied to the solution of the linear scalar ODE&lt;/p&gt;&lt;p&gt;$$u&#39;(t) = \lambda u(t)$$&lt;/p&gt;&lt;p&gt;the resulting iteration takes the simple form&lt;/p&gt;&lt;p&gt;$$U^{n} = R(h\lambda) U^{n-1}$$&lt;/p&gt;&lt;p&gt;where $U^n$ is a numerical approximation to the solution $u(t_n)$ and $R(h\lambda)$ is called the &lt;em&gt;stability function&lt;/em&gt;.  The details of the stability function depend on the choice of numerical method, but for any explicit Runge-Kutta method, $R(z)$ is a polynomial whose degree is at most the number of stages of the method.&lt;/p&gt;&lt;p&gt;The stability function completely characterizes the accuracy and stability of the method when applied to linear problems.  Consider the first order linear, autonomous ODE&lt;/p&gt;&lt;p&gt;$$u&#39;(t) = L u(t)$$&lt;/p&gt;&lt;p&gt;where now $u$ is a vector and $L$ is a square matrix.  The numerical solution will be&lt;/p&gt;&lt;p&gt;$$U^{n} = R(hL) U^{n-1}.$$&lt;/p&gt;&lt;p&gt;The global error satisfies a similar recurrence; in particular, it gets multiplied by a factor $R(hL)$ at each step.  Let $\lambda$ denote any eigenvalue of $L$; then If $L$ is a normal matrix, the solution will be absolutely stable in the Euclidean norm if all values $h\lambda$ lie within the stability region $S$, defined as&lt;/p&gt;&lt;p&gt;$$S = \{ z\in\mathbb{C} : |R(z)|\le 1\}.$$&lt;/p&gt;&lt;p&gt;Thus the region of absolute stability defines the portion of the complex plane in which a given numerical integration method may appropriately be applied.&lt;/p&gt;&lt;p&gt;In our &lt;a href=&quot;http://arxiv.org/abs/1201.3035&quot;&gt;preprint on Runge-Kutta stability regions&lt;/a&gt;, Aron Ahmadia and I claim that we have an algorithm to generate a stability region appropriate for &lt;strong&gt;any&lt;/strong&gt; spectrum.  By considering high-degree polynomials, we find that the resulting stability regions are tightly adapted to the shape of the imposed spectrum.&lt;/p&gt;&lt;p&gt;While this promises to be very useful for some problems, it also has an aspect that&#39;s just fun: we can generate stability regions with unusual shapes.  I haven&#39;t explored this much yet, but a first question that we ask in the preprint is how to generate a stability region for a spectrum of eigenvalues forming a rectangle in the left half of the complex plane.&lt;/p&gt;&lt;p&gt;Here is an example of a resulting stability region:&lt;/p&gt;&lt;p&gt;&lt;img style=&quot;display: block; margin-left: auto; margin-right: auto;&quot; title=&quot;rectangle.png&quot; src=&quot;http://lh5.ggpht.com/-hFUCwYmztZc/T2Tih_6hjqI/AAAAAAAAAqE/-bCijXPC9fU/rectangle.png?imgmax=800&quot; border=&quot;0&quot; alt=&quot;Rectangle&quot; width=&quot;300&quot; height=&quot;170&quot; /&gt;&lt;/p&gt;&lt;p&gt;The gray region is the set $S$ for a certain degree-20 stability polynomial corresponding to a consistent twenty-stage Runge-Kutta method.  As one colleague told me when I showed it to him, &quot;this seems too good to be true; is that rectangle really the stability region?&quot;&lt;/p&gt;&lt;p&gt;Indeed it is.  Zooming in on the top edge we see the detailed structure of the boundary:&lt;/p&gt;&lt;p&gt;&lt;img style=&quot;display: block; margin-left: auto; margin-right: auto;&quot; title=&quot;topzoom.png&quot; src=&quot;http://lh5.ggpht.com/-Kw9OH_BbvFo/T2Tkf-wpSwI/AAAAAAAAAqU/nh-AvaTLjME/topzoom.png?imgmax=800&quot; border=&quot;0&quot; alt=&quot;Topzoom&quot; width=&quot;400&quot; height=&quot;227&quot; /&gt;&lt;/p&gt;&lt;p&gt;Zooming in even closer:&lt;/p&gt;&lt;p&gt;&lt;img style=&quot;display: block; margin-left: auto; margin-right: auto;&quot; title=&quot;topzoomzoom.png&quot; src=&quot;http://lh6.ggpht.com/-Yl76vF8t5tE/T2TkhS5suMI/AAAAAAAAAqc/aAk3EZPO6Po/topzoomzoom.png?imgmax=800&quot; border=&quot;0&quot; alt=&quot;Topzoomzoom&quot; width=&quot;500&quot; height=&quot;283&quot; /&gt;&lt;/p&gt;&lt;p&gt;As is typical with optimal stability polynomials, we se that the boundary is tangent or nearly tangent to the desired region at a large number of points (about 20 in this case).&lt;/p&gt;&lt;p&gt;What other shapes can be approximated?  More on that later...&lt;/p&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img width=&#39;1&#39; height=&#39;1&#39; src=&#39;https://blogger.googleusercontent.com/tracker/4660225022390848760-2593423780459904784?l=scienceinthesands.blogspot.com&#39; alt=&#39;&#39; /&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>Managing publication lists in HTML</title>
   <link href="https://www.qixiaodong.tk/en/2011/10/28/managing-publication-lists-in-html.html"/>
   <updated>2011-10-28T00:00:00+00:00</updated>
   <id>/2011/10/28/managing-publication-lists-in-html</id>
   <content type="html">Note: This post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2011/10/28/managing-publication-lists-in-html.html&quot; target=&quot;_blank&quot;&gt;David Ketcheson&lt;/a&gt; and updated to my case.

&lt;p&gt;As an academic, it&#39;s a good idea to maintain a &lt;a href=&quot;http://web.kaust.edu.sa/faculty/davidketcheson/&quot;&gt;professional website&lt;/a&gt; with a &lt;a href=&quot;http://web.kaust.edu.sa/faculty/davidketcheson/publications.html&quot;&gt;list of your publications&lt;/a&gt;.  Ideally, this list should include links to where visitors can download the papers (PDFs) &lt;a href=&quot;http://sciencecodemanifesto.org&quot;&gt;and any related code&lt;/a&gt;.  In my case, I also maintain a &lt;a href=&quot;http://numerics.kaust.edu.sa&quot;&gt;website for my research group&lt;/a&gt; that has another &lt;a href=&quot;http://numerics.kaust.edu.sa/publications.html&quot;&gt;publication list.&lt;/a&gt; Of course, you need to maintain local reference files with the citation info for your publications (for inclusion in later publications), as well as your CV.&lt;/p&gt;&lt;p&gt;Maintaining all these separate lists can become very tedious, which is probably why most academics&#39; sites are usually out-of-date.  Here&#39;s how I automate much of it:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;strong&gt;I use &lt;a href=&quot;http://www.bibtex.org/&quot;&gt;Bibtex&lt;/a&gt;. &lt;/strong&gt;This allows automatic generation of bibliographies for papers and for my CV.  And it&#39;s the basis for generating HTML bibliographies, as outlined below.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;I use &lt;a href=&quot;http://www.mendeley.com&quot;&gt;Mendeley&lt;/a&gt;.&lt;/strong&gt; Mendeley allows me to create separate bibliographic lists (e.g., for my own publications and for those of my research group) and &lt;a href=&quot;http://www.mendeley.com/blog/tipstricks/howto-use-mendeley-to-create-citations-using-latex-and-bibtex/&quot;&gt;export them as bibtex files&lt;/a&gt;, using the desktop app.  It&#39;s also possible to &lt;a href=&quot;http://bibbase.org/cgi-bin/mendeley/Mendeley-oapi/requestToken.py&quot;&gt;get a bibtex file of your Mendeley publications directly on-line&lt;/a&gt; through &lt;a href=&quot;http://www.bibbase.org&quot;&gt;BibBase&lt;/a&gt;.  You can even &lt;a href=&quot;http://www.mendeley.com/blog/academic-features/if-you-publish-a-paper-but-nobody-reads-it-does-it-make-a-difference/#more-26402&quot;&gt;display a list of your publications on-line automatically using Mendeley,&lt;/a&gt; but it&#39;s not very customizable; for instance, they appear in alphabetical, rather than chronological order.&lt;/li&gt;&lt;li&gt;&lt;strong&gt;I would use &lt;a href=&quot;http://www.bibbase.org/&quot;&gt;BibBase&lt;/a&gt;&lt;/strong&gt; to &lt;a href=&quot;http://www.bibbase.org/help/&quot;&gt;automatically display an updated bibliography&lt;/a&gt; if my institutional server ran PHP or CGI scripts, but no luck there.&lt;/li&gt;&lt;li&gt;My less-automatic solution is &lt;strong&gt;&lt;a href=&quot;https://github.com/ketch/tex2_rst_html&quot;&gt;simple Python scripts&lt;/a&gt;&lt;/strong&gt; that generate CSS-friendly HTML.  The scripts use the Python module bibliograph to parse bibtex entries.  I could instead use &lt;a href=&quot;https://encrypted.google.com/url?sa=t&amp;amp;rct=j&amp;amp;q=bibtex2html&amp;amp;source=web&amp;amp;cd=1&amp;amp;sqi=2&amp;amp;ved=0CBgQFjAA&amp;amp;url=http%3A%2F%2Fwww.lri.fr%2F~filliatr%2Fbibtex2html%2F&amp;amp;ei=EqqqTubIK4zC8QPF7sySCw&amp;amp;usg=AFQjCNFE8lFV7TxfgvapcrTjFvSDcEqyng&quot;&gt;bibtex2html&lt;/a&gt;.  I like my solution better because the customization is all done using CSS rather than Python, so I can change the look without re-generating the HTML.  Of course, bibtex2html is a more polished and flexible tool than my 30-line script.&lt;/li&gt;&lt;li&gt;Here&#39;s a CSS snippet that&#39;s used for &lt;a href=&quot;http://numerics.kaust.edu.sa/publications.html&quot;&gt;this publication list&lt;/a&gt;:&lt;/li&gt;&lt;/ul&gt;&lt;pre class=&#39;brush:css;&#39;&gt;&lt;br /&gt;#pub {padding: 5px; border-width: 2px; border-style: none; background-color: #eee4b5; font-size: 1.2em; margin-top: 20px; margin-bottom: 20px;}&lt;br /&gt;#pub a{font-weight: bold; color: #09434e;}&lt;br /&gt;#pub name{font-weight: bold; color: #09434e;}&lt;br /&gt;#pub journal{font-style: italic;}&lt;br /&gt;&lt;/pre&gt;&lt;p&gt; &lt;/p&gt;&lt;p&gt;The workflow for adding a new paper to an html bibliography is:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;Add the paper in Mendeley.&lt;/li&gt;&lt;li&gt;Export bibtex from Mendeley.&lt;/li&gt;&lt;li&gt;Run Python scripts.&lt;/li&gt;&lt;li&gt;Paste resulting HTML into the appropriate file.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;Again, it would be simpler if I could use Bibbase (cutting out steps 2-4).  It&#39;s still fairly painless, and it&#39;s easy to generate new bibilographic lists or customize the look of existing ones.&lt;/p&gt;&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img width=&#39;1&#39; height=&#39;1&#39; src=&#39;https://blogger.googleusercontent.com/tracker/4660225022390848760-6191171778887335934?l=scienceinthesands.blogspot.com&#39; alt=&#39;&#39; /&gt;&lt;/div&gt;

Update by Xiaodong Qi:

In Jekyll, like this site, you can also use the &lt;a href=&quot;https://github.com/inukshuk/jekyll-scholar&quot; target=&quot;_blank&quot;&gt;Jekyll-scholar&lt;/a&gt; suit to manage bibtex database for your publication page in html.

If you use php or Wordpress on your web server, you can use the &lt;a href=&quot;https://github.com/monperrus/bibtexbrowser&quot; target=&quot;_blank&quot;&gt;bibtexbrowser&lt;/a&gt; tool.
I have customized one version under my &lt;a href=&quot;https://github.com/i2000s/bibtexbrowser&quot; target=&quot;_blank&quot;&gt;Github repo&lt;/a&gt; which is used for CQuIC&#39;s website site at &lt;a href=&quot;http://cquic.unm.edu/cquic-publications/&quot; target=&quot;_blank&quot;&gt;http://cquic.unm.edu/&lt;/a&gt; for a better outlook for physics publications.
</content>
 </entry>
 
 <entry>
   <title>How to edit all files containing a particular string</title>
   <link href="https://www.qixiaodong.tk/en/2011/06/27/how-to-edit-all-files-containing.html"/>
   <updated>2011-06-27T00:00:00+00:00</updated>
   <id>/2011/06/27/how-to-edit-all-files-containing</id>
   <content type="html">Note: This post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2011/06/27/how-to-edit-all-files-containing.html&quot; target=&quot;_blank&quot;&gt;David Ketcheson&lt;/a&gt;.

It&#39;s often useful to be able to automatically open all files with a particular string (say, to rename a variable throughout your code).  To do this with ack, and open all files containing my_string in vim, just type:&lt;br /&gt;&lt;br /&gt;vim $(ack -l my_string)&lt;br /&gt;&lt;br /&gt;It can be accomplished in a similar way with grep instead of ack.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Edit:&lt;/b&gt; If you just want to search and replace a particular string in all files under some directory recursively, use &lt;br /&gt;&lt;br /&gt;grep -rl matchstring somedir/ | xargs sed -i &quot;&quot; &#39;s/search string1/search string2/&#39;   &lt;br /&gt;&lt;br /&gt;It took me a while to find that the double quotes after -i are necessary on Mac OS X.  And be aware that the single quotes above usually get mangled to be backticks when copying and pasting.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;Edit 2:&lt;/b&gt; Don&#39;t do this in the root directory of a git repository!  It will corrupt the repository.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img width=&#39;1&#39; height=&#39;1&#39; src=&#39;https://blogger.googleusercontent.com/tracker/4660225022390848760-2002733795720160146?l=scienceinthesands.blogspot.com&#39; alt=&#39;&#39; /&gt;&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>How do shock waves behave in inhomogeneous materials?</title>
   <link href="https://www.qixiaodong.tk/en/2011/05/29/how-do-shocks-behave-in-inhomogeneous.html"/>
   <updated>2011-05-29T00:00:00+00:00</updated>
   <id>/2011/05/29/how-do-shocks-behave-in-inhomogeneous</id>
   <content type="html">Note: This post was originally written by &lt;a href=&quot;http://www.davidketcheson.info/2011/05/29/how-do-shocks-behave-in-inhomogeneous.html&quot; target=&quot;_blank&quot;&gt;David Ketcheson&lt;/a&gt;.

It&#39;s well known that solutions of genuinely nonlinear hyperbolic PDEs lead to shock singularities in finite time, under very weak assumptions on the initial data.  However, proofs of this statement invariably assume uniformity of the PDE coefficients in space and time.  What if the coefficients are allowed to vary, as would be the case for waves in many real materials, whose properties may be random or periodic?&lt;br /&gt;&lt;br /&gt;Surprisingly little is known about the answer to this question, but a first attempt to answer it in part is made in my recently submitted manuscript &lt;a href=&quot;http://arxiv.org/abs/1105.2892&quot;&gt;&quot;Shock dynamics in layered periodic media&quot;&lt;/a&gt;.  Among the &quot;shocking&quot; findings:&lt;br /&gt;&lt;br /&gt;-For certain media and relatively general initial conditions, shock formation seems not to occur even after extremely long times.&lt;br /&gt;-Shocks that would be stable in a homogeneous medium are frequently not stable in a heterogeneous medium&lt;br /&gt;-The asymptotic behavior of solutions in heterogeneous media is generally different; rather than consisting of N-waves, the solutions may be composed of solitary waves, for instance.&lt;br /&gt;&lt;br /&gt;To get an idea of what&#39;s going on, &lt;a href=&quot;https://bitbucket.org/ketch/layeredmediashocks/src/beaea8503a45/movies/&quot;&gt;take a look at some movies&lt;/a&gt; showing animations of the remarkable behavior of the solution.&lt;div class=&quot;blogger-post-footer&quot;&gt;&lt;img width=&#39;1&#39; height=&#39;1&#39; src=&#39;https://blogger.googleusercontent.com/tracker/4660225022390848760-972610786729015674?l=scienceinthesands.blogspot.com&#39; alt=&#39;&#39; /&gt;&lt;/div&gt;
</content>
 </entry>
 

</feed>
